<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>sqlserver开启cdc配置</title>
      <link href="/datasource/2024-08-29-sqlserver%E5%BC%80%E5%90%AFcdc%E9%85%8D%E7%BD%AE/"/>
      <url>/datasource/2024-08-29-sqlserver%E5%BC%80%E5%90%AFcdc%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>docker部署的sqlserver开启 flink-cdc配置</p><h2 id="进入容器-开启SqlServer-Agent-服务"><a href="#进入容器-开启SqlServer-Agent-服务" class="headerlink" title="进入容器,开启SqlServer-Agent 服务"></a>进入容器,开启SqlServer-Agent 服务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">exec</span> -it sqlserver_docker_cname bash<br><br>/opt/mssql/bin/mssql-conf <span class="hljs-built_in">set</span> sqlagent.enabled <span class="hljs-literal">true</span><br><br><span class="hljs-built_in">exit</span><br><br>docker restart sqlserver_docker_cname<br></code></pre></td></tr></table></figure><h2 id="使用SQL命令对库和表开启CDC"><a href="#使用SQL命令对库和表开启CDC" class="headerlink" title="使用SQL命令对库和表开启CDC"></a>使用SQL命令对库和表开启CDC</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs sql"><br><span class="hljs-comment">-- 对库开启</span><br>use db_name;<br><span class="hljs-keyword">EXEC</span> sys.sp_cdc_enable_db GO;<br><br><br><span class="hljs-comment">-- 对表开启</span><br>use db_name;<br><span class="hljs-keyword">EXEC</span> sys.sp_cdc_enable_table<br><span class="hljs-variable">@source</span>_schema <span class="hljs-operator">=</span> N<span class="hljs-string">&#x27;dbo&#x27;</span>,<br><span class="hljs-variable">@source</span>_name   <span class="hljs-operator">=</span> N<span class="hljs-string">&#x27;t_performance_test_1&#x27;</span>,<br><span class="hljs-variable">@role</span>_name     <span class="hljs-operator">=</span> <span class="hljs-keyword">NULL</span>,<br><span class="hljs-variable">@filegroup</span>_name <span class="hljs-operator">=</span> <span class="hljs-keyword">NULL</span>,<br><span class="hljs-variable">@supports</span>_net_changes <span class="hljs-operator">=</span> <span class="hljs-number">0</span><br>GO<br><br><span class="hljs-comment">-- 禁用:</span><br>use db_name;<br><span class="hljs-keyword">EXEC</span> sp_cdc_disable_table<br><span class="hljs-variable">@source</span>_schema <span class="hljs-operator">=</span> N<span class="hljs-string">&#x27;dbo&#x27;</span>,<br><span class="hljs-variable">@source</span>_name <span class="hljs-operator">=</span> N<span class="hljs-string">&#x27;t_performance_test_1&#x27;</span>,<br><span class="hljs-variable">@capture</span>_instance <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;dbo_t_performance_test_1&#x27;</span><br>GO<br><br><span class="hljs-comment">-- 查看是否开启</span><br><span class="hljs-keyword">SELECT</span> s.name <span class="hljs-keyword">AS</span> Schema_Name, tb.name <span class="hljs-keyword">AS</span> Table_Name<br>, tb.object_id, tb.type, tb.type_desc, tb.is_tracked_by_cdc<br><span class="hljs-keyword">FROM</span> sys.tables tb<br><span class="hljs-keyword">INNER</span> <span class="hljs-keyword">JOIN</span> sys.schemas s <span class="hljs-keyword">on</span> s.schema_id <span class="hljs-operator">=</span> tb.schema_id<br><span class="hljs-keyword">WHERE</span> tb.is_tracked_by_cdc <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br><br><br><span class="hljs-keyword">SELECT</span> is_cdc_enabled <span class="hljs-keyword">FROM</span> sys.databases <span class="hljs-keyword">WHERE</span> NAME <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test_1&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="扩展-SqlServer-CDC不支持采集DDL"><a href="#扩展-SqlServer-CDC不支持采集DDL" class="headerlink" title="扩展(SqlServer-CDC不支持采集DDL)"></a>扩展(SqlServer-CDC不支持采集DDL)</h2><p>目前SQL Server CDC自身对新增列不支持动态的采集.<br><br>兼容方案:<br>总体思路: 可以的中已存在的采集实例重建,来达到采集新增列的采集</p><ol><li>热部署：<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">1. 将所有更改应用于源表架构<br>2. 使用sys.sp_cdc_enable_table具有唯一参数值的过程为更新源表创建新的捕获表@capture_instance<br>3. 当Debezium从新的捕获表开始流式传输时，可以使用sys.sp_cdc_disable_table参数@capture_instance设置为旧捕获实例名称的存储过程删除旧的<br></code></pre></td></tr></table></figure></li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- Modify the source table schema</span><br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> test_dbo.customers <span class="hljs-keyword">ADD</span> phone_number <span class="hljs-type">VARCHAR</span>(<span class="hljs-number">32</span>);<br><br><span class="hljs-comment">-- Create the new capture instance</span><br><span class="hljs-keyword">EXEC</span> sys.sp_cdc_enable_table <span class="hljs-variable">@source</span>_schema <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test_dbo&#x27;</span>, <span class="hljs-variable">@source</span>_name <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;customers&#x27;</span>, <span class="hljs-variable">@role</span>_name <span class="hljs-operator">=</span> <span class="hljs-keyword">NULL</span>, <span class="hljs-variable">@supports</span>_net_changes <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, <span class="hljs-variable">@capture</span>_instance <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test_dbo_customers_v2&#x27;</span>;<br>GO<br><br><span class="hljs-comment">-- Drop the old capture instance</span><br><span class="hljs-keyword">EXEC</span> sys.sp_cdc_disable_table <span class="hljs-variable">@source</span>_schema <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test_dbo&#x27;</span>, <span class="hljs-variable">@source</span>_name <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;customers&#x27;</span>, <span class="hljs-variable">@capture</span>_instance <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test_dbo_customers&#x27;</span>;<br>GO<br><br><span class="hljs-comment">-- Insert new data</span><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> customers(first_name,last_name,email,phone_number) <span class="hljs-keyword">VALUES</span> (<span class="hljs-string">&#x27;John&#x27;</span>,<span class="hljs-string">&#x27;Doe&#x27;</span>,<span class="hljs-string">&#x27;john.doe@example.com&#x27;</span>, <span class="hljs-string">&#x27;+1-555-123456&#x27;</span>);<br>GO<br></code></pre></td></tr></table></figure><p>热部署缺点:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">热模式更新有一个缺点。从数据库架构更新到创建新的捕获实例之间有一段时间。<br>在此期间将要到达的所有更改都由具有旧结构的旧实例捕获。例如，这意味着对于新添加的列，在此期间产生的任何更改事件都将不包含该新列的字段。<br>如果您的应用程序不允许这样的过渡期，我们建议您遵循冷模式更新。(这也是官网原话)<br><br></code></pre></td></tr></table></figure><ol start="2"><li>冷部署<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">1. 挂起生成数据库记录的应用程序<br>2. 等待Debezium流所有未流的更改<br>3. 停止连接器<br>4. 将所有更改应用于源表架构<br>5. 使用sys.sp_cdc_enable_table具有唯一参数值的过程为更新源表创建新的捕获表@capture_instance<br>6. 恢复应用<br>7. 启动连接器<br>8. 当Debezium从新的捕获表开始流式传输时，可以使用sys.sp_cdc_disable_table参数@capture_instance设置为旧捕获实例名称的存储过程删除旧的<br></code></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> SqlServer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SqlServer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Log4j2使用和问题记录</title>
      <link href="/other/2024-08-14-log4j2%E4%BD%BF%E7%94%A8%E5%92%8C%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
      <url>/other/2024-08-14-log4j2%E4%BD%BF%E7%94%A8%E5%92%8C%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>记录自己在使用Log4j2的一些问题和技巧</p><h2 id="Log4j2采集日志输出到MQ-kafka-中"><a href="#Log4j2采集日志输出到MQ-kafka-中" class="headerlink" title="Log4j2采集日志输出到MQ(kafka)中"></a>Log4j2采集日志输出到MQ(kafka)中</h2><p>xml格式:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">Configuration</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;KafkaAppender&quot;</span> <span class="hljs-attr">status</span>=<span class="hljs-string">&quot;OFF&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Appenders</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Kafka</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;Kafka&quot;</span> <span class="hljs-attr">topic</span>=<span class="hljs-string">&quot;log-topic&quot;</span> &gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">JsonTemplateLayout</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">EventTemplateAdditionalField</span></span><br><span class="hljs-tag"><span class="hljs-attr">key</span>=<span class="hljs-string">&quot;yarnContainerId&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">format</span>=<span class="hljs-string">&quot;JSON&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">value</span>=<span class="hljs-string">&#x27;&quot;$&#123;sys:yarnContainerId&#125;&quot;&#x27;</span>/&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">EventTemplateAdditionalField</span></span><br><span class="hljs-tag"><span class="hljs-attr">key</span>=<span class="hljs-string">&quot;jobName&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">format</span>=<span class="hljs-string">&quot;JSON&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">value</span>=<span class="hljs-string">&#x27;&quot;$&#123;sys:jobName&#125;&quot;&#x27;</span>/&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">EventTemplateAdditionalField</span></span><br><span class="hljs-tag"><span class="hljs-attr">key</span>=<span class="hljs-string">&quot;jobId&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">format</span>=<span class="hljs-string">&quot;JSON&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">value</span>=<span class="hljs-string">&#x27;&quot;$&#123;sys:jobId&#125;&quot;&#x27;</span>/&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">EventTemplateAdditionalField</span></span><br><span class="hljs-tag"><span class="hljs-attr">key</span>=<span class="hljs-string">&quot;taskId&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">format</span>=<span class="hljs-string">&quot;JSON&quot;</span></span><br><span class="hljs-tag"><span class="hljs-attr">value</span>=<span class="hljs-string">&#x27;&quot;$&#123;sys:taskId&#125;&quot;&#x27;</span>/&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">JsonTemplateLayout</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;bootstrap.servers&quot;</span>&gt;</span>192.168.xxx.xxx:9092<span class="hljs-tag">&lt;/<span class="hljs-name">Property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- if kafka have password ,else cancel  --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;security.protocol&quot;</span>&gt;</span>SASL_PLAINTEXT<span class="hljs-tag">&lt;/<span class="hljs-name">Property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">Property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;sasl.mechanism&quot;</span>&gt;</span>PLAIN<span class="hljs-tag">&lt;/<span class="hljs-name">Property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">Property</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;sasl.jaas.config&quot;</span>&gt;</span>org.apache.kafka.common.security.plain.PlainLoginModule required username=&quot;admin&quot; password=&quot;passwd-123&quot;;<span class="hljs-tag">&lt;/<span class="hljs-name">Property</span>&gt;</span><br>        <br><span class="hljs-tag">&lt;/<span class="hljs-name">Kafka</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Console</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;STDOUT&quot;</span> <span class="hljs-attr">target</span>=<span class="hljs-string">&quot;SYSTEM_OUT&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">PatternLayout</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">pattern</span>&gt;</span>%d&#123;yy-MM-dd HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n<span class="hljs-tag">&lt;/<span class="hljs-name">pattern</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">PatternLayout</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">Console</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">Appenders</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Loggers</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Root</span> <span class="hljs-attr">level</span>=<span class="hljs-string">&quot;INFO&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">AppenderRef</span> <span class="hljs-attr">ref</span>=<span class="hljs-string">&quot;Kafka&quot;</span>/&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">AppenderRef</span> <span class="hljs-attr">ref</span>=<span class="hljs-string">&quot;STDOUT&quot;</span>/&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">Root</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">Logger</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;org.apache.kafka&quot;</span> <span class="hljs-attr">level</span>=<span class="hljs-string">&quot;WARN&quot;</span> <span class="hljs-attr">additivity</span>=<span class="hljs-string">&quot;false&quot;</span>/&gt;</span> <span class="hljs-comment">&lt;!-- avoid recursive logging --&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">Loggers</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">Configuration</span>&gt;</span><br><br></code></pre></td></tr></table></figure><p>propertites格式</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><br><span class="hljs-string">rootLogger.level</span> <span class="hljs-string">=</span> <span class="hljs-string">INFO</span><br><span class="hljs-string">rootLogger.appenderRef.console.ref</span> <span class="hljs-string">=</span> <span class="hljs-string">ConsoleAppender</span><br><span class="hljs-string">rootLogger.appenderRef.kafka.ref</span> <span class="hljs-string">=</span> <span class="hljs-string">KafkaLog4jAppender</span><br><br><br><span class="hljs-string">appender.console.name</span> <span class="hljs-string">=</span> <span class="hljs-string">ConsoleAppender</span><br><span class="hljs-string">appender.console.type</span> <span class="hljs-string">=</span> <span class="hljs-string">CONSOLE</span><br><span class="hljs-string">appender.console.layout.type</span> <span class="hljs-string">=</span> <span class="hljs-string">PatternLayout</span><br><span class="hljs-string">appender.console.layout.pattern</span> <span class="hljs-string">=</span> <span class="hljs-string">%d&#123;yyyy-MM-dd</span> <span class="hljs-string">HH:mm:ss,SSS&#125;</span> <span class="hljs-string">%-5p</span> <span class="hljs-string">%-60c</span> <span class="hljs-string">%x</span> <span class="hljs-bullet">-</span> <span class="hljs-string">%m%n</span><br><br><br><span class="hljs-comment">#log4j.appender.console=org.apache.log4j.ConsoleAppender</span><br><span class="hljs-comment">#log4j.appender.console.layout=org.apache.log4j.PatternLayout</span><br><span class="hljs-comment">#log4j.appender.console.layout.pattern=%d %p [%t] %m%n</span><br><span class="hljs-comment">#appender.kafka=org.apache.kafka.log4jappender.KafkaLog4jAppender</span><br><span class="hljs-string">appender.kafka.name</span> <span class="hljs-string">=</span> <span class="hljs-string">KafkaLog4jAppender</span><br><span class="hljs-string">appender.kafka.type</span> <span class="hljs-string">=</span> <span class="hljs-string">kafka</span><br><span class="hljs-string">appender.kafka.topic</span> <span class="hljs-string">=</span> <span class="hljs-string">log-topic</span><br><br><span class="hljs-string">appender.kafka.properties[0].type=Property</span><br><span class="hljs-string">appender.kafka.properties[0].name=bootstrap.servers</span><br><span class="hljs-string">appender.kafka.properties[0].value=192.168.xxx.xxx:9094</span><br><span class="hljs-string">appender.kafka.properties[1].type=Property</span><br><span class="hljs-string">appender.kafka.properties[1].name=timeout.ms</span><br><span class="hljs-string">appender.kafka.properties[1].value=30000</span><br><br><span class="hljs-comment">#appender.kafka.brokerList=192.168.12.234:9094</span><br><span class="hljs-comment">#appender.kafka.lingerMs=200</span><br><span class="hljs-comment">#appender.kafka.retries=3</span><br><span class="hljs-comment">#appender.kafka.layout=org.apache.logging.log4j.layout.template.json.JsonTemplateLayout</span><br><span class="hljs-comment">#appender.kafka.json.type = JsonTemplateLayout</span><br><span class="hljs-string">appender.kafka.layout.type</span> <span class="hljs-string">=</span> <span class="hljs-string">JsonTemplateLayout</span><br><span class="hljs-comment">#appender.kafka.layout.pattern = %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="hljs-comment">#appender.kafka.layout=org.apache.logging.log4j.layout.template.json.JsonTemplateLayout</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[0].type=EventTemplateAdditionalField</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[0].key=yarnContainerId</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[0].value=&quot;$&#123;sys:yarnContainerId&#125;&quot;</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[0].format=JSON</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[1].type=EventTemplateAdditionalField</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[1].key=jobName</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[1].value=&quot;$&#123;sys:jobName&#125;&quot;</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[1].format=JSON</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[2].type=EventTemplateAdditionalField</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[2].key=jobId</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[2].value=&quot;$&#123;sys:jobId&#125;&quot;</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[2].format=JSON</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[3].type=EventTemplateAdditionalField</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[3].key=taskId</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[3].value=&quot;$&#123;sys:taskId&#125;&quot;</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[3].format=JSON</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[4].type=EventTemplateAdditionalField</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[4].key=logId</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[4].value=&quot;$&#123;sys:logId&#125;&quot;</span><br><span class="hljs-string">appender.kafka.layout.eventTemplateAdditionalField[4].format=JSON</span><br><br></code></pre></td></tr></table></figure><h2 id="Log4j2设置指定包或类日志的打印级别"><a href="#Log4j2设置指定包或类日志的打印级别" class="headerlink" title="Log4j2设置指定包或类日志的打印级别"></a>Log4j2设置指定包或类日志的打印级别</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment">################################################################################</span><br><span class="hljs-string">rootLogger.level=INFO</span><br><span class="hljs-string">rootLogger.appenderRef.test.ref</span> <span class="hljs-string">=</span> <span class="hljs-string">TestLogger</span><br><br><span class="hljs-string">appender.testlogger.name</span> <span class="hljs-string">=</span> <span class="hljs-string">TestLogger</span><br><span class="hljs-string">appender.testlogger.type</span> <span class="hljs-string">=</span> <span class="hljs-string">CONSOLE</span><br><span class="hljs-string">appender.testlogger.target</span> <span class="hljs-string">=</span> <span class="hljs-string">SYSTEM_ERR</span><br><span class="hljs-string">appender.testlogger.layout.type</span> <span class="hljs-string">=</span> <span class="hljs-string">PatternLayout</span><br><span class="hljs-string">appender.testlogger.layout.pattern</span> <span class="hljs-string">=</span> <span class="hljs-string">%-4r</span> [<span class="hljs-string">%t</span>] <span class="hljs-string">%-5p</span> <span class="hljs-string">%c</span> <span class="hljs-bullet">-</span> <span class="hljs-string">%m%n</span><br><span class="hljs-comment">#指定包日志级别</span><br><span class="hljs-string">logger.kafkaLog.name</span> <span class="hljs-string">=</span> <span class="hljs-string">org.apache.kafka</span><br><span class="hljs-string">logger.kafkaLog.level</span> <span class="hljs-string">=</span> <span class="hljs-string">WARN</span><br><span class="hljs-string">logger.kafkaLog.additivity</span> <span class="hljs-string">=</span> <span class="hljs-literal">false</span><br><span class="hljs-comment"># 设置特定包的日志级别  </span><br><span class="hljs-string">logger.com.example.mypackage.name</span> <span class="hljs-string">=</span> <span class="hljs-string">com.example.mypackage</span>  <br><span class="hljs-string">logger.com.example.mypackage.level</span> <span class="hljs-string">=</span> <span class="hljs-string">DEBUG</span>  <br><span class="hljs-string">logger.com.example.mypackage.additivity</span> <span class="hljs-string">=</span> <span class="hljs-literal">false</span>  <br><br><span class="hljs-comment"># 设置另一个包的日志级别  </span><br><span class="hljs-string">logger.com.example.myotherpackage.name</span> <span class="hljs-string">=</span> <span class="hljs-string">com.example.myotherpackage</span>  <br><span class="hljs-string">logger.com.example.myotherpackage.level</span> <span class="hljs-string">=</span> <span class="hljs-string">INFO</span>  <br><span class="hljs-string">logger.com.example.myotherpackage.additivity</span> <span class="hljs-string">=</span> <span class="hljs-literal">false</span>  <br><br><span class="hljs-comment"># 设置特定类的日志级别  </span><br><span class="hljs-string">logger.com.example.mypackage.MyClass.name</span> <span class="hljs-string">=</span> <span class="hljs-string">com.example.mypackage.MyClass</span>  <br><span class="hljs-string">logger.com.example.mypackage.MyClass.level</span> <span class="hljs-string">=</span> <span class="hljs-string">TRACE</span>  <br><span class="hljs-string">logger.com.example.mypackage.MyClass.additivity</span> <span class="hljs-string">=</span> <span class="hljs-literal">false</span> <br><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mysql开启flink-cdc同步的相关配置</title>
      <link href="/datasource/2024-06-27-mysql%E5%BC%80%E5%90%AFflink-cdc%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/"/>
      <url>/datasource/2024-06-27-mysql%E5%BC%80%E5%90%AFflink-cdc%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="配置my-cnf"><a href="#配置my-cnf" class="headerlink" title="配置my.cnf"></a>配置my.cnf</h1><p>文件所在目录: &#x2F;etc&#x2F;my.cnf</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs conf">[client]<br>default-character-set=utf8mb4<br><br>[mysqld] <br># 配置时区<br>default_time_zone=&#x27;+8:00&#x27;<br># 数据所在目录<br>datadir=/var/lib/mysql<br>socket=/var/lib/mysql/mysql.sock<br><br># server-id,每个实例不能重复<br>server-id=1<br># binlog格式 <br>binlog_format=ROW<br># binlog所在目录<br>log_bin=/var/lib/mysql/log_bin<br><br>log-error=/var/log/mysqld.log<br>pid-file=/var/run/mysqld/mysqld.pid<br><br># 默认引擎和编码配置<br>default-storage-engine=INNODB<br>character-set-server=utf8mb4<br>collation-server=utf8mb4_unicode_ci<br><br># 配置开启gtid,此时cdc同步时,可以指定gtid启动,默认关闭. show variables like &#x27;gtid_mode&#x27;<br>gtid_mode=on                 #开启gtid模式<br>enforce_gtid_consistency=on  #强制gtid一致性，开启后对于特定create table不被支持<br></code></pre></td></tr></table></figure><h2 id="GTID-说明"><a href="#GTID-说明" class="headerlink" title="GTID 说明"></a>GTID 说明</h2><p>GTID (Global Transaction IDentifier) 是全局事务标识。它具有全局唯一性，一个事务对应一个GTID。唯一性不仅限于主服务器，GTID在所有的从服务器上也是唯一的。一个GTID在一个服务器上只执行一次，从而避免重复执行导致数据混乱或主从不一致。</p><p>在传统的复制里面，当发生故障需要主从切换时，服务器需要找到binlog和pos点，然后将其设定为新的主节点开启复制。相对来说比较麻烦，也容易出错。在MySQL 5.6里面，MySQL会通过内部机制自动匹配GTID断点，不再寻找binlog和pos点。我们只需要知道主节点的ip，端口，以及账号密码就可以自动复制。<br>更多说明参考: <a href="http://mysql.taobao.org/monthly/2020/05/09/">MySQL · 引擎特性 · 基于GTID复制实现的工作原理</a></p><h2 id="查看cdc相关配置开启情况"><a href="#查看cdc相关配置开启情况" class="headerlink" title="查看cdc相关配置开启情况"></a>查看cdc相关配置开启情况</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">show</span> variables <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;log_bin&#x27;</span>; <span class="hljs-comment">-- binlog是否开启</span><br><span class="hljs-keyword">show</span> variables <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;binlog_format&#x27;</span>; <span class="hljs-comment">-- binlog格式</span><br><span class="hljs-keyword">show</span> variables <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;gtid_mode&#x27;</span>; <span class="hljs-comment">-- gitd模式是否开启</span><br><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Postgres开启Flink-CDC同步配置</title>
      <link href="/flink/2024-06-27-Postgres%E5%BC%80%E5%90%AFcdc%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE/"/>
      <url>/flink/2024-06-27-Postgres%E5%BC%80%E5%90%AFcdc%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本:"></a>软件版本:</h1><p>PostgreSQL: </p><p>主要步骤: 1.配置conf, 2对用户进行授权</p><h1 id="1-配置conf"><a href="#1-配置conf" class="headerlink" title="1. 配置conf"></a>1. 配置conf</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs conf">#更改wal日志方式为logical（方式有：minimal、replica 、logical ）<br>wal_level = logical  <br><br># 更改solts最大数量（默认值为10），flink-cdc默认一张表占用一个slots<br>max_replication_slots = 20<br><br># 更改wal发送最大进程数（默认值为10），这个值和上面的solts设置一样<br>max_wal_senders = 20     <br><br># 中断那些停止活动超过指定毫秒数的复制连接，可以适当设置大一点（默认60s，0表示禁用）<br>wal_sender_timeout = 180s   <br></code></pre></td></tr></table></figure><h1 id="2-创建用户并授权"><a href="#2-创建用户并授权" class="headerlink" title="2. 创建用户并授权"></a>2. 创建用户并授权</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- pg新建用户</span><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">USER</span> cdc_user <span class="hljs-keyword">WITH</span> PASSWORD <span class="hljs-string">&#x27;cdc_user123&#x27;</span>;<br><br><br><span class="hljs-comment">-- 给用户复制流权限</span><br><span class="hljs-keyword">ALTER</span> ROLE ODPS_ETL replication;<br><br><span class="hljs-comment">-- 给用户登录数据库权限</span><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">CONNECT</span> <span class="hljs-keyword">ON</span> DATABASE test_db <span class="hljs-keyword">to</span> cdc_user;<br><br><span class="hljs-comment">-- 把当前库public下所有表查询权限赋给用户</span><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">ALL</span> PRIVILEGES <span class="hljs-keyword">ON</span> <span class="hljs-keyword">ALL</span> TABLES <span class="hljs-keyword">IN</span> SCHEMA public <span class="hljs-keyword">TO</span> cdc_user;<br> <br></code></pre></td></tr></table></figure><ol start="3"><li>发布表<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 设置发布为true</span><br><span class="hljs-keyword">update</span> pg_publication <span class="hljs-keyword">set</span> puballtables<span class="hljs-operator">=</span><span class="hljs-literal">true</span> <span class="hljs-keyword">where</span> pubname <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>;<br><br><span class="hljs-comment">-- 把所有表进行发布,实际使用中,根据自身需要同步的进行发布</span><br><span class="hljs-keyword">CREATE</span> PUBLICATION dbz_publication <span class="hljs-keyword">FOR</span> <span class="hljs-keyword">ALL</span> TABLES;<br><br><span class="hljs-comment">-- 查询哪些表已经发布</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> pg_publication_tables;<br><br><br><span class="hljs-comment">-- 更改复制标识包含更新和删除之前值（目的是为了确保表 test_tb 在实时同步过程中能够正确地捕获并同步更新和删除的数据变化。如果不执行这两条语句，那么 test_tb 表的复制标识可能默认为 NOTHING，这可能导致实时同步时丢失更新和删除的数据行信息，从而影响同步的准确性）</span><br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> test_tb REPLICA <span class="hljs-keyword">IDENTITY</span> <span class="hljs-keyword">FULL</span>;<br><br><span class="hljs-comment">-- 查看复制标识（为f标识说明设置成功，f（表示 full），否则为 n（表示 nothing），即复制标识未设置）</span><br><span class="hljs-keyword">select</span> relreplident <span class="hljs-keyword">from</span> pg_class <span class="hljs-keyword">where</span> relname<span class="hljs-operator">=</span><span class="hljs-string">&#x27;test_tb&#x27;</span>;<br><br><span class="hljs-comment">-- 给表查询权限</span><br><span class="hljs-keyword">grant</span> <span class="hljs-keyword">select</span> <span class="hljs-keyword">on</span> <span class="hljs-keyword">TABLE</span> test_tb <span class="hljs-keyword">to</span> ODPS_ETL;<br><br><span class="hljs-comment">-- 把当前库所有表查询权限赋给用户</span><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">ON</span> <span class="hljs-keyword">ALL</span> TABLES <span class="hljs-keyword">IN</span> SCHEMA public <span class="hljs-keyword">TO</span> ODPS_ETL;<br><span class="hljs-comment">-- 把当前库以后新建的表查询权限赋给用户</span><br><span class="hljs-keyword">alter</span> <span class="hljs-keyword">default</span> privileges <span class="hljs-keyword">in</span> schema public <span class="hljs-keyword">grant</span> <span class="hljs-keyword">select</span> <span class="hljs-keyword">on</span> tables <span class="hljs-keyword">to</span> ODPS_ETL;<br><br><span class="hljs-comment">-- 更改复制标识包含更新和删除之前值</span><br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> test_tb REPLICA <span class="hljs-keyword">IDENTITY</span> <span class="hljs-keyword">FULL</span>;<br><br><span class="hljs-comment">-- 查看复制标识</span><br><span class="hljs-keyword">select</span> relreplident <span class="hljs-keyword">from</span> pg_class <span class="hljs-keyword">where</span> relname<span class="hljs-operator">=</span><span class="hljs-string">&#x27;test_tb&#x27;</span>;<br><br><span class="hljs-comment">-- 查看solt使用情况</span><br><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> pg_replication_slots;<br><br><span class="hljs-comment">-- 删除solt</span><br><span class="hljs-keyword">SELECT</span> pg_drop_replication_slot(<span class="hljs-string">&#x27;flink_slot_test&#x27;</span>);<br><br><span class="hljs-comment">-- 查询用户当前连接数</span><br><span class="hljs-keyword">select</span> usename, <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">from</span> pg_stat_activity <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> usename <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> <span class="hljs-built_in">count</span>(<span class="hljs-operator">*</span>) <span class="hljs-keyword">desc</span>;<br><br><span class="hljs-comment">-- 设置用户最大连接数</span><br><span class="hljs-keyword">alter</span> role odps_etl connection limit <span class="hljs-number">200</span>;<br><br></code></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> Flink-CDC </category>
          
          <category> Postgres </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink-CDC </tag>
            
            <tag> Postgres </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink On K8S 实践分享</title>
      <link href="/flink/Flink%20On%20K8S%20%E5%AE%9E%E8%B7%B5%E5%88%86%E4%BA%AB/"/>
      <url>/flink/Flink%20On%20K8S%20%E5%AE%9E%E8%B7%B5%E5%88%86%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="各软件版本"><a href="#各软件版本" class="headerlink" title="各软件版本"></a>各软件版本</h2><ul><li>k8s: 1.24.2</li><li>flink: 1.14.5</li><li>JDK: 1.8</li><li>Hadoop: 3.0.0</li></ul><h2 id="K8S"><a href="#K8S" class="headerlink" title="K8S"></a>K8S</h2><p>Kubernetes是一个由谷歌开发的开源容器编排平台，用于自动化部署、扩展和管理容器化应用程序。Kubernetes旨在管理在主机集群上部署和扩展容器化应用程序时的复杂性。</p><h3 id="组成部分"><a href="#组成部分" class="headerlink" title="组成部分"></a>组成部分</h3><ul><li><p>Master节点：</p><blockquote><p>kube-apiserver（API Server）： 提供Kubernetes API，允许用户和其他组件与集群交互。所有集群操作都通过API Server进行。</p></blockquote><blockquote><p>etcd： 分布式键值存储系统，用于存储集群的配置数据、元数据和状态。</p></blockquote><blockquote><p>kube-scheduler： 根据资源需求和约束，将未分配的Pod（容器组）调度到合适的节点上。</p></blockquote><blockquote><p>kube-controller-manager： 运行控制器，监控集群状态并根据期望状态进行调整。常见的控制器包括副本控制器、节点控制器、服务控制器等。</p></blockquote><blockquote><p>cloud-controller-manager： 如果集群在云服务提供商上运行，这个组件会与云提供商的API交互，执行与云环境相关的任务。</p></blockquote></li><li><p>Node节点：</p><blockquote><p>kubelet： 在每个节点上运行，负责管理容器和Pod的生命周期，确保它们在所需的状态下运行。</p></blockquote><blockquote><p>kube-proxy： 负责为Pod设置网络代理和负载均衡规则，以实现服务发现和访问。</p></blockquote><blockquote><p>Container Runtime： 负责运行容器，如Docker、containerd等。</p></blockquote></li><li><p>其他关键组件：</p><blockquote><p>Pod： 一个或多个容器的组合，它们共享网络和存储，是Kubernetes的最小部署单位。</p></blockquote><blockquote><p>Deployment： 控制器的一种，用于声明性地定义Pod的部署方式，支持滚动更新和回滚。</p></blockquote><blockquote><p>Service： 用于公开Pod组成的应用程序，为其提供稳定的网络地址，实现负载均衡和服务发现。</p></blockquote><blockquote><p>Namespace： 用于将集群内的资源划分为不同的虚拟组，以帮助管理和隔离。</p></blockquote><blockquote><p>ConfigMap和Secret： 用于将配置信息和敏感信息（如密码、证书）与Pod分开，实现配置的分离和安全性。</p></blockquote><blockquote><p>Volume： 提供容器级别的持久性存储，以便数据在容器之间和容器重启之间持久保存。</p></blockquote><blockquote><p>Ingress： 允许外部流量进入集群，将请求路由到相应的服务和Pod。</p></blockquote><blockquote><p>StatefulSet： 用于管理有状态应用程序的控制器，确保有状态应用程序的有序部署、伸缩和更新。</p></blockquote></li></ul><h3 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h3><ul><li><p>容器编排： Kubernetes管理容器，这些容器是将应用程序及其依赖项打包在一起的隔离环境。它确保容器按照用户定义的规范运行、保持健康，并根据需要进行扩展。</p></li><li><p>自动扩展： Kubernetes可以根据资源使用情况或定义的规则自动扩展容器的数量。这确保了最佳性能和资源利用。</p></li><li><p>服务发现和负载均衡： Kubernetes提供机制来公开服务并将传入的网络流量分发到服务的实例。这有助于负载均衡并将流量路由到适当的容器。</p></li><li><p>自愈性： 如果容器或节点发生故障，Kubernetes可以自动用新容器替换失败的容器，以维护期望的应用程序状态和可用性。</p></li><li><p>配置管理： Kubernetes允许您单独管理应用程序配置和设置，而不与应用程序代码混在一起。这使得可以在不重新部署整个应用程序的情况下修改配置。</p></li><li><p>存储编排： Kubernetes提供了管理和挂载容器的存储的方式，从而实现数据持久性和在容器实例之间的共享。</p></li><li><p>声明式管理： Kubernetes使用声明性配置文件（YAML或JSON）来定义应用程序和基础架构的期望状态。系统会持续工作，确保当前状态与配置中指定的期望状态相匹配。</p></li><li><p>滚动更新和回滚： Kubernetes支持滚动更新，允许您在不停机的情况下更新应用程序。如果更新引发问题，您可以轻松回滚到先前的版本。</p></li><li><p>可扩展性： Kubernetes采用模块化架构，允许添加自定义插件和扩展，使其适应各种环境和需求。</p></li></ul><h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>Docker是一种开源的容器化平台，用于构建、发布和运行应用程序及其依赖项在轻量级、可移植的容器中。Docker容器是一种轻量级的虚拟化技术，允许应用程序在隔离的环境中运行，同时共享主机操作系统的内核。这使得应用程序可以在不同的环境中以一致的方式运行，从开发环境到生产环境，从本地机器到云服务器。</p><h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul><li><p>容器： 容器是一个独立且可执行的软件包，包括应用程序及其运行时所需的库、环境变量、配置文件等。容器是轻量级的，因为它们共享主机操作系统的内核。</p></li><li><p>镜像： 镜像是用于构建容器的模板。它包含了一切应用程序运行所需的文件、依赖项和配置信息。镜像是不可变的，一旦创建就不会改变。可以通过在Docker镜像上创建多个容器来实现应用程序的运行。</p></li><li><p>容器运行时： Docker容器运行时是负责启动、停止和管理容器的组件。常用的容器运行时包括Docker Engine、containerd等。</p></li><li><p>Docker引擎： Docker引擎是Docker平台的核心组件，包括Docker守护进程、CLI工具和REST API。它负责管理容器、镜像、网络等。</p></li></ul><h3 id="优势特性"><a href="#优势特性" class="headerlink" title="优势特性"></a>优势特性</h3><ul><li><p>轻量级和快速启动： 容器与传统虚拟机相比更轻量级，可以在几秒钟内启动。这使得应用程序的部署和扩展更加高效。</p></li><li><p>一致性： 应用程序在不同环境中以相同的方式运行，避免了“在我的机器上可工作”等问题。</p></li><li><p>隔离性： 容器之间以及容器与宿主机之间有强大的隔离性，可以防止应用程序之间的冲突和干扰。</p></li><li><p>可移植性： Docker容器可以在任何支持Docker的环境中运行，无论是开发人员的笔记本电脑还是云服务器。</p></li><li><p>可扩展性： Docker容器可以轻松地在多个主机上进行复制和扩展，实现应用程序的水平扩展。</p></li></ul><h2 id="Flink"><a href="#Flink" class="headerlink" title="Flink"></a>Flink</h2><p>一个开源的流处理和批处理框架，用于处理和分析大规模数据流和批量数据。</p><h3 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h3><ul><li>JobManager</li><li>TaskManager</li></ul><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ol><li>k8s集群环境</li><li>Docker私有仓库</li><li>Hadoop(Hive)环境<br>write data to iceberg,hudi, or flink checkpoint use hdfs</li></ol><h1 id="编写Flink-APP"><a href="#编写Flink-APP" class="headerlink" title="编写Flink-APP"></a>编写Flink-APP</h1><h2 id="maven-依赖引入"><a href="#maven-依赖引入" class="headerlink" title="maven 依赖引入"></a>maven 依赖引入</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br></pre></td><td class="code"><pre><code class="hljs xml"> <span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">maven.compiler.source</span>&gt;</span>8<span class="hljs-tag">&lt;/<span class="hljs-name">maven.compiler.source</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">maven.compiler.target</span>&gt;</span>8<span class="hljs-tag">&lt;/<span class="hljs-name">maven.compiler.target</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">iceberg.version</span>&gt;</span>1.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">iceberg.version</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">hive.version</span>&gt;</span>2.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">hive.version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>        <span class="hljs-comment">&lt;!--        flink --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-java<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-json<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-base<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-shaded-hadoop-2-uber<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.8.3-9.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.slf4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>slf4j-log4j12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-planner_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-api-java-bridge_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-api-java<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-runtime_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-sql-connector-kafka_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-hive_$&#123;scala.binary.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-metastore<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-sql-connector-hive-2.2.0_2.12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>commons-lang<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-lang<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.commons<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-lang3<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-metastore<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!--    flink end    --&gt;</span><br>        <span class="hljs-comment">&lt;!--     hive    --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-metastore<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>commons-lang<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-lang<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.commons<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-lang3<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-exec<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>antlr-runtime<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.antlr<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>commons-lang<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-lang<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.commons<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>commons-lang3<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!--  hive end    --&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>xml-apis<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>xml-apis<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.4.01<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>mysql<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>mysql-connector-java<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>8.0.25<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.postgresql<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>postgresql<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>42.5.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.microsoft.sqlserver<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>mssql-jdbc<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>11.2.0.jre8<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.oracle.ojdbc<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>ojdbc8<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>19.3.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-comment">&lt;!--  iceberg      --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.iceberg<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>iceberg-flink-runtime-1.14<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;iceberg.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!--  iceberg   end   --&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j-slf4j-impl<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j-api<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- log4j2 日志layout json模板        --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>log4j-layout-template-json<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;log4j.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- 日志组件往kafka中写日志       --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka-log4j-appender<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.2.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">exclusions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">exclusion</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka-clients<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">exclusion</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">exclusions</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>4.12<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>test<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>kafka-clients<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;kafka.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-runtime-web_2.12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>test<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br><br>            <span class="hljs-comment">&lt;!-- Java Compiler --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>$&#123;target.java.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>$&#123;target.java.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br><br>            <span class="hljs-comment">&lt;!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --&gt;</span><br>            <span class="hljs-comment">&lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry point changes. --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-shade-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactSet</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">excludes</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>org.apache.flink:flink-shaded-force-shading<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>com.google.code.findbugs:jsr305<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>org.slf4j:*<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>org.apache.logging.log4j:*<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">excludes</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">artifactSet</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">minimizeJar</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">minimizeJar</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">filters</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">filter</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">artifact</span>&gt;</span>*:*<span class="hljs-tag">&lt;/<span class="hljs-name">artifact</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">excludes</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>META-INF/*.SF<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>META-INF/*.DSA<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">exclude</span>&gt;</span>META-INF/*.RSA<span class="hljs-tag">&lt;/<span class="hljs-name">exclude</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">excludes</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">filter</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">filters</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">transformers</span>&gt;</span><br><span class="hljs-comment">&lt;!--                        &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;--&gt;</span><br><span class="hljs-comment">&lt;!--                        &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;--&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">transformer</span>  <span class="hljs-attr">implementation</span>=<span class="hljs-string">&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">mainClass</span>&gt;</span>com.xxx.xxx.MainClass<span class="hljs-tag">&lt;/<span class="hljs-name">mainClass</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">transformer</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">transformers</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                    <span class="hljs-comment">&lt;!-- Run shade goal on package phase --&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>shade<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-dependency-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.6.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>copy-compile-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>copy-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/deps<span class="hljs-tag">&lt;/<span class="hljs-name">outputDirectory</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">excludeTransitive</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">excludeTransitive</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">stripVersion</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">stripVersion</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">includeScope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">includeScope</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>copy-provided-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>copy-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/lib<span class="hljs-tag">&lt;/<span class="hljs-name">outputDirectory</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">excludeTransitive</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">excludeTransitive</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">stripVersion</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">stripVersion</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">includeScope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">includeScope</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">pluginManagement</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">pluginManagement</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">profiles</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">profile</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>hive2<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">activation</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">activeByDefault</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">activeByDefault</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">activation</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">repositories</span>&gt;</span><br>                <span class="hljs-comment">&lt;!-- hive-jdbc hive2版本,依赖org.pentaho:pentaho-aggdesigner-algorithm:pom:5.1.5-jhyde --&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>aliyunmaven-sp<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>spring-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>https://maven.aliyun.com/repository/spring-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">repositories</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">profile</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">profile</span>&gt;</span><br>            <span class="hljs-comment">&lt;!--  -P hive3           --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>hive3<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">hive.version</span>&gt;</span>3.1.3<span class="hljs-tag">&lt;/<span class="hljs-name">hive.version</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-sql-connector-hive-3.1.2_2.12<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>                    <span class="hljs-comment">&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-metastore<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-dependency-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.6.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>copy-compile-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>copy-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                                <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                             <br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">excludeTransitive</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">excludeTransitive</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">stripVersion</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">stripVersion</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">includeScope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">includeScope</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                                        flink-sql-connector-hive-2.2.0_$&#123;scala.binary.version&#125;<br>                                    <span class="hljs-tag">&lt;/<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>copy-provided-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>copy-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                                <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/lib<span class="hljs-tag">&lt;/<span class="hljs-name">outputDirectory</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">excludeTransitive</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">excludeTransitive</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">stripVersion</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">stripVersion</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">includeScope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">includeScope</span>&gt;</span><br>                                    <span class="hljs-tag">&lt;<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                                        flink-sql-connector-hive-2.2.0_$&#123;scala.binary.version&#125;<br>                                    <span class="hljs-tag">&lt;/<span class="hljs-name">excludeArtifactIds</span>&gt;</span><br>                                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">profile</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">profiles</span>&gt;</span><br></code></pre></td></tr></table></figure><p>程序主要逻辑:<br>读取kafka中json数据,写入到iceberg中.</p><h1 id="Build-Docker-Image"><a href="#Build-Docker-Image" class="headerlink" title="Build-Docker-Image"></a>Build-Docker-Image</h1><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs Dockerfile"><span class="hljs-keyword">FROM</span> flink:<span class="hljs-number">1.14</span>.<span class="hljs-number">5</span>-scala_2.<span class="hljs-number">12</span>-java8<br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">set</span> -ex; \</span><br><span class="language-bash">  apt-get update; \</span><br><span class="language-bash">  apt-get -y  install s3fs; \</span><br><span class="language-bash">  <span class="hljs-built_in">rm</span> -rf /var/lib/apt/lists/*</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">set</span> -ex; <span class="hljs-built_in">rm</span> -rf /opt/flink/lib/*</span><br><br><span class="hljs-keyword">COPY</span><span class="language-bash"> docker-entrypoint.sh /</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$FLINK_HOME</span>/usrlib</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./xxxxx.jar <span class="hljs-variable">$FLINK_HOME</span>/usrlib/</span><br></code></pre></td></tr></table></figure><h2 id="docker-entrypoint-sh"><a href="#docker-entrypoint-sh" class="headerlink" title="docker-entrypoint.sh"></a>docker-entrypoint.sh</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/usr/bin/env bash</span><br><br><span class="hljs-comment">###############################################################################</span><br><span class="hljs-comment">#  Licensed to the Apache Software Foundation (ASF) under one</span><br><span class="hljs-comment">#  or more contributor license agreements.  See the NOTICE file</span><br><span class="hljs-comment">#  distributed with this work for additional information</span><br><span class="hljs-comment">#  regarding copyright ownership.  The ASF licenses this file</span><br><span class="hljs-comment">#  to you under the Apache License, Version 2.0 (the</span><br><span class="hljs-comment">#  &quot;License&quot;); you may not use this file except in compliance</span><br><span class="hljs-comment">#  with the License.  You may obtain a copy of the License at</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#      http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">#  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">#  See the License for the specific language governing permissions and</span><br><span class="hljs-comment"># limitations under the License.</span><br><span class="hljs-comment">###############################################################################</span><br><br><span class="hljs-comment">###################### minio mount start#####################</span><br>AWS_S3_ACCESS_KEY_ID=<span class="hljs-variable">$&#123;AWS_S3_ACCESS_KEY_ID:-&quot;&quot;&#125;</span><br>AWS_S3_SECRET_ACCESS_KEY=<span class="hljs-variable">$&#123;AWS_S3_SECRET_ACCESS_KEY:-&quot;&quot;&#125;</span><br>AWS_S3_ROOT_DIR=<span class="hljs-variable">$&#123;AWS_S3_ROOT_DIR:-&quot;/&quot;&#125;</span><br>AWS_S3_AUTH_FILE=<span class="hljs-variable">$&#123;AWS_S3_ROOTDIR&#125;</span>/passwd-s3fs<br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;AWS_S3_ACCESS_KEY_ID&#125;</span>:<span class="hljs-variable">$&#123;AWS_S3_SECRET_ACCESS_KEY&#125;</span>&quot;</span> &gt; <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;AWS_S3_AUTH_FILE&#125;</span>&quot;</span><br><br><span class="hljs-built_in">chmod</span> 600 <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;AWS_S3_AUTH_FILE&#125;</span>&quot;</span><br><span class="hljs-comment">#cat $&#123;AWS_S3_AUTH_FILE&#125;</span><br><span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">&quot;<span class="hljs-variable">$AWS_S3_MOUNT</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">mkdir</span> -p <span class="hljs-string">&quot;<span class="hljs-variable">$AWS_S3_MOUNT</span>&quot;</span><br><span class="hljs-keyword">fi</span><br><br><span class="hljs-keyword">if</span> [[ <span class="hljs-variable">$AWS_S3_ACCESS_KEY_ID</span> != <span class="hljs-string">&#x27;&#x27;</span> ]];<span class="hljs-keyword">then</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-------------minio info---------------------&quot;</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;AWS_S3_ACCESS_KEY_ID=<span class="hljs-variable">$&#123;AWS_S3_ACCESS_KEY_ID&#125;</span>,AWS_S3_SECRET_ACCESS_KEY=<span class="hljs-variable">$&#123;AWS_S3_SECRET_ACCESS_KEY&#125;</span>,AWS_S3_BUCKET=<span class="hljs-variable">$&#123;AWS_S3_BUCKET&#125;</span>,AWS_S3_MOUNT=<span class="hljs-variable">$&#123;AWS_S3_MOUNT&#125;</span>,AWS_S3_URL=<span class="hljs-variable">$&#123;AWS_S3_URL&#125;</span>&quot;</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;--------------------------------------------&quot;</span><br>  <span class="hljs-comment"># s3fs -o passwd_file=/root/.passwd-s3fs -o url=$&#123;MINIO_URL&#125; -o allow_other -o nonempty -o no_check_certificate -o use_path_request_style -o umask=000 $&#123;MINIO_VOLUME&#125; $&#123;MOUNT_PATH&#125;</span><br>  mount_cmd=<span class="hljs-string">&quot;s3fs -o <span class="hljs-variable">$&#123;S3FS_ARGS&#125;</span> -o passwd_file=<span class="hljs-variable">$&#123;AWS_S3_AUTH_FILE&#125;</span> -o url=<span class="hljs-variable">$&#123;AWS_S3_URL&#125;</span> <span class="hljs-variable">$&#123;AWS_S3_BUCKET&#125;</span> <span class="hljs-variable">$&#123;AWS_S3_MOUNT&#125;</span>&quot;</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;mount_cmd=[<span class="hljs-variable">$&#123;mount_cmd&#125;</span>]&quot;</span><br>  <span class="hljs-built_in">which</span> s3fs<br>  <span class="hljs-keyword">if</span> [[ $? != <span class="hljs-string">&#x27;0&#x27;</span> ]];<span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;need first install s3fs,install cmd: apt-get update;  apt-get install -y s3fs&quot;</span><br>  <span class="hljs-keyword">fi</span><br>  <span class="hljs-built_in">eval</span> <span class="hljs-variable">$mount_cmd</span><br>  <span class="hljs-keyword">if</span> [[ $? == <span class="hljs-string">&#x27;0&#x27;</span> ]];<span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;mount minio success&quot;</span><br>  <span class="hljs-keyword">else</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;mount minio fail...&quot;</span><br>    <span class="hljs-built_in">cat</span> <span class="hljs-variable">$&#123;AWS_S3_AUTH_FILE&#125;</span><br>  <span class="hljs-keyword">fi</span><br><span class="hljs-keyword">fi</span><br><span class="hljs-comment">##################### minio mount end###############################</span><br><span class="hljs-built_in">ls</span> -alh /opt/flink/lib<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;print origin lib dir end -----------&quot;</span><br><br><br>FLINK_EXTRA_LIBS=<span class="hljs-variable">$&#123;FLINK_EXTRA_LIBS:-&quot;&quot;&#125;</span><br><span class="hljs-keyword">if</span> [[ <span class="hljs-variable">$FLINK_EXTRA_LIBS</span> != <span class="hljs-string">&#x27;&#x27;</span> ]];<span class="hljs-keyword">then</span><br>   <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;copy flink extra libs to /opt/flink/lib&quot;</span><br>   <span class="hljs-built_in">cp</span> -rf <span class="hljs-variable">$&#123;FLINK_EXTRA_LIBS&#125;</span>/* /opt/flink/lib<br><span class="hljs-keyword">fi</span><br><br><span class="hljs-comment">### print flink lib dir #########</span><br><span class="hljs-built_in">ls</span> -alh /opt/flink/lib<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;print lib dir end -----------&quot;</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;----------list flink/conf------------&quot;</span><br><span class="hljs-built_in">ls</span> -alh /opt/flink/conf<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;----------list flink/conf--end------------&quot;</span><br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;FLINK_HOME=<span class="hljs-variable">$&#123;FLINK_HOME&#125;</span>&quot;</span><br><br>COMMAND_STANDALONE=<span class="hljs-string">&quot;standalone-job&quot;</span><br>COMMAND_HISTORY_SERVER=<span class="hljs-string">&quot;history-server&quot;</span><br><br><span class="hljs-comment"># If unspecified, the hostname of the container is taken as the JobManager address</span><br>JOB_MANAGER_RPC_ADDRESS=<span class="hljs-variable">$&#123;JOB_MANAGER_RPC_ADDRESS:-$(hostname -f)&#125;</span><br>CONF_FILE=<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_HOME&#125;</span>/conf/flink-conf.yaml&quot;</span><br><br><span class="hljs-built_in">chmod</span> 775 <span class="hljs-variable">$CONF_FILE</span><br>exec_chmod=`$?`<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;chmod ret-----------<span class="hljs-variable">$&#123;exec_chmod&#125;</span>&quot;</span><br><br>kerberos_principal=<span class="hljs-variable">$&#123;kerberos_principal:-&quot;&quot;&#125;</span><br>kerberos_keytab=<span class="hljs-variable">$&#123;kerberos_keytab:-&quot;&quot;&#125;</span><br>kerberos_krb5=<span class="hljs-variable">$&#123;kerberos_krb5:-&quot;&quot;&#125;</span><br><br><br><span class="hljs-keyword">if</span> [[ <span class="hljs-variable">$kerberos_krb5</span> != <span class="hljs-string">&#x27;&#x27;</span> ]];<span class="hljs-keyword">then</span><br>   <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;cp kerberos_krb5&quot;</span><br>   <span class="hljs-built_in">cp</span> <span class="hljs-variable">$kerberos_krb5</span> /etc/<br><span class="hljs-keyword">fi</span><br><br><span class="hljs-keyword">if</span> [[ <span class="hljs-variable">$kerberos_principal</span> != <span class="hljs-string">&#x27;&#x27;</span> ]];<span class="hljs-keyword">then</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;security.kerberos.login.use-ticket-cache: true&quot;</span> &gt;&gt; <span class="hljs-variable">$CONF_FILE</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;security.kerberos.login.contexts: Client&quot;</span> &gt;&gt; <span class="hljs-variable">$CONF_FILE</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;security.kerberos.login.keytab: <span class="hljs-variable">$&#123;kerberos_keytab&#125;</span>&quot;</span> &gt;&gt; <span class="hljs-variable">$CONF_FILE</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;security.kerberos.login.principal: <span class="hljs-variable">$&#123;kerberos_principal&#125;</span>&quot;</span> &gt;&gt; <span class="hljs-variable">$CONF_FILE</span><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;security.kerberos.krb5-conf.path: <span class="hljs-variable">$&#123;kerberos_krb5&#125;</span>&quot;</span> &gt;&gt; <span class="hljs-variable">$CONF_FILE</span><br><span class="hljs-keyword">fi</span><br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-----kerberos files ----------------&quot;</span><br><span class="hljs-built_in">ls</span> -al /opt/kerberos/<br><span class="hljs-built_in">ls</span> -al /opt/kerberos/kerberos_keytab/<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-----kerberos files ----------------end&quot;</span><br><br><span class="hljs-function"><span class="hljs-title">drop_privs_cmd</span></span>() &#123;<br>    <span class="hljs-keyword">if</span> [ $(<span class="hljs-built_in">id</span> -u) != 0 ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-comment"># Don&#x27;t need to drop privs if EUID != 0</span><br>        <span class="hljs-built_in">return</span><br>    <span class="hljs-keyword">elif</span> [ -x /sbin/su-exec ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-comment"># Alpine</span><br>        <span class="hljs-built_in">echo</span> su-exec flink<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-comment"># Others</span><br>        <span class="hljs-built_in">echo</span> gosu flink<br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-title">copy_plugins_if_required</span></span>() &#123;<br>  <span class="hljs-keyword">if</span> [ -z <span class="hljs-string">&quot;<span class="hljs-variable">$ENABLE_BUILT_IN_PLUGINS</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">return</span> 0<br>  <span class="hljs-keyword">fi</span><br><br>  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Enabling required built-in plugins&quot;</span><br>  <span class="hljs-keyword">for</span> target_plugin <span class="hljs-keyword">in</span> $(<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$ENABLE_BUILT_IN_PLUGINS</span>&quot;</span> | <span class="hljs-built_in">tr</span> <span class="hljs-string">&#x27;;&#x27;</span> <span class="hljs-string">&#x27; &#x27;</span>); <span class="hljs-keyword">do</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Linking <span class="hljs-variable">$&#123;target_plugin&#125;</span> to plugin directory&quot;</span><br>    plugin_name=<span class="hljs-variable">$&#123;target_plugin%.jar&#125;</span><br><br>    <span class="hljs-built_in">mkdir</span> -p <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_HOME&#125;</span>/plugins/<span class="hljs-variable">$&#123;plugin_name&#125;</span>&quot;</span><br>    <span class="hljs-keyword">if</span> [ ! -e <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_HOME&#125;</span>/opt/<span class="hljs-variable">$&#123;target_plugin&#125;</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>      <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Plugin <span class="hljs-variable">$&#123;target_plugin&#125;</span> does not exist. Exiting.&quot;</span><br>      <span class="hljs-built_in">exit</span> 1<br>    <span class="hljs-keyword">else</span><br>      <span class="hljs-built_in">ln</span> -fs <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_HOME&#125;</span>/opt/<span class="hljs-variable">$&#123;target_plugin&#125;</span>&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_HOME&#125;</span>/plugins/<span class="hljs-variable">$&#123;plugin_name&#125;</span>&quot;</span><br>      <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Successfully enabled <span class="hljs-variable">$&#123;target_plugin&#125;</span>&quot;</span><br>    <span class="hljs-keyword">fi</span><br>  <span class="hljs-keyword">done</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">set_config_option</span></span>() &#123;<br>  <span class="hljs-built_in">local</span> option=<span class="hljs-variable">$1</span><br>  <span class="hljs-built_in">local</span> value=<span class="hljs-variable">$2</span><br><br>  <span class="hljs-comment"># escape periods for usage in regular expressions</span><br>  <span class="hljs-built_in">local</span> escaped_option=$(<span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;option&#125;</span> | sed -e <span class="hljs-string">&quot;s/\./\\\./g&quot;</span>)<br><br>  <span class="hljs-comment"># either override an existing entry, or append a new one</span><br>  <span class="hljs-keyword">if</span> grep -E <span class="hljs-string">&quot;^<span class="hljs-variable">$&#123;escaped_option&#125;</span>:.*&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>&quot;</span> &gt; /dev/null; <span class="hljs-keyword">then</span><br>        sed -i -e <span class="hljs-string">&quot;s/<span class="hljs-variable">$&#123;escaped_option&#125;</span>:.*/<span class="hljs-variable">$option</span>: <span class="hljs-variable">$value</span>/g&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>&quot;</span><br>  <span class="hljs-keyword">else</span><br>        <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;option&#125;</span>: <span class="hljs-variable">$&#123;value&#125;</span>&quot;</span> &gt;&gt; <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>&quot;</span><br>  <span class="hljs-keyword">fi</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">prepare_configuration</span></span>() &#123;<br>    set_config_option jobmanager.rpc.address <span class="hljs-variable">$&#123;JOB_MANAGER_RPC_ADDRESS&#125;</span><br>    set_config_option blob.server.port 6124<br>    set_config_option query.server.port 6125<br><br>    <span class="hljs-keyword">if</span> [ -n <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;TASK_MANAGER_NUMBER_OF_TASK_SLOTS&#125;</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>        set_config_option taskmanager.numberOfTaskSlots <span class="hljs-variable">$&#123;TASK_MANAGER_NUMBER_OF_TASK_SLOTS&#125;</span><br>    <span class="hljs-keyword">fi</span><br><br>    <span class="hljs-keyword">if</span> [ -n <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_PROPERTIES&#125;</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;FLINK_PROPERTIES&#125;</span>&quot;</span> &gt;&gt; <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>&quot;</span><br>    <span class="hljs-keyword">fi</span><br>    envsubst &lt; <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>&quot;</span> &gt; <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>.tmp&quot;</span> &amp;&amp; <span class="hljs-built_in">mv</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>.tmp&quot;</span> <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;CONF_FILE&#125;</span>&quot;</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-title">maybe_enable_jemalloc</span></span>() &#123;<br>    <span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;DISABLE_JEMALLOC:-false&#125;</span>&quot;</span> == <span class="hljs-string">&quot;false&quot;</span> ]; <span class="hljs-keyword">then</span><br>        JEMALLOC_PATH=<span class="hljs-string">&quot;/usr/lib/<span class="hljs-subst">$(uname -m)</span>-linux-gnu/libjemalloc.so&quot;</span><br>        JEMALLOC_FALLBACK=<span class="hljs-string">&quot;/usr/lib/x86_64-linux-gnu/libjemalloc.so&quot;</span><br>        <span class="hljs-keyword">if</span> [ -f <span class="hljs-string">&quot;<span class="hljs-variable">$JEMALLOC_PATH</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>            <span class="hljs-built_in">export</span> LD_PRELOAD=<span class="hljs-variable">$LD_PRELOAD</span>:<span class="hljs-variable">$JEMALLOC_PATH</span><br>        <span class="hljs-keyword">elif</span> [ -f <span class="hljs-string">&quot;<span class="hljs-variable">$JEMALLOC_FALLBACK</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>            <span class="hljs-built_in">export</span> LD_PRELOAD=<span class="hljs-variable">$LD_PRELOAD</span>:<span class="hljs-variable">$JEMALLOC_FALLBACK</span><br>        <span class="hljs-keyword">else</span><br>            <span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$JEMALLOC_PATH</span>&quot;</span> = <span class="hljs-string">&quot;<span class="hljs-variable">$JEMALLOC_FALLBACK</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>                MSG_PATH=<span class="hljs-variable">$JEMALLOC_PATH</span><br>            <span class="hljs-keyword">else</span><br>                MSG_PATH=<span class="hljs-string">&quot;<span class="hljs-variable">$JEMALLOC_PATH</span> and <span class="hljs-variable">$JEMALLOC_FALLBACK</span>&quot;</span><br>            <span class="hljs-keyword">fi</span><br>            <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;WARNING: attempted to load jemalloc from <span class="hljs-variable">$MSG_PATH</span> but the library couldn&#x27;t be found. glibc will be used instead.&quot;</span><br>        <span class="hljs-keyword">fi</span><br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br>maybe_enable_jemalloc<br><br>copy_plugins_if_required<br><br>prepare_configuration<br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;------------print flink-conf.yaml--------------------&quot;</span><br><span class="hljs-built_in">cat</span> <span class="hljs-variable">$CONF_FILE</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;------------print flink-conf.yaml---end--------------&quot;</span><br><br>args=(<span class="hljs-string">&quot;<span class="hljs-variable">$@</span>&quot;</span>)<br><span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;help&quot;</span> ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;Usage: <span class="hljs-subst">$(basename <span class="hljs-string">&quot;<span class="hljs-variable">$0</span>&quot;</span>)</span> (jobmanager|<span class="hljs-variable">$&#123;COMMAND_STANDALONE&#125;</span>|taskmanager|<span class="hljs-variable">$&#123;COMMAND_HISTORY_SERVER&#125;</span>)\n&quot;</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;    Or <span class="hljs-subst">$(basename <span class="hljs-string">&quot;<span class="hljs-variable">$0</span>&quot;</span>)</span> help\n\n&quot;</span><br>    <span class="hljs-built_in">printf</span> <span class="hljs-string">&quot;By default, Flink image adopts jemalloc as default memory allocator. This behavior can be disabled by setting the &#x27;DISABLE_JEMALLOC&#x27; environment variable to &#x27;true&#x27;.\n&quot;</span><br>    <span class="hljs-built_in">exit</span> 0<br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;jobmanager&quot;</span> ]; <span class="hljs-keyword">then</span><br>    args=(<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]:1&#125;</span>&quot;</span>)<br><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Starting Job Manager&quot;</span><br><br>    <span class="hljs-built_in">exec</span> $(drop_privs_cmd) <span class="hljs-string">&quot;<span class="hljs-variable">$FLINK_HOME</span>/bin/jobmanager.sh&quot;</span> start-foreground <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]&#125;</span>&quot;</span><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-variable">$&#123;COMMAND_STANDALONE&#125;</span> ]; <span class="hljs-keyword">then</span><br>    args=(<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]:1&#125;</span>&quot;</span>)<br><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Starting Job Manager&quot;</span><br><br>    <span class="hljs-built_in">exec</span> $(drop_privs_cmd) <span class="hljs-string">&quot;<span class="hljs-variable">$FLINK_HOME</span>/bin/standalone-job.sh&quot;</span> start-foreground <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]&#125;</span>&quot;</span><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-variable">$&#123;COMMAND_HISTORY_SERVER&#125;</span> ]; <span class="hljs-keyword">then</span><br>    args=(<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]:1&#125;</span>&quot;</span>)<br><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Starting History Server&quot;</span><br><br>    <span class="hljs-built_in">exec</span> $(drop_privs_cmd) <span class="hljs-string">&quot;<span class="hljs-variable">$FLINK_HOME</span>/bin/historyserver.sh&quot;</span> start-foreground <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]&#125;</span>&quot;</span><br><span class="hljs-keyword">elif</span> [ <span class="hljs-string">&quot;<span class="hljs-variable">$1</span>&quot;</span> = <span class="hljs-string">&quot;taskmanager&quot;</span> ]; <span class="hljs-keyword">then</span><br>    args=(<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]:1&#125;</span>&quot;</span>)<br><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Starting Task Manager&quot;</span><br><br>    <span class="hljs-built_in">exec</span> $(drop_privs_cmd) <span class="hljs-string">&quot;<span class="hljs-variable">$FLINK_HOME</span>/bin/taskmanager.sh&quot;</span> start-foreground <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]&#125;</span>&quot;</span><br><span class="hljs-keyword">fi</span><br><br>args=(<span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># Running command in pass-through mode</span><br><span class="hljs-built_in">exec</span> $(drop_privs_cmd) <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;args[@]&#125;</span>&quot;</span><br><br></code></pre></td></tr></table></figure><h2 id="pod-template-yaml"><a href="#pod-template-yaml" class="headerlink" title="pod-template.yaml"></a>pod-template.yaml</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">jobmanager-pod-template</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">flink-main-container</span><br>      <span class="hljs-attr">image:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.12</span><span class="hljs-number">.101</span><span class="hljs-string">/dev/flink1.14.5-base:latest</span><br>      <span class="hljs-attr">securityContext:</span><br>        <span class="hljs-attr">privileged:</span> <span class="hljs-literal">true</span><br>      <span class="hljs-attr">env:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">AWS_S3_BUCKET</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;kt-volume&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">S3FS_ARGS</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;use_path_request_style,allow_other,no_check_certificate,umask=000,nonempty&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">AWS_S3_ACCESS_KEY_ID</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;admin&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">AWS_S3_SECRET_ACCESS_KEY</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;admin123&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">AWS_S3_MOUNT</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;/mnt/kt-volume&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">AWS_S3_URL</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;http://192.168.12.178:9000&quot;</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">TZ</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">Asia/Shanghai</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">FLINK_LIBS</span><br>          <span class="hljs-attr">value:</span> <span class="hljs-string">Asia/Shanghai</span><br><br></code></pre></td></tr></table></figure><h1 id="Deploy-Flink-APP"><a href="#Deploy-Flink-APP" class="headerlink" title="Deploy Flink-APP"></a>Deploy Flink-APP</h1><p>submit cmd</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">export</span> FLINK_CONF_DIR=/opt/flink-1.14.5/conf;<br>/opt/flink-1.14.5/bin/flink run-application \<br>--target kubernetes-application \<br>-Dkubernetes.cluster-id=app-001 \<br>-Dkubernetes.container.image=192.168.1.110/dev/flink1.14.5-base:latest \<br>-Dkubernetes.container.image.pull-policy=Always \<br>-Dkubernetes.pod-template-file=/opt/flink-1.14.5/pod-template.yml \<br>-Dkubernetes.namespace=rts \<br>-Dkubernetes.config.file=/mnt/kt-volume/resource/rts/k8s/conf/config \<br>-Dkubernetes.rest-service.exposed.type=NodePort \<br>-Dcontainerized.master.env.HADOOP_CLASSPATH=/opt/hadoop/hdfs-conf:/opt/flink-1.14.5/conf/flink-conf.yaml:/opt/flink-1.14.5/conf/log4j2.xml \<br>-Dcontainerized.master.env.kerberos_krb5=/opt/hadoop/hdfs-conf/krb5.conf \<br>-Dcontainerized.taskmanager.env.HADOOP_CLASSPATH=/opt/hadoop/hdfs-conf:/opt/flink-1.14.5/conf/flink-conf.yaml:/opt/flink-1.14.5/conf/log4j2.xml \<br>-Dcontainerized.taskmanager.env.kerberos_krb5=/opt/hadoop/hdfs-conf/krb5.conf \<br>-Dclassloader.resolve-order=parent-first \<br>-Dsecurity.kerberos.login.principal=hive/cdh-100@KEENDATA.COM \<br>-Dsecurity.kerberos.login.use-ticket-cache=<span class="hljs-literal">true</span> \<br>-Dsecurity.kerberos.login.keytab=/opt/hadoop/hdfs-conf/hive100.keytab \<br>-D<span class="hljs-string">&#x27;$internal.pipeline.job-id&#x27;</span>=629ff7a21c24f10998f66e46d63bc2d3 \<br>-c com.keendata.rts.SyncSink \<br><span class="hljs-built_in">local</span>:///mnt/kt-volume/resource/rts/rts-sink-2.3-SNAPSHOT.jar -job /mnt/kt-volume/resource/temp/tmpjson/kafka_hive_iceberg.json \<br>-taskId 1669239192347009000 -mode INITIAL -jobName kafka_hive_iceberg \<br>-principal hive/cdh-100@KEENDATA.COM -keytabPath /opt/hadoop/hdfs-conf/hive100.keytab \<br>-krb5Conf /opt/hadoop/hdfs-conf/krb5.conf -useLocalFile <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mysql-Flink-Hudi数据同步</title>
      <link href="/flink/Mysql-Flink-Hudi%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
      <url>/flink/Mysql-Flink-Hudi%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="Mysql-Flink-Hudi数据同步"><a href="#Mysql-Flink-Hudi数据同步" class="headerlink" title="Mysql-Flink-Hudi数据同步"></a>Mysql-Flink-Hudi数据同步</h1><p>使用Flink-Cdc同步mysql数据到Hudi中.使用Kafka作为中间缓存组件.</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ol><li><p>开启MySQL-binglog日志</p></li><li><p>编译好相关hudi版本,本次使用Hudi:0.12.3</p></li><li><p>其他软件版本:</p><p> flink:1.15.4</p><p> Java:1.8</p><p> hadoop: 3.3.0</p></li></ol><h1 id="同步数据操作"><a href="#同步数据操作" class="headerlink" title="同步数据操作"></a>同步数据操作</h1><h2 id="1-启动Flink-Yarn-Session"><a href="#1-启动Flink-Yarn-Session" class="headerlink" title="1.启动Flink-Yarn-Session"></a>1.启动Flink-Yarn-Session</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/yarn-session -d<br></code></pre></td></tr></table></figure><h2 id="2-启动Flink-Sq客户端"><a href="#2-启动Flink-Sq客户端" class="headerlink" title="2.启动Flink-Sq客户端."></a>2.启动Flink-Sq客户端.</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/sql-client.sh embedded -s yarn-session<br></code></pre></td></tr></table></figure><h2 id="3-创建cdc-mysql连接器"><a href="#3-创建cdc-mysql连接器" class="headerlink" title="3.创建cdc-mysql连接器."></a>3.创建cdc-mysql连接器.</h2><p>在flink-sql中创建.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  school string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string,<br>  <span class="hljs-keyword">primary</span> key (id) <span class="hljs-keyword">not</span> enforced<br>) <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;mysql-cdc&#x27;</span>,<br>  <span class="hljs-string">&#x27;hostname&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd000&#x27;</span>,<br>  <span class="hljs-string">&#x27;port&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;3306&#x27;</span>,<br>  <span class="hljs-string">&#x27;username&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;root&#x27;</span>,<br>  <span class="hljs-string">&#x27;password&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;root&#x27;</span>,<br>  <span class="hljs-string">&#x27;database-name&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test&#x27;</span>,<br>  <span class="hljs-string">&#x27;table-name&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;stu3&#x27;</span><br>);<br><br><span class="hljs-keyword">set</span> <span class="hljs-keyword">sql</span><span class="hljs-operator">-</span>client.execution.result<span class="hljs-operator">-</span>mode<span class="hljs-operator">=</span>tableau; <br></code></pre></td></tr></table></figure><h2 id="4-创建Kafka表"><a href="#4-创建Kafka表" class="headerlink" title="4.创建Kafka表"></a>4.创建Kafka表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog_sink_kafka(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  school string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string,<br>  <span class="hljs-keyword">primary</span> key (id) <span class="hljs-keyword">not</span> enforced<br>) <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;upsert-kafka&#x27;</span><br>  ,<span class="hljs-string">&#x27;topic&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;cdc_mysql_stu3_sink&#x27;</span><br>  ,<span class="hljs-string">&#x27;properties.zookeeper.connect&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd001:2181,hd002:2181,hd003:2181&#x27;</span><br>  ,<span class="hljs-string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd001:9092,hd003:9092,hd002:9092&#x27;</span><br>  ,<span class="hljs-string">&#x27;key.format&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;json&#x27;</span><br>  ,<span class="hljs-string">&#x27;value.format&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;json&#x27;</span><br>);<br></code></pre></td></tr></table></figure><h2 id="5-将mysql-binlog日志写入kafka"><a href="#5-将mysql-binlog日志写入kafka" class="headerlink" title="5.将mysql binlog日志写入kafka"></a>5.将mysql binlog日志写入kafka</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> stu3_binlog_sink_kafka<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> stu3_binlog;<br></code></pre></td></tr></table></figure><h2 id="6-创建kafka源表"><a href="#6-创建kafka源表" class="headerlink" title="6.创建kafka源表"></a>6.创建kafka源表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog_source_kafka(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  school string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string<br> ) <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;kafka&#x27;</span>,<br>  <span class="hljs-string">&#x27;topic&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;cdc_mysql_stu3_sink&#x27;</span>,<br>  <span class="hljs-string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd001:9092,hd003:9092,hd002:9092&#x27;</span>,<br>  <span class="hljs-string">&#x27;format&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;json&#x27;</span>,<br>  <span class="hljs-string">&#x27;scan.startup.mode&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;earliest-offset&#x27;</span>,<br>  <span class="hljs-string">&#x27;properties.group.id&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;testGroup&#x27;</span><br>  );<br></code></pre></td></tr></table></figure><h2 id="7-创建hudi目标表"><a href="#7-创建hudi目标表" class="headerlink" title="7.创建hudi目标表"></a>7.创建hudi目标表</h2>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs sql"> <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog_sink_hudi(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  `school` string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string,<br>  <span class="hljs-keyword">primary</span> key (id) <span class="hljs-keyword">not</span> enforced<br>)<br> partitioned <span class="hljs-keyword">by</span> (`school`)<br> <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hudi&#x27;</span>,<br>  <span class="hljs-string">&#x27;path&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hdfs:///tmp/hudi_flink/stu3_binlog_sink_hudi&#x27;</span>,<br>  <span class="hljs-string">&#x27;table.type&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;MERGE_ON_READ&#x27;</span>,<br>  <span class="hljs-string">&#x27;write.option&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;insert&#x27;</span>,<br>  <span class="hljs-string">&#x27;write.precombine.field&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;school&#x27;</span><br>  );<br></code></pre></td></tr></table></figure><h2 id="8-将kafka数据写入到hudi中"><a href="#8-将kafka数据写入到hudi中" class="headerlink" title="8.将kafka数据写入到hudi中"></a>8.将kafka数据写入到hudi中</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> stu3_binlog_sink_hudi<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span>  stu3_binlog_source_kafka;<br></code></pre></td></tr></table></figure><h1 id="使用sql文件形式进行同步"><a href="#使用sql文件形式进行同步" class="headerlink" title="使用sql文件形式进行同步"></a>使用sql文件形式进行同步</h1><h2 id="定义flink-sql文件"><a href="#定义flink-sql文件" class="headerlink" title="定义flink_sql文件"></a>定义flink_sql文件</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs sql"><br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  school string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string,<br>  <span class="hljs-keyword">primary</span> key (id) <span class="hljs-keyword">not</span> enforced<br>) <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;mysql-cdc&#x27;</span>,<br>  <span class="hljs-string">&#x27;hostname&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd000&#x27;</span>,<br>  <span class="hljs-string">&#x27;port&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;3306&#x27;</span>,<br>  <span class="hljs-string">&#x27;username&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;root&#x27;</span>,<br>  <span class="hljs-string">&#x27;password&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;root&#x27;</span>,<br>  <span class="hljs-string">&#x27;database-name&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;test&#x27;</span>,<br>  <span class="hljs-string">&#x27;table-name&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;stu3&#x27;</span><br>);<br><br><br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog_sink_kafka(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  school string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string,<br>  <span class="hljs-keyword">primary</span> key (id) <span class="hljs-keyword">not</span> enforced<br>) <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;upsert-kafka&#x27;</span><br>  ,<span class="hljs-string">&#x27;topic&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;cdc_mysql_stu3_sink&#x27;</span><br>  ,<span class="hljs-string">&#x27;properties.zookeeper.connect&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd001:2181,hd002:2181,hd003:2181&#x27;</span><br>  ,<span class="hljs-string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd001:9092,hd003:9092,hd002:9092&#x27;</span><br>  ,<span class="hljs-string">&#x27;key.format&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;json&#x27;</span><br>  ,<span class="hljs-string">&#x27;value.format&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;json&#x27;</span><br>);<br><br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> stu3_binlog_sink_kafka<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> stu3_binlog;<br><br><br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog_source_kafka(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  school string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string<br> ) <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;kafka&#x27;</span>,<br>  <span class="hljs-string">&#x27;topic&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;cdc_mysql_stu3_sink&#x27;</span>,<br>  <span class="hljs-string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hd001:9092,hd003:9092,hd002:9092&#x27;</span>,<br>  <span class="hljs-string">&#x27;format&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;json&#x27;</span>,<br>  <span class="hljs-string">&#x27;scan.startup.mode&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;earliest-offset&#x27;</span>,<br>  <span class="hljs-string">&#x27;properties.group.id&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;testGroup&#x27;</span><br>  );<br><br><br> <span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3_binlog_sink_hudi(<br>  id <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  name string,<br>  `school` string,<br>  nickname string,<br>  age <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  class_num <span class="hljs-type">int</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  phone <span class="hljs-type">bigint</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span>,<br>  email string,<br>  ip string,<br>  <span class="hljs-keyword">primary</span> key (id) <span class="hljs-keyword">not</span> enforced<br>)<br> partitioned <span class="hljs-keyword">by</span> (`school`)<br> <span class="hljs-keyword">with</span> (<br>  <span class="hljs-string">&#x27;connector&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hudi&#x27;</span>,<br>  <span class="hljs-string">&#x27;path&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;hdfs:///tmp/hudi_flink/stu3_binlog_sink_hudi&#x27;</span>,<br>  <span class="hljs-string">&#x27;table.type&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;MERGE_ON_READ&#x27;</span>,<br>  <span class="hljs-string">&#x27;write.option&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;insert&#x27;</span>,<br>  <span class="hljs-string">&#x27;write.precombine.field&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;school&#x27;</span>,<br>  <span class="hljs-string">&#x27;read.streaming.enabled&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;true&#x27;</span>,<br>  <span class="hljs-string">&#x27;read.streaming.check-interval&#x27;</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;10&#x27;</span><br>  );<br><br><br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> stu3_binlog_sink_hudi<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span>  stu3_binlog_source_kafka;<br></code></pre></td></tr></table></figure><h2 id="执行sql文件"><a href="#执行sql文件" class="headerlink" title="执行sql文件"></a>执行sql文件</h2><p>前提需启动yarn-session</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/sql-client.sh embedded -s yarn-session -f sqls/xxxx.sql<br></code></pre></td></tr></table></figure><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul><li>flink-conf.yml配置</li></ul><p>开启flink-cps, 并设置有效一次消费.</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-comment"># execution.checkpointing.interval: 3min</span><br><span class="hljs-attr">execution.checkpointing.interval:</span> <span class="hljs-string">10000ms</span><br><span class="hljs-comment"># execution.checkpointing.externalized-checkpoint-retention: [DELETE_ON_CANCELLATION, RETAIN_ON_CANCELLATION]</span><br><span class="hljs-comment"># execution.checkpointing.max-concurrent-checkpoints: 1</span><br><span class="hljs-attr">execution.checkpointing.max-concurrent-checkpoints:</span> <span class="hljs-number">1</span><br><span class="hljs-comment"># execution.checkpointing.min-pause: 0</span><br><span class="hljs-comment"># execution.checkpointing.mode: [EXACTLY_ONCE, AT_LEAST_ONCE]</span><br><span class="hljs-attr">execution.checkpointing.mode:</span> <span class="hljs-string">EXACTLY_ONCE</span><br><span class="hljs-comment"># execution.checkpointing.timeout: 10min</span><br><span class="hljs-comment"># execution.checkpointing.tolerable-failed-checkpoints: 0</span><br><span class="hljs-comment"># execution.checkpointing.unaligned: false</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Supported backends are &#x27;hashmap&#x27;, &#x27;rocksdb&#x27;, or the</span><br><span class="hljs-comment"># &lt;class-name-of-factory&gt;.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># state.backend: hashmap</span><br><span class="hljs-attr">state.backend:</span> <span class="hljs-string">rocksdb</span><br><br><span class="hljs-comment"># Directory for checkpoints filesystem, when using any of the default bundled</span><br><span class="hljs-comment"># state backends.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># state.checkpoints.dir: hdfs://namenode-host:port/flink-checkpoints</span><br><span class="hljs-attr">state.checkpoints.dir:</span> <span class="hljs-string">hdfs:///flink/checkpoints</span><br><br><span class="hljs-comment"># Default target directory for savepoints, optional.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># state.savepoints.dir: hdfs://namenode-host:port/flink-savepoints</span><br><span class="hljs-attr">state.savepoints.dir:</span> <span class="hljs-string">hdfs:///flink/savepoints</span><br><br><span class="hljs-comment"># Flag to enable/disable incremental checkpoints for backends that</span><br><span class="hljs-comment"># support incremental checkpoints (like the RocksDB state backend). </span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># state.backend.incremental: false</span><br><span class="hljs-attr">state.backend.incremental:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><ul><li>配置启动所需的环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">vim bin/config.sh<br><span class="hljs-built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`<br><br>vim /ect/profile.d/my_env.sh<br><span class="hljs-built_in">export</span> HADOOP_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop<br><span class="hljs-built_in">export</span> YARN_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop<br></code></pre></td></tr></table></figure></li></ul><p>&#x2F;etc&#x2F;profil.d&#x2F;my_env.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-8-openjdk-arm64<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin<br><br><span class="hljs-built_in">export</span> HADOOP_HOME=/opt/ha/hadoop-3.3.0<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/bin<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/sbin<br><br><span class="hljs-built_in">export</span> ZK_HOME=/opt/zk/zookeeper<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$ZK_HOME</span>/bin<br><br><span class="hljs-built_in">export</span> HIVE_HOME=/opt/hive/hive3.1.3<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HIVE_HOME</span>/bin<br><br><span class="hljs-built_in">export</span> HADOOP_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop<br><span class="hljs-built_in">export</span> YARN_CONF_DIR=<span class="hljs-variable">$HADOOP_HOME</span>/etc/hadoop<br><br><span class="hljs-built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`<br></code></pre></td></tr></table></figure><ul><li><p>启动yarn-session,及提交sql</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 启动yarn-session</span><br>./bin/yarn-session.sh -jm 2048M -yn <span class="hljs-string">&quot;flink-hudi&quot;</span> -d<br><br><span class="hljs-comment"># 通过文件形式提交sql到yarn-session中.</span><br>./bin/sql-client.sh embedded -s yarn-session -f sqls/xxxx.sql<br></code></pre></td></tr></table></figure></li><li><p>MySQL开启binlog</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs conf">cat my.cnf<br>#设置日志三种格式：STATEMENT、ROW、MIXED 。<br>binlog_format = ROW<br>#设置日志路径，注意路经需要mysql用户有权限写<br>log-bin = /var/lib/mysql/mysql-bin<br>#设置binlog清理时间<br>expire_logs_days = 15<br>#binlog每个日志文件大小<br>max_binlog_size = 200m<br>#binlog缓存大小<br>binlog_cache_size = 4m<br>#最大binlog缓存大小<br>max_binlog_cache_size = 512m<br><br>server-id=1<br><br>default-time_zone = &#x27;+8:00&#x27;<br></code></pre></td></tr></table></figure></li><li><p>使用工具批量插入数据到mysql</p><p>  <a href="https://developer.aliyun.com/article/852227">https://developer.aliyun.com/article/852227</a></p>  <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs txt">id||int||自增id[:inc(id,30000)]<br>name||varchar(20)||学生名字<br>school||varchar(20)||学校名字[:enum(qinghua,beida,shanghaijiaoda,fudan,xidian,zhongda)]<br>nickname||varchar(20)||学生小名[:enum(tom,tony,mick,rich,jasper)]<br>age||int||学生年龄[:age]<br>class_num||int||班级人数[:int(10, 100)]<br>phone||bigint||电话号码[:phone_number]<br>email||varchar(64)||家庭网络邮箱[:email]<br>ip||varchar(32)||IP地址[:ipv4]<br></code></pre></td></tr></table></figure>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- auto-generated definition</span><br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3<br>(<br>    id        <span class="hljs-type">int</span> unsigned auto_increment comment <span class="hljs-string">&#x27;自增id&#x27;</span><br>        <span class="hljs-keyword">primary</span> key,<br>    name      <span class="hljs-type">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;学生名字&#x27;</span>,<br>    school    <span class="hljs-type">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;学校名字&#x27;</span>,<br>    nickname  <span class="hljs-type">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;学生小名&#x27;</span>,<br>    age       <span class="hljs-type">int</span>         <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;学生年龄&#x27;</span>,<br>    class_num <span class="hljs-type">int</span>         <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;班级人数&#x27;</span>,<br>    phone     <span class="hljs-type">bigint</span>      <span class="hljs-keyword">not</span> <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;电话号码&#x27;</span>,<br>    email     <span class="hljs-type">varchar</span>(<span class="hljs-number">64</span>) <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;家庭网络邮箱&#x27;</span>,<br>    ip        <span class="hljs-type">varchar</span>(<span class="hljs-number">32</span>) <span class="hljs-keyword">null</span> comment <span class="hljs-string">&#x27;IP地址&#x27;</span><br>)<br>    charset <span class="hljs-operator">=</span> utf8mb3;<br><br><br></code></pre></td></tr></table></figure>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">datafaker rdb mysql+mysqldb://root:root@hd000:3306/test?charset=utf8 stu3 30000 --meta meta.txt<br></code></pre></td></tr></table></figure></li><li><p>hudi-hdfs目录最终效果</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs dfs -<span class="hljs-built_in">ls</span> -h /tmp/hudi_flink/stu3_binlog_sink_hudi<br><br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:52 /tmp/hudi_flink/stu3_binlog_sink_hudi/.hoodie<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:44 /tmp/hudi_flink/stu3_binlog_sink_hudi/beida<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:44 /tmp/hudi_flink/stu3_binlog_sink_hudi/fudan<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:44 /tmp/hudi_flink/stu3_binlog_sink_hudi/qinghua<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:44 /tmp/hudi_flink/stu3_binlog_sink_hudi/shanghaijiaoda<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:44 /tmp/hudi_flink/stu3_binlog_sink_hudi/xidian<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:44 /tmp/hudi_flink/stu3_binlog_sink_hudi/zhongda<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:43 /tmp/hudi_flink/stu3_binlog_sink_hudi/北京大学<br>drwxr-xr-x   - miao supergroup          0 2023-05-08 06:52 /tmp/hudi_flink/stu3_binlog_sink_hudi/清华<br></code></pre></td></tr></table></figure></li><li><p>Flink依赖jar包:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs bash">miao@hd001:/opt/flink/flink-1.15.4$ ll -ht lib/<br>total 317M<br>drwxr-xr-x 12 miao miao 4.0K May  8 06:19 ../<br>-rw-rw-r--  1 miao miao  22M May  4 11:12 flink-sql-connector-mysql-cdc-2.2.0.jar<br>drwxr-xr-x  2 miao miao 4.0K May  4 11:12 ./<br>-rw-rw-r--  1 miao miao 5.0M May  4 11:12 flink-sql-connector-kafka-1.15.4.jar<br>-rw-r--r--  1 miao miao 1.6M May  4 10:54 hadoop-mapreduce-client-core-3.3.0.jar<br>-rw-r--r--  1 miao miao 2.4M May  4 10:34 guava-20.0.jar<br>-rw-rw-r--  1 miao miao  91M May  4 10:14 hudi-flink1.15-bundle-0.12.3.jar<br>-rw-r--r--  1 miao miao 111M Mar  9 08:57 flink-dist-1.15.4.jar<br>-rw-r--r--  1 miao miao  35M Mar  9 08:55 flink-table-planner-loader-1.15.4.jar<br>-rw-r--r--  1 miao miao  15M Mar  9 08:55 flink-table-api-java-uber-1.15.4.jar<br>-rw-r--r--  1 miao miao  21M Mar  9 08:55 flink-scala_2.12-1.15.4.jar<br>-rw-r--r--  1 miao miao 172K Mar  9 08:51 flink-json-1.15.4.jar<br>-rw-r--r--  1 miao miao  93K Mar  9 08:49 flink-csv-1.15.4.jar<br>-rw-r--r--  1 miao miao 475K Mar  9 08:43 flink-connector-files-1.15.4.jar<br>-rw-r--r--  1 miao miao 2.9M Mar  9 08:42 flink-table-runtime-1.15.4.jar<br>-rw-r--r--  1 miao miao 190K Mar  9 08:41 flink-cep-1.15.4.jar<br>-rw-r--r--  1 miao miao  11M Feb  8  2022 flink-shaded-zookeeper-3.5.9.jar<br>-rw-r--r--  1 miao miao 204K Jan  4  2022 log4j-1.2-api-2.17.1.jar<br>-rw-r--r--  1 miao miao 295K Jan  4  2022 log4j-api-2.17.1.jar<br>-rw-r--r--  1 miao miao 1.8M Jan  4  2022 log4j-core-2.17.1.jar<br>-rw-r--r--  1 miao miao  24K Jan  4  2022 log4j-slf4j-impl-2.17.1.jar<br></code></pre></td></tr></table></figure><p>  需要新增jar包:</p>  <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs txt">flink-sql-connector-mysql-cdc-2.2.0.jar # 需要下载<br>flink-sql-connector-kafka-1.15.4.jar # 需要下载<br>hadoop-mapreduce-client-core-3.3.0.jar # 需从hadoop环境中copy<br>guava-20.0.jar # 解决冲突放入<br>hudi-flink1.15-bundle-0.12.3.jar # 需手动编译hudi得到<br></code></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> Hudi </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Flink </tag>
            
            <tag> Hudi </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vim插件管理工具使用</title>
      <link href="/linux/Vim%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86%E4%BD%BF%E7%94%A8/"/>
      <url>/linux/Vim%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Vim插件管理工具介绍"><a href="#Vim插件管理工具介绍" class="headerlink" title="Vim插件管理工具介绍"></a>Vim插件管理工具介绍</h1><p>vim插件管理工具主要用于对vim编辑器中自动提示，主题显示，代码补全各种插件的管理和更新。目前主流的插件管理工具有以下几种：</p><ol><li><p>vim-plug </p><p> 是一个轻量级且功能强大的插件管理器，易于设置和使用。配置和插件存放在一个目录中。</p></li><li><p>pathogen.vim</p><p> pathogen.vim 是最古老的 Vim 插件管理器之一。像大多数插件管理器一样，它将插件排列到单独的文件夹中。</p></li><li><p>Vundle</p><p> 受pathogen.vim启发，安装简便，github地址：<a href="https://github.com/VundleVim/Vundle.vim#quick-start">https://github.com/VundleVim/Vundle.vim#quick-start</a></p></li><li><p>dein.vim</p><p> 很现代的插件管理工具，是Vim&#x2F;Neovim 插件管理器</p></li><li><p>Volt</p><p> 速度很快的一个插件管理工具。</p></li><li><p>Vim8自带插件管理</p><p> 在 Vim 8 及更高版本上，Vim自带插件管理，需要插件复制到~&#x2F;.vim 指定目录下即可。</p></li></ol><h1 id="使用Vundle"><a href="#使用Vundle" class="headerlink" title="使用Vundle"></a>使用Vundle</h1><p>本文使用的是插件管理： Vundle. 在其github官网中的quickstart中已经可以满足基本使用了。<br><br><br>特点：安装简单, 插件安装方式多, 文档清晰.</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim<br></code></pre></td></tr></table></figure><h2 id="配置-x2F-vimrc"><a href="#配置-x2F-vimrc" class="headerlink" title="配置 ~&#x2F;.vimrc"></a>配置 ~&#x2F;.vimrc</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">set</span> nocompatible              <span class="hljs-comment">&quot; be iMproved, required</span><br><span class="hljs-keyword">filetype</span> off                  <span class="hljs-comment">&quot; required</span><br><br><span class="hljs-comment">&quot; set the runtime path to include Vundle and initialize</span><br><span class="hljs-keyword">set</span> rtp+=~/.<span class="hljs-keyword">vim</span>/bundle/Vundle.<span class="hljs-keyword">vim</span><br><span class="hljs-keyword">call</span> vundle#begin()<br><span class="hljs-comment">&quot; alternatively, pass a path where Vundle should install plugins</span><br><span class="hljs-comment">&quot;call vundle#begin(&#x27;~/some/path/here&#x27;)</span><br><br><span class="hljs-comment">&quot; let Vundle manage Vundle, required</span><br>Plugin <span class="hljs-string">&#x27;VundleVim/Vundle.vim&#x27;</span><br><br><span class="hljs-comment">&quot; 以下是Vundle支持的插件安装几种方式：</span><br><span class="hljs-comment">&quot; The following are examples of different formats supported.</span><br><span class="hljs-comment">&quot; Keep Plugin commands between vundle#begin/end.</span><br><span class="hljs-comment">&quot; plugin on GitHub repo ： 插件中github仓库中直接下载，只需要指定名称。</span><br>Plugin <span class="hljs-string">&#x27;tpope/vim-fugitive&#x27;</span><br><span class="hljs-comment">&quot; plugin from http://vim-scripts.org/vim/scripts.html</span><br><span class="hljs-comment">&quot; Plugin &#x27;L9&#x27;</span><br><span class="hljs-comment">&quot; Git plugin not hosted on GitHub ： 指定具体的git地址，从地址中下载插件。</span><br>Plugin <span class="hljs-string">&#x27;git://git.wincent.com/command-t.git&#x27;</span><br><span class="hljs-comment">&quot; git repos on your local machine (i.e. when working on your own plugin) ： 指定具体的插件所在本地系统路径。</span><br>Plugin <span class="hljs-string">&#x27;file:///home/gmarik/path/to/plugin&#x27;</span><br><span class="hljs-comment">&quot; The sparkup vim script is in a subdirectory of this repo called vim.</span><br><span class="hljs-comment">&quot; Pass the path to set the runtimepath properly. ： 从vim 的repo仓库中下载安装插件。</span><br>Plugin <span class="hljs-string">&#x27;rstacruz/sparkup&#x27;</span>, &#123;<span class="hljs-string">&#x27;rtp&#x27;</span>: <span class="hljs-string">&#x27;vim/&#x27;</span>&#125;<br><span class="hljs-comment">&quot; Install L9 and avoid a Naming conflict if you&#x27;ve already installed a</span><br><span class="hljs-comment">&quot; different version somewhere else.</span><br><span class="hljs-comment">&quot; Plugin &#x27;ascenator/L9&#x27;, &#123;&#x27;name&#x27;: &#x27;newL9&#x27;&#125;</span><br><br><span class="hljs-comment">&quot; All of your Plugins must be added before the following line</span><br><span class="hljs-keyword">call</span> vundle#end()            <span class="hljs-comment">&quot; required</span><br><span class="hljs-keyword">filetype</span> plugin <span class="hljs-built_in">indent</span> <span class="hljs-keyword">on</span>    <span class="hljs-comment">&quot; required</span><br><span class="hljs-comment">&quot; To ignore plugin indent changes, instead use:</span><br><span class="hljs-comment">&quot;filetype plugin on</span><br><span class="hljs-comment">&quot;</span><br><span class="hljs-comment">&quot; Brief help</span><br><span class="hljs-comment">&quot; :PluginList       - lists configured plugins</span><br><span class="hljs-comment">&quot; :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate</span><br><span class="hljs-comment">&quot; :PluginSearch foo - searches for foo; append `!` to refresh local cache</span><br><span class="hljs-comment">&quot; :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal</span><br><span class="hljs-comment">&quot;</span><br><span class="hljs-comment">&quot; see :h vundle for more details or wiki for FAQ</span><br><span class="hljs-comment">&quot; Put your non-Plugin stuff after this line</span><br></code></pre></td></tr></table></figure><p>至此Vundle安装完成.</p><h2 id="主题使用"><a href="#主题使用" class="headerlink" title="主题使用"></a>主题使用</h2><p>自己使用的主题：<a href="https://github.com/sonph/onehalf/tree/master/vim">onehalf</a><br>下载主题相关配色文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p ~/tmp/<br>git <span class="hljs-built_in">clone</span> https://github.com/sonph/onehalf.git ~/tmp/onehalf<br><span class="hljs-built_in">cd</span> ~/tmp/onehalf &amp;&amp; <span class="hljs-built_in">cp</span> -r vim/autoload ~/.vim/ &amp;&amp; <span class="hljs-built_in">cp</span> -r vim/colors ~/.vim/<br><br></code></pre></td></tr></table></figure><br>github中提供的是vim-plug管理器安装方式，使用Vundle安装只需要修改前缀即可。<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-comment">&quot; vim主题，自动识别文本显示高亮等。</span><br>Plugin <span class="hljs-string">&#x27;sonph/onehalf&#x27;</span>, &#123; <span class="hljs-string">&#x27;rtp&#x27;</span>: <span class="hljs-string">&#x27;vim&#x27;</span> &#125;<br><br><span class="hljs-comment">&quot; vim状态栏目主题：</span><br>Plugin <span class="hljs-string">&#x27;itchyny/lightline.vim&#x27;</span><br></code></pre></td></tr></table></figure>启用主题插件和配置项：<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">syntax</span> <span class="hljs-keyword">on</span><br><span class="hljs-keyword">set</span> t_Co=<span class="hljs-number">256</span><br><span class="hljs-keyword">set</span> cursorline<br><span class="hljs-comment">&quot; colorscheme onehalflight </span><br><span class="hljs-comment">&quot; 设置主题</span><br><span class="hljs-keyword">colorscheme</span> onehalfdark<br><span class="hljs-keyword">let</span> <span class="hljs-variable">g:airline_theme</span>=<span class="hljs-string">&#x27;onehalfdark&#x27;</span><br><span class="hljs-comment">&quot; lightline</span><br><span class="hljs-comment">&quot; let g:lightline = &#123; &#x27;colorscheme&#x27;: &#x27;onehalfdark&#x27; &#125;</span><br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">exists</span>(<span class="hljs-string">&#x27;+termguicolors&#x27;</span>)<br>  <span class="hljs-keyword">let</span> &amp;t_8f = <span class="hljs-string">&quot;\&lt;Esc&gt;[38;2;%lu;%lu;%lum&quot;</span><br>  <span class="hljs-keyword">let</span> &amp;t_8b = <span class="hljs-string">&quot;\&lt;Esc&gt;[48;2;%lu;%lu;%lum&quot;</span><br>  <span class="hljs-keyword">set</span> termguicolors<br><span class="hljs-keyword">endif</span><br><br><span class="hljs-comment">&quot; 启用状态栏主题。</span><br><span class="hljs-comment">&quot; 自定义 Plugin &#x27;itchyny/lightline.vim&#x27;</span><br><span class="hljs-keyword">if</span> !has(<span class="hljs-string">&#x27;gui_running&#x27;</span>)<br>  <span class="hljs-keyword">set</span> t_Co=<span class="hljs-number">256</span><br><span class="hljs-keyword">endif</span><br><br><span class="hljs-comment">&quot; 总是显示状态行</span><br><span class="hljs-keyword">set</span> laststatus=<span class="hljs-number">2</span><br><br></code></pre></td></tr></table></figure><h2 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h2><p>两种方式：</p><ol><li><p>在终端运行</p><p> 运行后等待一会安装就好。</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">vim +PluginInstall +qall<br></code></pre></td></tr></table></figure></li><li><p>在vim编辑器模式下运行</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">:PluginInstall<br></code></pre></td></tr></table></figure></li></ol><h2 id="安装后效果"><a href="#安装后效果" class="headerlink" title="安装后效果"></a>安装后效果</h2><p><img src="/img/blog/em_miao_20230425215733.png"></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Vim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop源码解读</title>
      <link href="/hadoop/2022-11-15-Hadoop%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
      <url>/hadoop/2022-11-15-Hadoop%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop源码解读"><a href="#Hadoop源码解读" class="headerlink" title="Hadoop源码解读"></a>Hadoop源码解读</h1><p>以下解读基础Hadoop版本：3.2.4</p><h1 id="写流程解读："><a href="#写流程解读：" class="headerlink" title="写流程解读："></a>写流程解读：</h1><p>关键类：</p><p><code>DistributedFileSystem</code></p><p>DFSClient</p><p>org.apache.hadoop.hdfs.DFSClient#create()</p><p>org.apache.hadoop.hdfs.DFSOutputStream#newStreamForCreate()</p><p>org.apache.hadoop.hdfs.DFSOutputStream#DFSOutputStream()</p><p>org.apache.hadoop.hdfs.DataStreamer()</p><p>DataStreamer extend Thread</p><p>org.apache.hadoop.hdfs.DataStreamer#run</p><p>org.apache.hadoop.hdfs.DataStreamer.ResponseProcessor#run</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Same as &#123;<span class="hljs-doctag">@link</span> #create(String, FsPermission, EnumSet, boolean, short, long,</span><br><span class="hljs-comment">   * Progressable, int, ChecksumOpt, InetSocketAddress[])&#125; with the addition of</span><br><span class="hljs-comment">   * ecPolicyName that is used to specify a specific erasure coding policy</span><br><span class="hljs-comment">   * instead of inheriting any policy from this new file&#x27;s parent directory.</span><br><span class="hljs-comment">   * This policy will be persisted in HDFS. A value of null means inheriting</span><br><span class="hljs-comment">   * parent groups&#x27; whatever policy.</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">public</span> DFSOutputStream <span class="hljs-title function_">create</span><span class="hljs-params">(String src, FsPermission permission,</span><br><span class="hljs-params">      EnumSet&lt;CreateFlag&gt; flag, <span class="hljs-type">boolean</span> createParent, <span class="hljs-type">short</span> replication,</span><br><span class="hljs-params">      <span class="hljs-type">long</span> blockSize, Progressable progress, <span class="hljs-type">int</span> buffersize,</span><br><span class="hljs-params">      ChecksumOpt checksumOpt, InetSocketAddress[] favoredNodes,</span><br><span class="hljs-params">      String ecPolicyName)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>    checkOpen();<br>    <span class="hljs-keyword">final</span> <span class="hljs-type">FsPermission</span> <span class="hljs-variable">masked</span> <span class="hljs-operator">=</span> applyUMask(permission);<br>    LOG.debug(<span class="hljs-string">&quot;&#123;&#125;: masked=&#123;&#125;&quot;</span>, src, masked);<br>    <span class="hljs-keyword">final</span> <span class="hljs-type">DFSOutputStream</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> DFSOutputStream.newStreamForCreate(<span class="hljs-built_in">this</span>,<br>        src, masked, flag, createParent, replication, blockSize, progress,<br>        dfsClientConf.createChecksum(checksumOpt),<br>        getFavoredNodesStr(favoredNodes), ecPolicyName);<br>    beginFileLease(result.getFileId(), result);<br>    <span class="hljs-keyword">return</span> result;<br>  &#125;<br></code></pre></td></tr></table></figure><p>DFSOutputStream.newStreamForCreate</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">final</span> DFSOutputStream out;<br>    <span class="hljs-keyword">if</span>(stat.getErasureCodingPolicy() != <span class="hljs-literal">null</span>) &#123;<br>      out = <span class="hljs-keyword">new</span> <span class="hljs-title class_">DFSStripedOutputStream</span>(dfsClient, src, stat,<br>          flag, progress, checksum, favoredNodes);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      out = <span class="hljs-keyword">new</span> <span class="hljs-title class_">DFSOutputStream</span>(dfsClient, src, stat,<br>          flag, progress, checksum, favoredNodes, <span class="hljs-literal">true</span>);<br>    &#125;<br>    out.start();<br>    <span class="hljs-keyword">return</span> out;<br></code></pre></td></tr></table></figure><p>new DFSOutputStream(dfsClient, src, stat,  flag, progress, checksum, favoredNodes, true)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">protected</span> <span class="hljs-title function_">DFSOutputStream</span><span class="hljs-params">(DFSClient dfsClient, String src,</span><br><span class="hljs-params">      HdfsFileStatus stat, EnumSet&lt;CreateFlag&gt; flag, Progressable progress,</span><br><span class="hljs-params">      DataChecksum checksum, String[] favoredNodes, <span class="hljs-type">boolean</span> createStreamer)</span> &#123;<br>    <span class="hljs-built_in">this</span>(dfsClient, src, flag, progress, stat, checksum);<br>    <span class="hljs-built_in">this</span>.shouldSyncBlock = flag.contains(CreateFlag.SYNC_BLOCK);<br><br>    computePacketChunkSize(dfsClient.getConf().getWritePacketSize(),<br>        bytesPerChecksum);<br><br>    <span class="hljs-keyword">if</span> (createStreamer) &#123;<br>      streamer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">DataStreamer</span>(stat, <span class="hljs-literal">null</span>, dfsClient, src, progress,<br>          checksum, cachingStrategy, byteArrayManager, favoredNodes,<br>          addBlockFlags);<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure><p>new DataStreamer()   : <strong>DataStreamer extend</strong> <code>Daemod -&gt;</code> <code>Daemon</code> <strong>extend Thread</strong></p><p>真正和datanode通信的线程，并提交数据的线程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * streamer thread is the only thread that opens streams to datanode,</span><br><span class="hljs-comment"> * and closes them. Any error recovery is also done by this thread.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-type">TraceScope</span> <span class="hljs-variable">scope</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>  <span class="hljs-keyword">while</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;<br><span class="hljs-comment">// if the Responder encountered an error, shutdown Responder</span><br><span class="hljs-keyword">if</span> (errorState.hasError()) &#123;<br>      closeResponder();<br>    &#125;<br><br>    DFSPacket one;<br>    <span class="hljs-keyword">try</span> &#123;<br><span class="hljs-comment">// process datanode IO errors if any</span><br><span class="hljs-type">boolean</span> <span class="hljs-variable">doSleep</span> <span class="hljs-operator">=</span> processDatanodeOrExternalError();<br><br>      <span class="hljs-keyword">synchronized</span> (dataQueue) &#123;<br><span class="hljs-comment">// wait for a packet to be sent.</span><br><span class="hljs-keyword">while</span> ((!shouldStop() &amp;&amp; dataQueue.isEmpty()) || doSleep) &#123;<br>          <span class="hljs-type">long</span> <span class="hljs-variable">timeout</span> <span class="hljs-operator">=</span> <span class="hljs-number">1000</span>;<br>          <span class="hljs-keyword">if</span> (stage == BlockConstructionStage.DATA_STREAMING) &#123;<br>            timeout = sendHeartbeat();<br>          &#125;<br>          <span class="hljs-keyword">try</span> &#123;<br>            dataQueue.wait(timeout);<br>          &#125; <span class="hljs-keyword">catch</span> (InterruptedException  e) &#123;<br>LOG.debug(<span class="hljs-string">&quot;Thread interrupted&quot;</span>, e);<br>          &#125;<br>          doSleep = <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (shouldStop()) &#123;<br>          <span class="hljs-keyword">continue</span>;<br>        &#125;<br><span class="hljs-comment">// get packet to be sent.</span><br><span class="hljs-keyword">try</span> &#123;<br>          backOffIfNecessary();<br>        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>LOG.debug(<span class="hljs-string">&quot;Thread interrupted&quot;</span>, e);<br>        &#125;<br>        one = dataQueue.getFirst();<span class="hljs-comment">// regular data packet</span><br>SpanId[] parents = one.getTraceParents();<br>        <span class="hljs-keyword">if</span> (parents.length &gt; <span class="hljs-number">0</span>) &#123;<br>          scope = dfsClient.getTracer().<br>              newScope(<span class="hljs-string">&quot;dataStreamer&quot;</span>, parents[<span class="hljs-number">0</span>]);<br>          scope.getSpan().setParents(parents);<br>        &#125;<br>      &#125;<br><br><span class="hljs-comment">// get new block from namenode.</span><br>LOG.debug(<span class="hljs-string">&quot;stage=&#123;&#125;, &#123;&#125;&quot;</span>, stage, <span class="hljs-built_in">this</span>);<br><br>      <span class="hljs-keyword">if</span> (stage == BlockConstructionStage.PIPELINE_SETUP_CREATE) &#123;<br>LOG.debug(<span class="hljs-string">&quot;Allocating new block: &#123;&#125;&quot;</span>, <span class="hljs-built_in">this</span>);<br>        setPipeline(nextBlockOutputStream());<br>        initDataStreaming();<br>      &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (stage == BlockConstructionStage.PIPELINE_SETUP_APPEND) &#123;<br>LOG.debug(<span class="hljs-string">&quot;Append to block &#123;&#125;&quot;</span>, block);<br>        setupPipelineForAppendOrRecovery();<br>        <span class="hljs-keyword">if</span> (streamerClosed) &#123;<br>          <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        initDataStreaming();<br>      &#125;<br><br>      <span class="hljs-type">long</span> <span class="hljs-variable">lastByteOffsetInBlock</span> <span class="hljs-operator">=</span> one.getLastByteOffsetBlock();<br>      <span class="hljs-keyword">if</span> (lastByteOffsetInBlock &gt; stat.getBlockSize()) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IOException</span>(<span class="hljs-string">&quot;BlockSize &quot;</span> + stat.getBlockSize() +<br>            <span class="hljs-string">&quot; &lt; lastByteOffsetInBlock, &quot;</span> + <span class="hljs-built_in">this</span> + <span class="hljs-string">&quot;, &quot;</span> + one);<br>      &#125;<br><br>      <span class="hljs-keyword">if</span> (one.isLastPacketInBlock()) &#123;<br><span class="hljs-comment">// wait for all data packets have been successfully acked</span><br>waitForAllAcks();<br>        <span class="hljs-keyword">if</span>(shouldStop()) &#123;<br>          <span class="hljs-keyword">continue</span>;<br>        &#125;<br>        stage = BlockConstructionStage.PIPELINE_CLOSE;<br>      &#125;<br><br><span class="hljs-comment">// send the packet</span><br><span class="hljs-type">SpanId</span> <span class="hljs-variable">spanId</span> <span class="hljs-operator">=</span> SpanId.INVALID;<br>      <span class="hljs-keyword">synchronized</span> (dataQueue) &#123;<br><span class="hljs-comment">// move packet from dataQueue to ackQueue</span><br><span class="hljs-keyword">if</span> (!one.isHeartbeatPacket()) &#123;<br>          <span class="hljs-keyword">if</span> (scope != <span class="hljs-literal">null</span>) &#123;<br>            spanId = scope.getSpanId();<br>            scope.detach();<br>            one.setTraceScope(scope);<br>          &#125;<br>          scope = <span class="hljs-literal">null</span>;<br>          dataQueue.removeFirst();<br>          ackQueue.addLast(one);<br>          packetSendTime.put(one.getSeqno(), Time.monotonicNow());<br>          dataQueue.notifyAll();<br>        &#125;<br>      &#125;<br><br>LOG.debug(<span class="hljs-string">&quot;&#123;&#125; sending &#123;&#125;&quot;</span>, <span class="hljs-built_in">this</span>, one);<br><br><span class="hljs-comment">// write out data to remote datanode</span><br><span class="hljs-keyword">try</span> (<span class="hljs-type">TraceScope</span> <span class="hljs-variable">ignored</span> <span class="hljs-operator">=</span> dfsClient.getTracer().<br>          newScope(<span class="hljs-string">&quot;DataStreamer#writeTo&quot;</span>, spanId)) &#123;<br>        sendPacket(one);<br>      &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br><span class="hljs-comment">// HDFS-3398 treat primary DN is down since client is unable to</span><br>        <span class="hljs-comment">// write to primary DN. If a failed or restarting node has already</span><br>        <span class="hljs-comment">// been recorded by the responder, the following call will have no</span><br>        <span class="hljs-comment">// effect. Pipeline recovery can handle only one node error at a</span><br>        <span class="hljs-comment">// time. If the primary node fails again during the recovery, it</span><br>        <span class="hljs-comment">// will be taken out then.</span><br>errorState.markFirstNodeIfNotMarked();<br>        <span class="hljs-keyword">throw</span> e;<br>      &#125;<br><br><span class="hljs-comment">// update bytesSent</span><br><span class="hljs-type">long</span> <span class="hljs-variable">tmpBytesSent</span> <span class="hljs-operator">=</span> one.getLastByteOffsetBlock();<br>      <span class="hljs-keyword">if</span> (bytesSent &lt; tmpBytesSent) &#123;<br>        bytesSent = tmpBytesSent;<br>      &#125;<br><br>      <span class="hljs-keyword">if</span> (shouldStop()) &#123;<br>        <span class="hljs-keyword">continue</span>;<br>      &#125;<br><br><span class="hljs-comment">// Is this block full?</span><br><span class="hljs-keyword">if</span> (one.isLastPacketInBlock()) &#123;<br><span class="hljs-comment">// wait for the close packet has been acked</span><br><span class="hljs-keyword">try</span> &#123;<br>          waitForAllAcks();<br>        &#125; <span class="hljs-keyword">catch</span> (IOException ioe) &#123;<br><span class="hljs-comment">// No need to do a close recovery if the last packet was acked.</span><br>          <span class="hljs-comment">// i.e. ackQueue is empty.  waitForAllAcks() can get an exception</span><br>          <span class="hljs-comment">// (e.g. connection reset) while sending a heartbeat packet,</span><br>          <span class="hljs-comment">// if the DN sends the final ack and closes the connection.</span><br><span class="hljs-keyword">synchronized</span> (dataQueue) &#123;<br>            <span class="hljs-keyword">if</span> (!ackQueue.isEmpty()) &#123;<br>              <span class="hljs-keyword">throw</span> ioe;<br>            &#125;<br>          &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (shouldStop()) &#123;<br>          <span class="hljs-keyword">continue</span>;<br>        &#125;<br><br>        endBlock();<br>      &#125;<br>      <span class="hljs-keyword">if</span> (progress != <span class="hljs-literal">null</span>) &#123; progress.progress(); &#125;<br><br><span class="hljs-comment">// This is used by unit test to trigger race conditions.</span><br><span class="hljs-keyword">if</span> (artificialSlowdown != <span class="hljs-number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;<br>        Thread.sleep(artificialSlowdown);<br>      &#125;<br>    &#125; <span class="hljs-keyword">catch</span> (Throwable e) &#123;<br><span class="hljs-comment">// Log warning if there was a real error.</span><br><span class="hljs-keyword">if</span> (!errorState.isRestartingNode()) &#123;<br><span class="hljs-comment">// Since their messages are descriptive enough, do not always</span><br>        <span class="hljs-comment">// log a verbose stack-trace WARN for quota exceptions.</span><br><span class="hljs-keyword">if</span> (e <span class="hljs-keyword">instanceof</span> QuotaExceededException) &#123;<br>LOG.debug(<span class="hljs-string">&quot;DataStreamer Quota Exception&quot;</span>, e);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>LOG.warn(<span class="hljs-string">&quot;DataStreamer Exception&quot;</span>, e);<br>        &#125;<br>      &#125;<br>      lastException.set(e);<br>      <span class="hljs-keyword">assert</span> !(e <span class="hljs-keyword">instanceof</span> NullPointerException);<br>      errorState.setInternalError();<br>      <span class="hljs-keyword">if</span> (!errorState.isNodeMarked()) &#123;<br><span class="hljs-comment">// Not a datanode issue</span><br>streamerClosed = <span class="hljs-literal">true</span>;<br>      &#125;<br>    &#125; <span class="hljs-keyword">finally</span> &#123;<br>      <span class="hljs-keyword">if</span> (scope != <span class="hljs-literal">null</span>) &#123;<br>        scope.close();<br>        scope = <span class="hljs-literal">null</span>;<br>      &#125;<br>    &#125;<br>  &#125;<br>  closeInternal();<br>&#125;<br><br></code></pre></td></tr></table></figure><p>org.apache.hadoop.hdfs.DataStreamer#sendPacket</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">sendPacket</span><span class="hljs-params">(DFSPacket packet)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>    <span class="hljs-comment">// write out data to remote datanode</span><br>    <span class="hljs-keyword">try</span> &#123;<br>      packet.writeTo(blockStream);z<br>      blockStream.flush();<br>    &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>      <span class="hljs-comment">// HDFS-3398 treat primary DN is down since client is unable to</span><br>      <span class="hljs-comment">// write to primary DN. If a failed or restarting node has already</span><br>      <span class="hljs-comment">// been recorded by the responder, the following call will have no</span><br>      <span class="hljs-comment">// effect. Pipeline recovery can handle only one node error at a</span><br>      <span class="hljs-comment">// time. If the primary node fails again during the recovery, it</span><br>      <span class="hljs-comment">// will be taken out then.</span><br>      errorState.markFirstNodeIfNotMarked();<br>      <span class="hljs-keyword">throw</span> e;<br>    &#125;<br>    lastPacket = Time.monotonicNow();<br>  &#125;<br></code></pre></td></tr></table></figure><p>大体写流程步骤：</p><ol><li>创建DFSClicent会创建一个<code>DFSOutputStream</code></li><li>创建<code>DFSOutputStream</code>时，<ol><li>创建<code>HdfsFileStatus</code> 文件状态信息</li><li>初始化packetSize(max&#x3D;16M)</li><li>创建一个<code>DataStreamer</code>流进程，用于对数据的排队，上传（），ack等操作。</li></ol></li><li><code>DataStreamer</code> 进程写数据步骤：<ol><li><p><code>setPipeline(nextBlockOutputStream());</code>向NameNode中申请块信息（可用的datanode节点)，即：获取第一个DataNode信息即所存储的块。</p></li><li><p>根据总的文件大小，和设定的packet大小，得到很多歌packet。拆分数据为到不同的packet中</p></li><li><p>将packet放入到queue。</p></li><li><p>执行发送Packet（从queue取出队列中DFSPacket发送到datanode1的block块中。）</p></li><li><p>当块中数据达到阈值（128M)时，关闭块，后续packet重新申请block，重复上述传输步骤。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">sendPacket</span><span class="hljs-params">(DFSPacket packet)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>    <span class="hljs-comment">// write out data to remote datanode</span><br>    <span class="hljs-keyword">try</span> &#123;<br>      packet.writeTo(blockStream);<br>      blockStream.flush();<br>    &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>      <span class="hljs-comment">// HDFS-3398 treat primary DN is down since client is unable to</span><br>      <span class="hljs-comment">// write to primary DN. If a failed or restarting node has already</span><br>      <span class="hljs-comment">// been recorded by the responder, the following call will have no</span><br>      <span class="hljs-comment">// effect. Pipeline recovery can handle only one node error at a</span><br>      <span class="hljs-comment">// time. If the primary node fails again during the recovery, it</span><br>      <span class="hljs-comment">// will be taken out then.</span><br>      errorState.markFirstNodeIfNotMarked();<br>      <span class="hljs-keyword">throw</span> e;<br>    &#125;<br>    lastPacket = Time.monotonicNow();<br>  &#125;<br></code></pre></td></tr></table></figure></li><li><p>副本同步+ack。</p></li></ol><p> <code>FSOutputSummer</code></p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">write1</span><span class="hljs-params">(<span class="hljs-type">byte</span> b[], <span class="hljs-type">int</span> off, <span class="hljs-type">int</span> len)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>    <span class="hljs-keyword">if</span>(count==<span class="hljs-number">0</span> &amp;&amp; len&gt;=buf.length) &#123;<br>      <span class="hljs-comment">// local buffer is empty and user buffer size &gt;= local buffer size, so</span><br>      <span class="hljs-comment">// simply checksum the user buffer and send it directly to the underlying</span><br>      <span class="hljs-comment">// stream</span><br>      <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">length</span> <span class="hljs-operator">=</span> buf.length;<br>      writeChecksumChunks(b, off, length);<br>      <span class="hljs-keyword">return</span> length;<br>    &#125;<br><br></code></pre></td></tr></table></figure><p> <code>DFSOutputStream</code>.writeChunk()时，将数据封装成packet，放入dataQueue中。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br>  <span class="hljs-keyword">protected</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">writeChunk</span><span class="hljs-params">(<span class="hljs-type">byte</span>[] b, <span class="hljs-type">int</span> offset, <span class="hljs-type">int</span> len,</span><br><span class="hljs-params">      <span class="hljs-type">byte</span>[] checksum, <span class="hljs-type">int</span> ckoff, <span class="hljs-type">int</span> cklen)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>    writeChunkPrepare(len, ckoff, cklen);<br><br>    currentPacket.writeChecksum(checksum, ckoff, cklen);<br>    currentPacket.writeData(b, offset, len);<br>    currentPacket.incNumChunks();<br>    getStreamer().incBytesCurBlock(len);<br><br>    <span class="hljs-comment">// If packet is full, enqueue it for transmission</span><br>    <span class="hljs-keyword">if</span> (currentPacket.getNumChunks() == currentPacket.getMaxChunks() ||<br>        getStreamer().getBytesCurBlock() == blockSize) &#123;<br>      enqueueCurrentPacketFull();<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure></li></ol><p><code>new DFSOutputStream().start()</code></p><p>创建流时（<code>DFSOutputStream</code>），同时会启动一个<code>DataStreamer</code>线程 用于发送 packet。</p><p><code>DataStreamer</code>线程 发送的流程：</p><ol><li><p><code>setPipeline(nextBlockOutputStream());</code>（与namenode通信,在namenode中注册块信息和文件信息，返回datanode信息和储存信息）</p><ol><li>从datanode列表中中获取第一个可用的datanode建立<code>Socket</code></li><li>发送请求</li><li>ack确认</li><li>ack确认成功后，返回可用的块和节点信息</li><li>设置可用的节点和块信息。</li></ol></li><li><p><code>initDataStreaming</code> 初始化流，并启动一个ack进程。</p><ol><li><p>初始化*<code>data streaming</code>* ,其中单独有个线程有response来进行ack确认，保证数据传输的完整性。</p><p> <code>new ResponseProcessor(nodes)</code>.start()</p><p> <code>ResponseProcessor</code> extend Thread</p></li></ol></li><li><p>发送packet到datanode的block中，通过流的形式，使用ackqueue进行确认，保证数据完整性。</p><p> <code>dataQueue.removeFirst();</code></p><p> <code>ackQueue.addLast(one);</code></p><p> <code>sendPacket(one);</code></p><p> 将packet移除dataQueue，加入待确认的ackQueue，并发送packet。</p><ol><li>将packet通过流的形式发送到datanode1的block块中，当数据大小达到块大小，则关闭块；</li><li>后续的packet会重新申请block；再往新的block中写入数据。</li></ol></li><li><p>如果发送失败，会进行重试。</p><ol><li>失败重试成功，会去更新NameNode中的块信息</li><li>若是追加块信息，也会重新去更新NameNode中的块信息</li></ol></li><li><p>副本同步；如有hdfs设置副本超过1了，dn1,会向dn2，dn2再向dn3,进行数据同步操作(block级别同步)；此步骤也需要ack确认。</p><p> <code>setupPipelineForAppendOrRecovery</code></p><p> <code>handleDatanodeReplacement()</code></p></li><li><p>等待所有数据发送完成后，且副本同步成功，则视为整个写入流程完成，接着关闭相关资源</p><p> 如果是最后一个packet发送时，尝试等待allAcks确认，如果都成功，则清理资源。</p><p> <code>waitForAllAcks();</code></p><p> 将所有packet发送完成后，等待allAcks确认完成；关闭 发送线程 和 ack确认线程 ，清理queue。</p></li></ol><h1 id="读流程解读："><a href="#读流程解读：" class="headerlink" title="读流程解读："></a>读流程解读：</h1><ol><li><p>获取文件系统</p></li><li><p>打开文件系统时，通过文件路径，定位出文件所有的块信息。</p><p> <code>LocatedBlocks locatedBlocks = getLocatedBlocks(src, 0);</code></p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LocatedBlocks</span> &#123;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> fileLength;<br>  <span class="hljs-comment">// array of blocks with prioritized locations</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> List&lt;LocatedBlock&gt; blocks;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> underConstruction;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> LocatedBlock lastLocatedBlock;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> isLastBlockComplete;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> FileEncryptionInfo fileEncryptionInfo;<br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ErasureCodingPolicy ecPolicy;<br>&#125;<br><br>LocatedBlock <br></code></pre></td></tr></table></figure><p> <img src="/img/hadoop/hdfs_block.png" alt="hdfs_block"></p></li><li><p>根据块信息<code>LocatedBlock中的``DatanodeInfo[]返回可用的dataNode节点信息</code></p></li><li><p>通过返回的DataNode节点，建立连接访问块中数据</p><p> <code>DNAddrPair retval = chooseDataNode(targetBlock, null);</code></p></li><li><p>根据块的新的，访问实际数据<code>actualGetFromOneDataNode</code> <code>getBlockReader</code></p></li></ol><h1 id="hadoop-MR流程"><a href="#hadoop-MR流程" class="headerlink" title="hadoop-MR流程"></a>hadoop-MR流程</h1><h2 id="任务提交阶段："><a href="#任务提交阶段：" class="headerlink" title="任务提交阶段："></a>任务提交阶段：</h2><ol><li><p>生成JobID</p></li><li><p>拷贝配置和配置文件到工作目录中。</p></li><li><p>计算分片个数（FileInputFormat中；通过块的个数，默认情况下，等于文件块的个数），分片个数也等于map-task的个数。</p><ol><li><p>org.apache.hadoop.mapreduce.JobSubmitter#submitJobInternal</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">protected</span> <span class="hljs-type">long</span> <span class="hljs-title function_">computeSplitSize</span><span class="hljs-params">(<span class="hljs-type">long</span> blockSize, <span class="hljs-type">long</span> minSize,</span><br><span class="hljs-params">                                <span class="hljs-type">long</span> maxSize)</span> &#123;<br>  <span class="hljs-keyword">return</span> Math.max(minSize, Math.min(maxSize, blockSize));<br>&#125;<br></code></pre></td></tr></table></figure></li></ol></li><li><p>客户端端提交Job</p><ol><li>如何提交到yarn，提交到ResourceManger，则会申请一台DataNode节点后启动appMster进程。</li></ol></li></ol><h2 id="MapTask阶段："><a href="#MapTask阶段：" class="headerlink" title="MapTask阶段："></a>MapTask阶段：</h2><p>org.apache.hadoop.mapred.MapTask#runNewMapper</p><p>org.apache.hadoop.mapred.MapTask#getSplitDetails</p><p>org.apache.hadoop.mapred.MapTask#createSortingCollector</p><p><code>job.getClasses(JobContext.*MAP_OUTPUT_COLLECTOR_CLASS_ATTR*, MapOutputBuffer.class);</code></p><p>org.apache.hadoop.mapred.MapTask.MapOutputBuffer#init</p><p>org.apache.hadoop.mapred.MapTask.MapOutputBuffer#flush</p><p>org.apache.hadoop.mapred.MapTask.MapOutputBuffer#sortAndSpill</p><p>org.apache.hadoop.util.IndexedSorter#sort(org.apache.hadoop.util.IndexedSortable, int, int, org.apache.hadoop.util.Progressable)</p><ol><li><p>接收来自InputFormat传递过来的KV值；</p></li><li><p>map方法处理逻辑并写出数据。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">map</span><span class="hljs-params">(KEYIN key, VALUEIN value, </span><br><span class="hljs-params">                     Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException &#123;<br>    context.write((KEYOUT) key, (VALUEOUT) value);<br>  &#125;<br></code></pre></td></tr></table></figure></li><li><p>MapOutput阶段输出结果到临时文件：Shuffle阶段在MapTask中的部分。</p></li></ol><h2 id="Shuffle-阶段1："><a href="#Shuffle-阶段1：" class="headerlink" title="Shuffle 阶段1："></a>Shuffle 阶段1：</h2><p> org.apache.hadoop.mapred.MapTask.MapOutputBuffer</p><ol><li><p>初始化环形缓冲区。</p></li><li><p>将数据写入环形缓冲区</p></li><li><p>当数据达到缓冲区阈值时，</p></li><li><p>落盘前进行了分区和快排。</p><p> org.apache.hadoop.mapred.MapTask.MapOutputBuffer#compare</p><p> 先排序分区，再通过key排序。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">compare</span><span class="hljs-params">(<span class="hljs-keyword">final</span> <span class="hljs-type">int</span> mi, <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> mj)</span> &#123;<br>      <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">kvi</span> <span class="hljs-operator">=</span> offsetFor(mi % maxRec);<br>      <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">kvj</span> <span class="hljs-operator">=</span> offsetFor(mj % maxRec);<br>      <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">kvip</span> <span class="hljs-operator">=</span> kvmeta.get(kvi + PARTITION);<br>      <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">kvjp</span> <span class="hljs-operator">=</span> kvmeta.get(kvj + PARTITION);<br>      <span class="hljs-comment">// sort by partition</span><br>      <span class="hljs-keyword">if</span> (kvip != kvjp) &#123;<br>        <span class="hljs-keyword">return</span> kvip - kvjp;<br>      &#125;<br>      <span class="hljs-comment">// sort by key</span><br>      <span class="hljs-keyword">return</span> comparator.compare(kvbuffer,<br>          kvmeta.get(kvi + KEYSTART),<br>          kvmeta.get(kvi + VALSTART) - kvmeta.get(kvi + KEYSTART),<br>          kvbuffer,<br>          kvmeta.get(kvj + KEYSTART),<br>          kvmeta.get(kvj + VALSTART) - kvmeta.get(kvj + KEYSTART));<br>    &#125;<br></code></pre></td></tr></table></figure></li><li><p>对数据进行溢写到磁盘中。[spillN.out]</p></li></ol><p>至此mapTask阶段完成</p><h2 id="Shuffle阶段2："><a href="#Shuffle阶段2：" class="headerlink" title="Shuffle阶段2："></a>Shuffle阶段2：</h2><p>发生在map之后，</p><p>触发时在reduceTask中，但发生在reduce之前。</p><p>ReduceTask启时，也会启动</p><p>初始化shuffle时做的事情：</p><ol><li>初始化合并管理器<code>MergeManagerImpl</code> 初始化合并管理器后，线程运行，发现有合并的队列就进行合并。 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">org.apache.hadoop.mapreduce.task.reduce.MergeThread#run<br>org.apache.hadoop.mapred.Merger#merge(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem, java.lang.Class&lt;K&gt;, java.lang.Class&lt;V&gt;, java.util.List&lt;org.apache.hadoop.mapred.Merger.Segment&lt;K,V&gt;&gt;, <span class="hljs-type">int</span>, org.apache.hadoop.fs.Path, org.apache.hadoop.io.RawComparator&lt;K&gt;, org.apache.hadoop.util.Progressable, org.apache.hadoop.mapred.Counters.Counter, org.apache.hadoop.mapred.Counters.Counter, org.apache.hadoop.util.Progress)<br></code></pre></td></tr></table></figure><ol><li><p>其中又初始化了三个类型的合并管理器</p><p> 合并器即：合并（归并）线程，其中维护了一个linkedlist的待合并的队列。</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">boolean</span> <span class="hljs-variable">allowMemToMemMerge</span> <span class="hljs-operator">=</span> <br>      jobConf.getBoolean(MRJobConfig.REDUCE_MEMTOMEM_ENABLED, <span class="hljs-literal">false</span>);<br>    <span class="hljs-keyword">if</span> (allowMemToMemMerge) &#123;<br>      <span class="hljs-built_in">this</span>.memToMemMerger = <br>        <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntermediateMemoryToMemoryMerger</span>(<span class="hljs-built_in">this</span>,<br>                                             memToMemMergeOutputsThreshold);<br>      <span class="hljs-built_in">this</span>.memToMemMerger.start();<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-built_in">this</span>.memToMemMerger = <span class="hljs-literal">null</span>;<br>    &#125;<br>    <br>    <span class="hljs-built_in">this</span>.inMemoryMerger = createInMemoryMerger();<br>    <span class="hljs-built_in">this</span>.inMemoryMerger.start();<br>    <br>    <span class="hljs-built_in">this</span>.onDiskMerger = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OnDiskMerger</span>(<span class="hljs-built_in">this</span>);<br>    <span class="hljs-built_in">this</span>.onDiskMerger.start();<br></code></pre></td></tr></table></figure></li></ol></li></ol><p>步骤：</p><ol><li>接受来自MapOutput阶段输出的值。</li><li>将数据写入到Shuffer的Buffer中</li><li>当数据量达到一定阈值的时候，刷新到磁盘</li><li>Key合并排序[归并排序]刷写到磁盘。</li></ol><p>关键代码 ：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java">org.apache.hadoop.mapred.ReduceTask#run<br>shuffleConsumerPlugin.run()<br>org.apache.hadoop.mapreduce.task.reduce.Shuffle#run<br>fetchers[i].start();<br>org.apache.hadoop.mapreduce.task.reduce.Fetcher#run<br><span class="hljs-comment">// shuffle 关键 1.拷贝或下载mapout的结果</span><br>org.apache.hadoop.mapreduce.task.reduce.Fetcher#copyFromHost<br>org.apache.hadoop.mapreduce.task.reduce.Fetcher#<span class="hljs-type">copyMapOutput</span><br><br><span class="hljs-variable">mapOutput</span> <span class="hljs-operator">=</span> merger.reserve(mapId, decompressedLength, id);<br>mapOutPut.doShuffle()<br>org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput#doShuffle<br><span class="hljs-comment">//根据分区和key执行归并排序。</span><br>org.apache.hadoop.mapreduce.task.reduce.Shuffle#init<br>org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl#MergeManagerImpl<br><br>org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.OnDiskMerger#merge<br>org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.InMemoryMerger#merge<br><span class="hljs-comment">//最后将排序好的数据传递到Reduce</span><br></code></pre></td></tr></table></figure><h2 id="Reduce阶段"><a href="#Reduce阶段" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h2><p>Shuffle完后，启动Reduce</p><p>根据自定义的Reduce函数，执行统计保存到指定的outPut存储中。</p><p>org.apache.hadoop.mapred.ReduceTask#runNewReducer</p><p>org.apache.hadoop.mapreduce.lib.chain.ChainReducer#run</p><p>org.apache.hadoop.mapreduce.lib.chain.Chain#runReducer</p><p>org.apache.hadoop.mapreduce.Reducer#run</p>]]></content>
      
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop3的一些重大升级</title>
      <link href="/hadoop/2022-11-08-Hadoop3%E7%9A%84%E4%B8%80%E4%BA%9B%E9%87%8D%E5%A4%A7%E5%8D%87%E7%BA%A7/"/>
      <url>/hadoop/2022-11-08-Hadoop3%E7%9A%84%E4%B8%80%E4%BA%9B%E9%87%8D%E5%A4%A7%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="一-HA中NameNode，ResourceManager支持超过2个"><a href="#一-HA中NameNode，ResourceManager支持超过2个" class="headerlink" title="一. HA中NameNode，ResourceManager支持超过2个"></a>一. HA中NameNode，ResourceManager支持超过2个</h1><p>在hadoop3以前 hdfs的HA和yarn的HA中，NN和RM支持两个，存在standby的单节点故障问题。<br>Hadoop3升级后，可以配置超过2个的NN和RM</p><h1 id="二-端口的变化"><a href="#二-端口的变化" class="headerlink" title="二. 端口的变化"></a>二. 端口的变化</h1><p>Namenode ports: 50470 –&gt; 9871, 50070–&gt; 9870, 8020 –&gt; 8020<br>Secondary NN ports: 50091 –&gt; 9869,50090 –&gt; 9868<br>Datanode ports: 50020 –&gt; 9867, 50010–&gt; 9866, 50475 –&gt; 9865, 50075 –&gt; 9864<br>Kms server ports: 16000 –&gt; 9600 (原先的16000与HMaster端口冲突)</p><table><thead><tr><th>端口名称</th><th>Hadoop2.x</th><th>Hadoop3.x</th></tr></thead><tbody><tr><td>NameNode内部通信端口</td><td>8020 &#x2F; 9000</td><td>8020 &#x2F; 9000&#x2F;9820</td></tr><tr><td>NameNode HTTP UI</td><td>50070</td><td>9870</td></tr><tr><td>MapReduce查看执行任务端口</td><td>8088</td><td>8088</td></tr><tr><td>历史服务器通信端口</td><td>19888</td><td>19888</td></tr></tbody></table><h1 id="三-HDFS纠删码"><a href="#三-HDFS纠删码" class="headerlink" title="三. HDFS纠删码"></a>三. HDFS纠删码</h1><p>Erasure coding纠删码技术简称EC，是一种数据保护技术。<br>引入纠删码后，节省了储存空间。以副本为3为例：<br>原来储存利用率为1&#x2F;3,另外两个副本占用2&#x2F;3<br>使用纠删码后，另外副本只需要存储纠删码，占用空间约2&#x2F;3 * 1&#x2F;2 -&gt; 1&#x2F;3<br>与副本相比纠删码是一种更节省空间的数据持久化存储方法。标准编码(比如Reed-Solomon(10,4))会有1.4 倍的空间开销；然而HDFS副本则会有3倍的空间开销。</p><h1 id="四-Shell脚本重写"><a href="#四-Shell脚本重写" class="headerlink" title="四. Shell脚本重写"></a>四. Shell脚本重写</h1><p>最明显的启动hdfs和yarn的进行<br>eg:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs --daemon start namenode<br>hdfs --daemon start datanode<br>hdfs --daemon start zkfc<br>hdfs --daemon start jouralnode<br><br><span class="hljs-comment"># ------ </span><br>yarn --daemon start resourcemanager<br>yarn --daemon start nodemanager<br></code></pre></td></tr></table></figure><h1 id="五-磁盘平衡"><a href="#五-磁盘平衡" class="headerlink" title="五. 磁盘平衡"></a>五. 磁盘平衡</h1><p>Hadoop2时，数据平衡只能在节点间进行平衡。<br>Hadoop3，datanode节点存储目录可以是多个，且单个DataNode节点的数据磁盘可以进行再平衡。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- 默认关闭状态 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.disk.balancer.enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs diskbalancer 对磁盘<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop3.x-HA设置</title>
      <link href="/hadoop/%202022-11-08-Hadoop3-x-HA%E8%AE%BE%E7%BD%AE/"/>
      <url>/hadoop/%202022-11-08-Hadoop3-x-HA%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop-HA"><a href="#Hadoop-HA" class="headerlink" title="Hadoop-HA"></a>Hadoop-HA</h1><h1 id="HDFS-NameNode-HA"><a href="#HDFS-NameNode-HA" class="headerlink" title="HDFS-NameNode-HA"></a>HDFS-NameNode-HA</h1><ol><li>依赖Zookeeper</li><li>每个nn会有一个ZKFC进程进行管理状态。</li><li>hadoop3.x可以启动N≥2个NN,可以超过2个，3个等。</li><li>Hadoop2.x及一下，只能启动两个NN作高可用。</li><li>NN做HA时，不在有2NN,由其他standby的NN同步active的NN的元数据信息(fsimage,edits)，替代2NN。<br> JournalNode负责edits文件的一致性。<ol><li>Fsimage：让一台NN生成数据，其他NN同步</li><li>Edits：引进新的模块JournalNode保证edits的文件数据一致性。</li><li>HA环境下 定期合并fsimage和edits由standby的NN完成。</li></ol></li></ol><h2 id="NameNode从standby切换到active过程。"><a href="#NameNode从standby切换到active过程。" class="headerlink" title="NameNode从standby切换到active过程。"></a>NameNode从standby切换到active过程。</h2><ol><li>原有active-nn与zk通信失败或死掉</li><li>standby上的nn的<strong>ZKFC</strong>发送进程kill旧的nn,防止原来的active-nn假死。</li><li>也可通过自定义脚本去杀死原有的nn再次确保原来nn死掉。</li><li>standby-nn在确保上述的步骤ok后，从standby切换为active。完成切换。</li></ol><h1 id="Yarn-ResourceManager-HA"><a href="#Yarn-ResourceManager-HA" class="headerlink" title="Yarn-ResourceManager-HA"></a>Yarn-ResourceManager-HA</h1><ol><li>依赖zookeeper</li><li>hadoop3.x可以有用2个以上(3,4个等）的RM</li><li>hadoop2.x只能有两个RM</li></ol><p>RM由备用切换到active过程。</p><p>通过注册到zk中的节点数，采取<strong>抢占式</strong>的方式获取节点进行切换。</p><ol><li>启动时，谁先对zk中的目录节点进行注册，谁就是active节点。</li><li>当原有active节点死掉，其余备用节点采取抢占式的方式对zk的rm的数据目录进行抢占式注册；谁先成功，谁就被激活为active</li><li>如果yarn有正在进行运行的任务，新切换的active节点将继续对其支持；任务任务运行时所存储的数据均在zk中。</li></ol><h1 id="HA配置文件"><a href="#HA配置文件" class="headerlink" title="HA配置文件"></a>HA配置文件</h1><h2 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS-HA"></a>HDFS-HA</h2><p>core-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="hljs-meta">&lt;?xml-stylesheet type=<span class="hljs-string">&quot;text/xsl&quot;</span> href=<span class="hljs-string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><br><span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 把多个 NameNode 的地址组装成一个集群 mycluster --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://hacluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 hadoop 运行时产生文件的存储目录 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/opt/ha/hadoop-3.3.0/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>ha.zookeeper.quorum<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:2181,hd002:2181,hd003:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><p>hfds-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="hljs-meta">&lt;?xml-stylesheet type=<span class="hljs-string">&quot;text/xsl&quot;</span> href=<span class="hljs-string">&quot;configuration.xsl&quot;</span>?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><br><span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!-- NameNode 数据存储目录 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- DataNode 数据存储目录 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- JournalNode 数据存储目录 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 完全分布式集群名称 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.nameservices<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hacluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 集群中 NameNode 节点都有哪些 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.namenodes.hacluster<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>nn1,nn2,nn3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- NameNode 的 RPC 通信地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.rpc-address.hacluster.nn1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:8020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.rpc-address.hacluster.nn2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:8020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.rpc-address.hacluster.nn3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:8020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- NameNode 的 http 通信地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.http-address.hacluster.nn1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:9870<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.http-address.hacluster.nn2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:9870<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.http-address.hacluster.nn3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:9870<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 NameNode 元数据在 JournalNode 上的存放位置 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>qjournal://hd001:8485;hd002:8485;hd003:8485/hacluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 访问代理类：client 用于确定哪个 NameNode 为 Active --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.client.failover.proxy.provider.hacluster<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>sshfence<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 使用隔离机制时需要 ssh 秘钥登录--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/miao/.ssh/id_rsa<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!-- 启用 nn 故障自动转移 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><h2 id="Yarn-HA"><a href="#Yarn-HA" class="headerlink" title="Yarn-HA"></a>Yarn-HA</h2><p>  yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span>?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!-- Site specific YARN configuration properties --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 启用 resourcemanager ha --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 声明3台 resourcemanager 的地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster-yarn1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!--指定 resourcemanager 的逻辑列表--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>rm1,rm2,rm3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- ========== rm1 的配置 ========== --&gt;</span><br><span class="hljs-comment">&lt;!-- 指定 rm1 的主机名 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 指定 rm1 的 web 端地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:8088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 指定 rm1 的内部通信地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:8032<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:8030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定供 NM 连接的地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:8031<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- ========== rm2 的配置 ========== --&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 rm2 的主机名 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:8088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:8032<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:8030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:8031<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- ========== rm3 的配置 ========== --&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 rm1 的主机名 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 rm1 的 web 端地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:8088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 rm1 的内部通信地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address.rm3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:8032<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:8030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定供 NM 连接的地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm3<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:8031<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定 zookeeper 集群的地址 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:2181,hd002:2181,hd003:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 启用自动恢复 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 环境变量的继承 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLAS SPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><h1 id="新增节点-DataNode-NodeManager"><a href="#新增节点-DataNode-NodeManager" class="headerlink" title="新增节点(DataNode,NodeManager)"></a>新增节点(DataNode,NodeManager)</h1><p>新增节点， copy NameNode的hadoop目录，与其保持一致，<strong>删除data目录数据，及logs目录的日志。</strong></p><p>添加新节点的hostname到workers中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">/opt/ha/hadoop-3.3.0/etc/hadoop/workers<br>miao@hd001:/opt/ha/hadoop-3.3.0/etc/hadoop$ <span class="hljs-built_in">cat</span> workers<br>hd001<br>hd002<br>hd003<br>hd004<br></code></pre></td></tr></table></figure><p>添加完works同步works文件，并将hosts文件也添加上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">miao@hd001:/opt/ha/hadoop-3.3.0/etc/hadoop$ <span class="hljs-built_in">cat</span> /etc/hosts<br>127.0.0.1 localhost<br>127.0.1.1 hd<br><br><span class="hljs-comment"># The following lines are desirable for IPv6 capable hosts</span><br>::1     ip6-localhost ip6-loopback<br>fe00::0 ip6-localnet<br>ff00::0 ip6-mcastprefix<br>ff02::1 ip6-allnodes<br>ff02::2 ip6-allrouters<br><br>192.168.64.51 hd001<br>192.168.64.52 hd002<br>192.168.64.53 hd003<br>192.168.64.54 hd004<br></code></pre></td></tr></table></figure><p>同步works文件和hosts文件到其他节点。</p><p><strong>NameNode节点和ResourceManager不用重启</strong>。</p><p>在<strong>新节点上启动DataNode</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hdfs --daemon start datanode<br><span class="hljs-comment">#刷新节点信息</span><br>hfds dfsadmin -refreshNodes<br></code></pre></td></tr></table></figure><p>在<strong>新节点启动nodemanager</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">yarn --daemon start nodemanager<br></code></pre></td></tr></table></figure><h1 id="HA自动不能自动切换"><a href="#HA自动不能自动切换" class="headerlink" title="HA自动不能自动切换"></a>HA自动不能自动切换</h1><h2 id="错误现象1"><a href="#错误现象1" class="headerlink" title="错误现象1"></a>错误现象1</h2><p> invalid privatekey</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs prolog"><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">481</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: ====== <span class="hljs-symbol">Beginning</span> <span class="hljs-symbol">Service</span> <span class="hljs-symbol">Fencing</span> <span class="hljs-symbol">Process</span>... ======<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">481</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: <span class="hljs-symbol">Trying</span> method <span class="hljs-number">1</span>/<span class="hljs-number">2</span>: org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>(miao:<span class="hljs-number">22</span>)<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">485</span> <span class="hljs-symbol">WARN</span> org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>: <span class="hljs-symbol">Unable</span> to create <span class="hljs-symbol">SSH</span> session<br>com.jcraft.jsch.<span class="hljs-symbol">JSchException</span>: invalid privatekey: [<span class="hljs-symbol">B</span>@<span class="hljs-number">1</span>b7652da<br>        at com.jcraft.jsch.<span class="hljs-symbol">KeyPair</span>.load(<span class="hljs-symbol">KeyPair</span>.java:<span class="hljs-number">664</span>)<br>        at com.jcraft.jsch.<span class="hljs-symbol">KeyPair</span>.load(<span class="hljs-symbol">KeyPair</span>.java:<span class="hljs-number">561</span>)<br>        at com.jcraft.jsch.<span class="hljs-symbol">IdentityFile</span>.newInstance(<span class="hljs-symbol">IdentityFile</span>.java:<span class="hljs-number">40</span>)<br>        at com.jcraft.jsch.<span class="hljs-symbol">JSch</span>.addIdentity(<span class="hljs-symbol">JSch</span>.java:<span class="hljs-number">406</span>)<br>        at com.jcraft.jsch.<span class="hljs-symbol">JSch</span>.addIdentity(<span class="hljs-symbol">JSch</span>.java:<span class="hljs-number">366</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>.createSession(<span class="hljs-symbol">SshFenceByTcpPort</span>.java:<span class="hljs-number">121</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>.tryFence(<span class="hljs-symbol">SshFenceByTcpPort</span>.java:<span class="hljs-number">90</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>.fence(<span class="hljs-symbol">NodeFencer</span>.java:<span class="hljs-number">98</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.doFence(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">542</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.fenceOldActive(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">515</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.access$<span class="hljs-number">1100</span>(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">60</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>$<span class="hljs-symbol">ElectorCallbacks</span>.fenceOldActive(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">951</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.fenceOldActive(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">997</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.becomeActive(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">896</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.processResult(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">476</span>)<br>        at org.apache.zookeeper.<span class="hljs-symbol">ClientCnxn</span>$<span class="hljs-symbol">EventThread</span>.processEvent(<span class="hljs-symbol">ClientCnxn</span>.java:<span class="hljs-number">636</span>)<br>        at org.apache.zookeeper.<span class="hljs-symbol">ClientCnxn</span>$<span class="hljs-symbol">EventThread</span>.run(<span class="hljs-symbol">ClientCnxn</span>.java:<span class="hljs-number">510</span>)<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">485</span> <span class="hljs-symbol">WARN</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: <span class="hljs-symbol">Fencing</span> method org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>(miao:<span class="hljs-number">22</span>) was unsuccessful.<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">485</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: <span class="hljs-symbol">Trying</span> method <span class="hljs-number">2</span>/<span class="hljs-number">2</span>: org.apache.hadoop.ha.<span class="hljs-symbol">ShellCommandFencer</span>(/bin/true)<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">491</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">ShellCommandFencer</span>: <span class="hljs-symbol">Launched</span> fencing command <span class="hljs-string">&#x27;/bin/true&#x27;</span> with pid <span class="hljs-number">24463</span><br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">499</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: ====== <span class="hljs-symbol">Fencing</span> successful by method org.apache.hadoop.ha.<span class="hljs-symbol">ShellCommandFencer</span>(/bin/true) ======<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">499</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>: <span class="hljs-symbol">Writing</span> znode /hadoop-ha/hacluster/<span class="hljs-symbol">ActiveBreadCrumb</span> to indicate that the local node is the most recent active...<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">503</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>: <span class="hljs-symbol">Trying</span> to make <span class="hljs-symbol">NameNode</span> at hd003/<span class="hljs-number">192.168</span><span class="hljs-number">.64</span><span class="hljs-number">.53</span>:<span class="hljs-number">8020</span> active...<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">04</span>:<span class="hljs-number">14</span>:<span class="hljs-number">01</span>,<span class="hljs-number">692</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>: <span class="hljs-symbol">Successfully</span> transitioned <span class="hljs-symbol">NameNode</span> at hd003/<span class="hljs-number">192.168</span><span class="hljs-number">.64</span><span class="hljs-number">.53</span>:<span class="hljs-number">8020</span> to active state<br></code></pre></td></tr></table></figure><h2 id="错误现象2"><a href="#错误现象2" class="headerlink" title="错误现象2"></a>错误现象2</h2><p>Auth fail</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs prolog"><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">02</span>:<span class="hljs-number">52</span>:<span class="hljs-number">38</span>,<span class="hljs-number">916</span> <span class="hljs-symbol">INFO</span> org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>.jsch: <span class="hljs-symbol">Disconnecting</span> from hd003 port <span class="hljs-number">22</span><br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">02</span>:<span class="hljs-number">52</span>:<span class="hljs-number">38</span>,<span class="hljs-number">917</span> <span class="hljs-symbol">WARN</span> org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>: <span class="hljs-symbol">Unable</span> to connect to hd003 as user miao<br>com.jcraft.jsch.<span class="hljs-symbol">JSchException</span>: <span class="hljs-symbol">Auth</span> fail<br>        at com.jcraft.jsch.<span class="hljs-symbol">Session</span>.connect(<span class="hljs-symbol">Session</span>.java:<span class="hljs-number">519</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>.tryFence(<span class="hljs-symbol">SshFenceByTcpPort</span>.java:<span class="hljs-number">99</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>.fence(<span class="hljs-symbol">NodeFencer</span>.java:<span class="hljs-number">98</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.doFence(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">542</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.fenceOldActive(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">515</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.access$<span class="hljs-number">1100</span>(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">60</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>$<span class="hljs-symbol">ElectorCallbacks</span>.fenceOldActive(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">951</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.fenceOldActive(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">997</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.becomeActive(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">896</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.processResult(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">476</span>)<br>        at org.apache.zookeeper.<span class="hljs-symbol">ClientCnxn</span>$<span class="hljs-symbol">EventThread</span>.processEvent(<span class="hljs-symbol">ClientCnxn</span>.java:<span class="hljs-number">636</span>)<br>        at org.apache.zookeeper.<span class="hljs-symbol">ClientCnxn</span>$<span class="hljs-symbol">EventThread</span>.run(<span class="hljs-symbol">ClientCnxn</span>.java:<span class="hljs-number">510</span>)<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">02</span>:<span class="hljs-number">52</span>:<span class="hljs-number">38</span>,<span class="hljs-number">917</span> <span class="hljs-symbol">WARN</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: <span class="hljs-symbol">Fencing</span> method org.apache.hadoop.ha.<span class="hljs-symbol">SshFenceByTcpPort</span>(null) was unsuccessful.<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">02</span>:<span class="hljs-number">52</span>:<span class="hljs-number">38</span>,<span class="hljs-number">917</span> <span class="hljs-symbol">ERROR</span> org.apache.hadoop.ha.<span class="hljs-symbol">NodeFencer</span>: <span class="hljs-symbol">Unable</span> to fence service by any configured method.<br><span class="hljs-number">2022</span><span class="hljs-number">-11</span><span class="hljs-number">-08</span> <span class="hljs-number">02</span>:<span class="hljs-number">52</span>:<span class="hljs-number">38</span>,<span class="hljs-number">917</span> <span class="hljs-symbol">WARN</span> org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>: <span class="hljs-symbol">Exception</span> handling the winning of election<br>java.lang.<span class="hljs-symbol">RuntimeException</span>: <span class="hljs-symbol">Unable</span> to fence <span class="hljs-symbol">NameNode</span> at hd003/<span class="hljs-number">192.168</span><span class="hljs-number">.64</span><span class="hljs-number">.53</span>:<span class="hljs-number">8020</span><br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.doFence(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">543</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.fenceOldActive(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">515</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>.access$<span class="hljs-number">1100</span>(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">60</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ZKFailoverController</span>$<span class="hljs-symbol">ElectorCallbacks</span>.fenceOldActive(<span class="hljs-symbol">ZKFailoverController</span>.java:<span class="hljs-number">951</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.fenceOldActive(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">997</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.becomeActive(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">896</span>)<br>        at org.apache.hadoop.ha.<span class="hljs-symbol">ActiveStandbyElector</span>.processResult(<span class="hljs-symbol">ActiveStandbyElector</span>.java:<span class="hljs-number">476</span>)<br>        at org.apache.zookeeper.<span class="hljs-symbol">ClientCnxn</span>$<span class="hljs-symbol">EventThread</span>.processEvent(<span class="hljs-symbol">ClientCnxn</span>.java:<span class="hljs-number">636</span>)<br>        at org.apache.zookeeper.<span class="hljs-symbol">ClientCnxn</span>$<span class="hljs-symbol">EventThread</span>.run(<span class="hljs-symbol">ClientCnxn</span>.java:<span class="hljs-number">510</span>)<br></code></pre></td></tr></table></figure><h2 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h2><p>步骤：</p><ol><li>确保所有的NameNode节点间可以互相免密登录</li><li>配置ha-fencing规则为多个，防止其中一个失效 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span><br>          sshfence<br>          shell(/bin/true)<br>        <span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure> 在本次的日志异常中，发现sshfence出现错误，提示 invalid privatekey，使用方式2shell切换成功。（shell(&#x2F;bin&#x2F;true)）<ol><li>或使用自定义脚本，对失效的namenode节点的namenode进程手动kill 配置指定shell脚本路径， <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;<br>        &lt;value&gt;<br>          sshfence(miao:22)<br>          &lt;!-- shell(/bin/true) --&gt;<br>          shell(/opt/ha/hadoop-3.3.0/etc/hadoop/fence_script.sh --nameservice=<span class="hljs-variable">$target_nameserviceid</span> <span class="hljs-variable">$target_host</span> <span class="hljs-variable">$target_port</span>)<br>        &lt;/value&gt;<br>    &lt;/property&gt;<br></code></pre></td></tr></table></figure> 编写shell脚本，保存到指定路径， 增加运行权限： <strong>chmod +x fence_script.sh</strong> <strong>并分发到各namenode节点,</strong> fence_script.sh <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-----------fench----------&quot;</span><br>args=$*<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;<span class="hljs-variable">$args</span>&quot;</span><br>namespace=<span class="hljs-variable">$1</span><br>target_host=<span class="hljs-variable">$2</span><br>target_port=<span class="hljs-variable">$3</span><br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;target_host=[<span class="hljs-variable">$&#123;target_host&#125;</span>] target_port=[<span class="hljs-variable">$&#123;target_port&#125;</span>] &quot;</span><br>nc -z <span class="hljs-variable">$target_host</span> <span class="hljs-variable">$target_port</span><br><br><span class="hljs-keyword">if</span> [[ $? == 0 ]];<span class="hljs-keyword">then</span><br>    nn_pid=`ssh <span class="hljs-variable">$&#123;target_host&#125;</span> lsof -i:8020 |grep LISTEN |awk <span class="hljs-string">&#x27;&#123;print $2&#125;&#x27;</span>` <br>    ssh <span class="hljs-variable">$target_host</span> <span class="hljs-string">&quot;kill -9 <span class="hljs-variable">$&#123;nn_pid&#125;</span>&quot;</span><br><span class="hljs-keyword">fi</span><br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-----------fench-end----------&quot;</span><br></code></pre></td></tr></table></figure></li></ol></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>Hadoop官网配置说明[<strong>dfs.ha.fencing.methods</strong>]：<a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html">https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java_JUC</title>
      <link href="/java/java-juc%E5%A4%8D%E4%B9%A0/"/>
      <url>/java/java-juc%E5%A4%8D%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="Java-JUC"><a href="#Java-JUC" class="headerlink" title="Java-JUC"></a>Java-JUC</h1><h1 id="JUC简介"><a href="#JUC简介" class="headerlink" title="JUC简介"></a>JUC简介</h1><p>java.util.concurrent</p><p>java并发编程，提高程序运行效率。</p><p>充分提供cpu多核。提高吞吐量。</p><p>问题：</p><ol><li>线程安全问题</li><li>线程锁问题</li><li>线程性能问题</li></ol><h1 id="2-线程"><a href="#2-线程" class="headerlink" title="2.线程"></a>2.线程</h1><ul><li>用户线程（User Thread）一般情况new Thread都是用户线程</li><li>守护线程 (Daemon Thread)<ul><li>一种特殊的线程，在后台默默的完成系统性的工作，比如垃圾回收线程</li><li>守护线程作为一个服务线程，当服务对象没有了就没必须继续运行，就自动结束了。</li></ul></li></ul><h1 id="3-CompletableFuture"><a href="#3-CompletableFuture" class="headerlink" title="3. CompletableFuture"></a>3. CompletableFuture</h1><p>异步执行任务</p><ol><li>Runnable</li><li>Callable 有返回</li><li>Future→FutureTask <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Creates a &#123;<span class="hljs-doctag">@code</span> FutureTask&#125; that will, upon running, execute the</span><br><span class="hljs-comment">     * given &#123;<span class="hljs-doctag">@code</span> Callable&#125;.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span>  callable the callable task</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> NullPointerException if the callable is null</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">FutureTask</span><span class="hljs-params">(Callable&lt;V&gt; callable)</span> &#123;<br>        <span class="hljs-keyword">if</span> (callable == <span class="hljs-literal">null</span>)<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">NullPointerException</span>();<br>        <span class="hljs-built_in">this</span>.callable = callable;<br>        <span class="hljs-built_in">this</span>.state = NEW;       <span class="hljs-comment">// ensure visibility of callable</span><br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Creates a &#123;<span class="hljs-doctag">@code</span> FutureTask&#125; that will, upon running, execute the</span><br><span class="hljs-comment">     * given &#123;<span class="hljs-doctag">@code</span> Runnable&#125;, and arrange that &#123;<span class="hljs-doctag">@code</span> get&#125; will return the</span><br><span class="hljs-comment">     * given result on successful completion.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> runnable the runnable task</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> result the result to return on successful completion. If</span><br><span class="hljs-comment">     * you don&#x27;t need a particular result, consider using</span><br><span class="hljs-comment">     * constructions of the form:</span><br><span class="hljs-comment">     * &#123;<span class="hljs-doctag">@code</span> Future&lt;?&gt; f = new FutureTask&lt;Void&gt;(runnable, null)&#125;</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> NullPointerException if the runnable is null</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">FutureTask</span><span class="hljs-params">(Runnable runnable, V result)</span> &#123;<br>        <span class="hljs-built_in">this</span>.callable = Executors.callable(runnable, result);<br>        <span class="hljs-built_in">this</span>.state = NEW;       <span class="hljs-comment">// ensure visibility of callable</span><br>    &#125;<br></code></pre></td></tr></table></figure> 痛点：<ol><li>Thread</li></ol> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Allocates a new &#123;<span class="hljs-doctag">@code</span> Thread&#125; object. This constructor has the same</span><br><span class="hljs-comment">     * effect as &#123;<span class="hljs-doctag">@linkplain</span> #Thread(ThreadGroup,Runnable,String) Thread&#125;</span><br><span class="hljs-comment">     * &#123;<span class="hljs-doctag">@code</span> (null, target, name)&#125;.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span>  target</span><br><span class="hljs-comment">     *         the object whose &#123;<span class="hljs-doctag">@code</span> run&#125; method is invoked when this thread</span><br><span class="hljs-comment">     *         is started. If &#123;<span class="hljs-doctag">@code</span> null&#125;, this thread&#x27;s run method is invoked.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span>  name</span><br><span class="hljs-comment">     *         the name of the new thread</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Thread</span><span class="hljs-params">(Runnable target, String name)</span> &#123;<br>        init(<span class="hljs-literal">null</span>, target, name, <span class="hljs-number">0</span>);<br>    &#125;<br></code></pre></td></tr></table></figure><ol><li><p>多线程，又返回，异步任务</p><ol><li>FutureTask构造注入，实现了多线程，异步，又返回</li></ol><p> <img src="/img/Java-JUC-IMGS/Untitled.png" alt="Untitled"></p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">FutureTask</span>&lt;V&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">RunnableFuture</span>&lt;V&gt;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Creates a &#123;<span class="hljs-doctag">@code</span> FutureTask&#125; that will, upon running, execute the</span><br><span class="hljs-comment">     * given &#123;<span class="hljs-doctag">@code</span> Callable&#125;.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span>  callable the callable task</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> NullPointerException if the callable is null</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">FutureTask</span><span class="hljs-params">(Callable&lt;V&gt; callable)</span> &#123;<br>        <span class="hljs-keyword">if</span> (callable == <span class="hljs-literal">null</span>)<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">NullPointerException</span>();<br>        <span class="hljs-built_in">this</span>.callable = callable;<br>        <span class="hljs-built_in">this</span>.state = NEW;       <span class="hljs-comment">// ensure visibility of callable</span><br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Creates a &#123;<span class="hljs-doctag">@code</span> FutureTask&#125; that will, upon running, execute the</span><br><span class="hljs-comment">     * given &#123;<span class="hljs-doctag">@code</span> Runnable&#125;, and arrange that &#123;<span class="hljs-doctag">@code</span> get&#125; will return the</span><br><span class="hljs-comment">     * given result on successful completion.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> runnable the runnable task</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> result the result to return on successful completion. If</span><br><span class="hljs-comment">     * you don&#x27;t need a particular result, consider using</span><br><span class="hljs-comment">     * constructions of the form:</span><br><span class="hljs-comment">     * &#123;<span class="hljs-doctag">@code</span> Future&lt;?&gt; f = new FutureTask&lt;Void&gt;(runnable, null)&#125;</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@throws</span> NullPointerException if the runnable is null</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">FutureTask</span><span class="hljs-params">(Runnable runnable, V result)</span> &#123;<br>        <span class="hljs-built_in">this</span>.callable = Executors.callable(runnable, result);<br>        <span class="hljs-built_in">this</span>.state = NEW;       <span class="hljs-comment">// ensure visibility of callable</span><br>    &#125;<br></code></pre></td></tr></table></figure></li></ol><p> FutureTask优点：</p><p> 同时满足Runnable和Callable使用特点，配合线程池，提高程序效率。</p><p> 缺点：</p><ol><li><p>get():容易造成阻塞</p></li><li><p>isDone轮询: 耗费CPU资源</p></li><li><p><strong>Future→FutureTask → CompletableFuture</strong></p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CompletableFuture</span>&lt;T&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Future</span>&lt;T&gt;, CompletionStage&lt;T&gt; <br></code></pre></td></tr></table></figure></li></ol><p> 函数式编程：</p><p> <img src="/img/Java-JUC-IMGS/Untitled%201.png" alt="Untitled"></p><ol><li>CompletableFuture为何出现<ol><li>提供了一种观察者模式类似的机制，可以让任务执行完成后通知监听的一方。</li><li>对异步线程，想要获取结果，改进了FutureTask get阻塞获取结果的方式。</li></ol></li></ol><p> 实现代码：</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CompletableFuture</span>&lt;T&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Future</span>&lt;T&gt;, CompletionStage&lt;T&gt; &#123;<br></code></pre></td></tr></table></figure><p> <img src="/img/Java-JUC-IMGS/Untitled%202.png" alt="Untitled"></p><p> CompletionStage 是什么</p><p> <img src="/img/Java-JUC-IMGS/Untitled%203.png" alt="Untitled"></p><ol><li><p>CompletableFuture核心四个静态方法创建异步任务</p><ol><li><p>无返回值，两组：CompletableFuture.runAsync()</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Returns a new CompletableFuture that is asynchronously completed</span><br><span class="hljs-comment">     * by a task running in the &#123;<span class="hljs-doctag">@link</span> ForkJoinPool#commonPool()&#125; after</span><br><span class="hljs-comment">     * it runs the given action.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> runnable the action to run before completing the</span><br><span class="hljs-comment">     * returned CompletableFuture</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> the new CompletableFuture</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAsync</span><span class="hljs-params">(Runnable runnable)</span> &#123;<br>        <span class="hljs-keyword">return</span> asyncRunStage(asyncPool, runnable);<br>    &#125;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Returns a new CompletableFuture that is asynchronously completed</span><br><span class="hljs-comment">     * by a task running in the given executor after it runs the given</span><br><span class="hljs-comment">     * action.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> runnable the action to run before completing the</span><br><span class="hljs-comment">     * returned CompletableFuture</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> executor the executor to use for asynchronous execution</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> the new CompletableFuture</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAsync</span><span class="hljs-params">(Runnable runnable,</span><br><span class="hljs-params">                                                   Executor executor)</span> &#123;<br>        <span class="hljs-keyword">return</span> asyncRunStage(screenExecutor(executor), runnable);<br>    &#125;<br></code></pre></td></tr></table></figure></li><li><p>有返回值，两组：CompletableFuture.supplyAsync()</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Returns a new CompletableFuture that is asynchronously completed</span><br><span class="hljs-comment">     * by a task running in the &#123;<span class="hljs-doctag">@link</span> ForkJoinPool#commonPool()&#125; with</span><br><span class="hljs-comment">     * the value obtained by calling the given Supplier.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> supplier a function returning the value to be used</span><br><span class="hljs-comment">     * to complete the returned CompletableFuture</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> &lt;U&gt; the function&#x27;s return type</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> the new CompletableFuture</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">supplyAsync</span><span class="hljs-params">(Supplier&lt;U&gt; supplier)</span> &#123;<br>        <span class="hljs-keyword">return</span> asyncSupplyStage(asyncPool, supplier);<br>    &#125;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Returns a new CompletableFuture that is asynchronously completed</span><br><span class="hljs-comment">     * by a task running in the given executor with the value obtained</span><br><span class="hljs-comment">     * by calling the given Supplier.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> supplier a function returning the value to be used</span><br><span class="hljs-comment">     * to complete the returned CompletableFuture</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> executor the executor to use for asynchronous execution</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> &lt;U&gt; the function&#x27;s return type</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> the new CompletableFuture</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">supplyAsync</span><span class="hljs-params">(Supplier&lt;U&gt; supplier,</span><br><span class="hljs-params">                                                       Executor executor)</span> &#123;<br>        <span class="hljs-keyword">return</span> asyncSupplyStage(screenExecutor(executor), supplier);<br>    &#125;<br></code></pre></td></tr></table></figure><p> 不指定线程池，默认使用ForkJoinPool.commonPool（守护线程池）</p></li></ol><p> CompletableFuture有点：</p><ol><li>异步任务结束是，会自动回调某个对象方法（相对FutureTask减少了阻塞和轮询查询结果）。</li><li>主线程设置好回调后，不再关心异步任务执行，异步任务之间可以顺序执行。 </li><li>异步任务执行出错是，会自动回调某个对象的方法。</li></ol><p>  join和get方法获取返回值区别：</p><ol><li>get() 编译时会做异常检查让代码抛出异常</li><li>join() 编译时不做检测。两者作用一样。</li></ol></li></ol><h1 id="4-Java-”锁“"><a href="#4-Java-”锁“" class="headerlink" title="4. Java ”锁“"></a>4. Java ”锁“</h1><p> 这里先说一些理论信息；后续有更具体的讲解。</p><h1 id="5-LockSupport和线程中断"><a href="#5-LockSupport和线程中断" class="headerlink" title="5. LockSupport和线程中断"></a>5. LockSupport和线程中断</h1><h2 id="线程中断的三种方法：-多线程之间协同时，中断另外的线程）"><a href="#线程中断的三种方法：-多线程之间协同时，中断另外的线程）" class="headerlink" title="线程中断的三种方法：(多线程之间协同时，中断另外的线程）"></a>线程中断的三种方法：(多线程之间协同时，中断另外的线程）</h2><hr><ol><li>使用volatile实现中断</li><li>使用atomicBoolean</li><li>使用Thread.interrupt</li></ol><p> Thread-interrupt 源码详解：3个方法：</p><ol><li><p>interrupt() &#x2F;&#x2F; </p><p> 1.1 线程处于正常状态：将中断标志位 设置为true，线程不受影响（不会立刻停止），需要线程配合才能中断线程。（不活动的线程，不会产生任何影响）</p><p> 1.2 如果线程处于阻塞状态（wait，join ,sleep中断状态将被清除) 调用interrupt()，线程会退出阻塞状态，并抛出interruptedException </p></li><li><p>isInterrupted() &#x2F;&#x2F;判断此线程是否被中断</p></li><li><p>静态方法：  static<code>interrupted()//返回当前线程中断标志位，并将中断标志位清除，重新置为false</code></p></li></ol></li></ol><h2 id="LockSupport-线程等待唤醒机制"><a href="#LockSupport-线程等待唤醒机制" class="headerlink" title="LockSupport(线程等待唤醒机制)"></a>LockSupport(线程等待唤醒机制)</h2><h3 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h3><p>用于创建锁和其他同步类的的基本线程阻塞原语 </p><p>LockSupport中的park(),unpark()的作用分别是阻塞线程和解除阻塞线程  </p><p>线程阻塞的工具类。</p><h3 id="线程等待唤醒方法"><a href="#线程等待唤醒方法" class="headerlink" title="线程等待唤醒方法"></a>线程等待唤醒方法</h3><ol><li>Object中wait()让线程等待，Object.notify()唤醒线程。</li><li>JUC包中的lock.Condition的await()让线程等待，使用signal()唤醒线程。</li><li>LockSupport类可以阻塞当前线程及唤醒指定被阻塞的线程。</li></ol><p>线程等待唤醒发展过程：</p><p><img src="/img/Java-JUC-IMGS/Untitled%204.png" alt="Untitled"></p><p>Object-awit-notify结论：</p><ol><li>Object中的awit和notify实现等待唤醒必须放在同步块中，且成对使用</li><li>先wait后notify才OK，否则顺序不对也不行。</li></ol><p>JUC中lock.Condition-awit-signal结论：</p><ol><li>线程必要获得并持有锁（及在lock.lock和unlock中间），且成对使用。</li><li>必须要先等待后唤醒（先awit后signal）。线程才能被唤醒。</li></ol><p>LockSupport结论：</p><ol><li>正常+无锁块需求。</li><li>之前错误的先唤醒后等待，LockSupport照样支持。park，unpark无先后顺序。</li><li>成双成对要牢记。</li><li>LockSupport通行证(permit)只能有且最多一个，不能累计。</li></ol><hr><h2 id="6-Java内存模型-JMM"><a href="#6-Java内存模型-JMM" class="headerlink" title="6. Java内存模型(JMM)"></a>6. Java内存模型(JMM)</h2><p><img src="/img/Java-JUC-IMGS/Untitled%205.png" alt="Untitled"></p><p>JMM作用： 屏蔽掉各种硬件和各操作系统的内存访问差异。让java程序在各平台达到一致的内存访问效果。</p><p>概念介绍：</p><p>JMM本身是一种抽象概念并不真实存在，仅仅是描述的一组约定和规范。通过这组规定定义了程序中（尤其是多线程）各个变量的读写访问方式并决定了一个线程对共享变量的写入 何时以及如何变成对另外 一个线程可见，关键技术点都是围绕多线程的 原子性，可见性，有序性 展开。</p><p>原则： </p><p>JMM关键技术点都是围绕多线程的 原子性，可见性，有序性展开的。</p><p>能干啥？</p><ol><li>通过JMM实现线程和主内存之间的抽象关系。</li><li>屏蔽各个硬件平台和操作系统的内存访问差异，让Java程序在各平台下达到统一的内存访问效果。</li></ol><p>三大特性：</p><ol><li>可见性：变量存放于主内存中是，每个线程有自己的本地内存，数据copy自主内存，操作完后写入主内存。主内存中的变量对所有线程可见。及时可见。</li><li>原子性：在多线程环境下；同一个操作不能被其他线程打断。</li><li>有序性：指令重 排序</li></ol><p><strong>小结</strong></p><ol><li>所有的共享变量都存储在物理主内存中 </li><li>每个线程都有自己独立的工作内存，里面保存该线程使用到的变量副本（主内存中该变量的拷贝）</li><li>线程对共享变量所有的操作都必须在自己的内存中操作完后，再写回主内存，不能直接在主内存中操作。</li><li>不同线程间无法直接访问其他线程的工作内存。线程间变量值的传递需要通过主内存完成。</li></ol><p>多线程先行发现原则之 happens-before</p><p>总原则： 可见和顺序性</p><ol><li>如果一个操作happens-before另一操作，那么第一个的操作结果对第二个操作可见，且第一个操作的执行顺序排在第二个操作之前。</li><li>两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序执行，如果重排后执行的结果与happens-before关系执行的结果一致。那么重排并不非法。</li><li>先行发生原则-8原则</li></ol><p><img src="/img/Java-JUC-IMGS/Untitled%206.png" alt="Untitled"></p><h2 id="7-volatile-与-JMM"><a href="#7-volatile-与-JMM" class="headerlink" title="7. volatile 与 JMM"></a>7. volatile 与 JMM</h2><p>volatile作用：让变量变动时，立即刷新回主内存中并发出通知，对其他线程可见和有序，其他线程也从主内存中读取。</p><p>特点：</p><ol><li>可见性</li><li>有序性，排序要求，禁止重排</li></ol><p>volatile凭什么可以保证可见性和有序性？</p><p>反编译后发现变量会用 ACC_VOLATILE修饰,</p><p>即：JVM编译时,对volatile修饰变量会按照JMM规范在相应位置插入内存屏障。</p><p><strong>内存屏蔽。Memory Barrier； 又称</strong> 内存栅栏，是一类同步屏障指令。使得CPU或编译器对 屏障指令前后所发出的操作 执行一个排序约束。</p><p>volatile无法保证原子性。</p><p>内存屏障作用：</p><ol><li>禁止指令重排序。</li><li>读屏障：Load Barrier，读指令之前插入读屏障，让线程临时内存中的数据失效，重新会到主内存中进行获取最新数据。</li><li>写屏障：Store Barrier，写指令之后插入写屏障，强制把写缓冲区的数据刷写回主内存中。</li></ol><p>细分四种：</p><ol><li>loadload</li><li>storestore</li><li>storeload</li><li>loadstore</li></ol><p><img src="/img/Java-JUC-IMGS/Untitled%207.png" alt="Untitled"></p><p><strong>volatile可见性</strong></p><p>工作内存和主内存间的原子操作性-<strong>读写过程</strong></p><p><img src="/img/Java-JUC-IMGS/Untitled%208.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%209.png" alt="Untitled"></p><p><strong>volatile不保证原子，使用场景：</strong></p><ol><li>运算结果并不依赖变量的当前值，或能够确保只有单一线程修改变量值</li><li>变量不需要与其他的状态变量共同参与不变约束。</li></ol><p><strong>禁止指令重排</strong></p><p><img src="/img/Java-JUC-IMGS/Untitled%2010.png" alt="Untitled"></p><p>volatile三句话总结：</p><p><img src="/img/Java-JUC-IMGS/Untitled%2011.png" alt="Untitled"></p><h2 id="8-CAS-Compare-And-Swap-原子操作性"><a href="#8-CAS-Compare-And-Swap-原子操作性" class="headerlink" title="8. CAS(Compare And Swap)+ 原子操作性"></a>8. CAS(Compare And Swap)+ 原子操作性</h2><p>atomic类，乐观锁思想。替换synchronized保证原子操作</p><p>cas参数：自旋</p><ol><li>V内存地址</li><li>A旧的预期值</li><li>B新的值</li></ol><p>CAS是JDK提供的非阻塞原子操作，通过硬件保证了比较-更新的原子性。</p><p>CAS是一条CPU的原子指令（cmpxchg指令）不会造成数据不一致问题。Unsafe提供的CAS方法底层实现即为CPU（cmpxchg）指令</p><p><img src="/img/Java-JUC-IMGS/Untitled%2012.png" alt="Untitled"></p><p>AtomicInteger利用 CAS+volatile和native方法保证原子操作，避免synchronized的高开销，执行效率大为提升。</p><p>CAS自旋jdk实现</p><p><img src="/img/Java-JUC-IMGS/Untitled%2013.png" alt="Untitled"></p><p>compareAndSawpxxx底层汇编代码：</p><p><img src="/img/Java-JUC-IMGS/Untitled%2014.png" alt="Untitled"></p><p> cmpxchg指令：</p><p><img src="/img/Java-JUC-IMGS/Untitled%2015.png" alt="Untitled"></p><p><strong>CAS与自旋锁</strong></p><p>自旋锁（spinlock）</p><p>cas是自旋锁基础，cas利用cpu指令保证了原子性，达到锁的效果</p><p>自旋：采用循环方式去获取锁（do-while),当线程发现锁被占用是，不断判断循环去获取锁，直到成功;优点：减少线程上下文切换，缺点：消耗CPU。   </p><p>CAS缺点：</p><ol><li>循环时间长，CPU消耗高</li><li>ABA问题</li></ol><p>ABA问题解决方案：</p><ol><li>增加版本号&#x2F;戳记流水(<code>AtomicStampedReference</code>)</li></ol><h2 id="9-原子类"><a href="#9-原子类" class="headerlink" title="9. 原子类"></a>9. 原子类</h2><p>CAS—&gt;unsafe(cpu指令)—&gt;do-while —&gt; ABA —&gt; 版本号&#x2F;时间戳<code>AtomicStampedReference（版本号、时间戳）</code></p><p><code>AtomicMarkableReference(true/false-AtomicStampedReference简化版)</code></p><p>共16个类</p><p><img src="/img/Java-JUC-IMGS/Untitled%2016.png" alt="Untitled"></p><p>基本类</p><p>数组类</p><p>原子引用</p><p>原子字段类型：更加细粒度的原子操作 </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.company;<br><br><span class="hljs-keyword">import</span> java.util.concurrent.CountDownLatch;<br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicIntegerFieldUpdater;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyBank</span>&#123;<br>    String carNo=<span class="hljs-string">&quot;AA&quot;</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">volatile</span> <span class="hljs-type">int</span> money;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">transfer</span><span class="hljs-params">(MyBank myBank)</span>&#123;<br>        fieldUpdater.getAndIncrement(myBank);<br>    &#125;<br>    AtomicIntegerFieldUpdater&lt;MyBank&gt; fieldUpdater= AtomicIntegerFieldUpdater.newUpdater(MyBank.class,<span class="hljs-string">&quot;money&quot;</span>);<br><br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AtomicIntegerFieldReDemo</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-type">MyBank</span> <span class="hljs-variable">myBank</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">MyBank</span>();<br>        <span class="hljs-type">CountDownLatch</span> <span class="hljs-variable">cdl</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CountDownLatch</span>(<span class="hljs-number">10</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123;<br>            <span class="hljs-keyword">new</span> <span class="hljs-title class_">Thread</span>(()-&gt;&#123;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; <span class="hljs-number">1000</span>; j++) &#123;<br>                    myBank.transfer(myBank);<br>                &#125;<br>                cdl.countDown();<br>            &#125;,String.valueOf(i)).start();<br>        &#125;<br>        cdl.await();<br>        System.out.println(myBank.money);<br>    &#125;<br>&#125;`<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.company;<br><br><span class="hljs-keyword">import</span> java.util.concurrent.CountDownLatch;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><span class="hljs-keyword">import</span> java.util.concurrent.atomic.AtomicReferenceFieldUpdater;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCard</span>&#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">volatile</span> Boolean flag=Boolean.FALSE;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">init</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br><span class="hljs-comment">//        System.out.println(Thread.currentThread().getName()+&quot;\t init come in&quot;);</span><br>        <span class="hljs-keyword">if</span>(fieldUpdater.compareAndSet(<span class="hljs-built_in">this</span>,Boolean.FALSE,Boolean.TRUE))&#123;<br>            System.out.println(Thread.currentThread().getName()+<span class="hljs-string">&quot;\t init doing&quot;</span>);<br>            TimeUnit.SECONDS.sleep(<span class="hljs-number">2</span>);<br>            System.out.println(Thread.currentThread().getName()+<span class="hljs-string">&quot;\t init end&quot;</span>);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(Thread.currentThread().getName()+<span class="hljs-string">&quot;\t 有其他线程正在初始化中&quot;</span>);<br>        &#125;<br>    &#125;<br>    AtomicReferenceFieldUpdater&lt;MyCard,Boolean&gt; fieldUpdater =<br>            AtomicReferenceFieldUpdater.newUpdater(MyCard.class,Boolean.class,<span class="hljs-string">&quot;flag&quot;</span>);<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AtomicReferenceFieldUpdaterDemo</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> InterruptedException &#123;<br>        <span class="hljs-type">MyCard</span> <span class="hljs-variable">myCard</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">MyCard</span>();<br>        <span class="hljs-type">CountDownLatch</span> <span class="hljs-variable">cdl</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CountDownLatch</span>(<span class="hljs-number">5</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">5</span>; i++) &#123;<br>            <span class="hljs-keyword">new</span> <span class="hljs-title class_">Thread</span>(()-&gt; &#123;<br>                <span class="hljs-keyword">try</span> &#123;<br>                    myCard.init();<br>                &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>                    e.printStackTrace();<br>                &#125;<span class="hljs-keyword">finally</span> &#123;<br>                    cdl.countDown();<br>                &#125;<br>            &#125;,String.valueOf(i)).start();<br>        &#125;<br>        cdl.await();<br>        System.out.println(myCard.flag);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>synchronized , AtomicLong,LongAdder, LongAccumulator对比</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"> <br></code></pre></td></tr></table></figure><p>LongAdder效率更高的原因：</p><p><strong>化整为零</strong></p><p>求和结果：Base+Cell[]</p><p>LongAdder源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(<span class="hljs-type">long</span> x)</span> &#123;<br>        Cell[] as; <span class="hljs-type">long</span> b, v; <span class="hljs-type">int</span> m; Cell a;<br>        <span class="hljs-keyword">if</span> ((as = cells) != <span class="hljs-literal">null</span> || !casBase(b = base, b + x)) &#123;<br>            <span class="hljs-type">boolean</span> <span class="hljs-variable">uncontended</span> <span class="hljs-operator">=</span> <span class="hljs-literal">true</span>;<br>            <span class="hljs-keyword">if</span> (as == <span class="hljs-literal">null</span> || (m = as.length - <span class="hljs-number">1</span>) &lt; <span class="hljs-number">0</span> ||<br>                (a = as[getProbe() &amp; m]) == <span class="hljs-literal">null</span> ||<br>                !(uncontended = a.cas(v = a.value, v + x)))<br>                longAccumulate(x, <span class="hljs-literal">null</span>, uncontended);<br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Handles cases of updates involving initialization, resizing,</span><br><span class="hljs-comment">     * creating new Cells, and/or contention. See above for</span><br><span class="hljs-comment">     * explanation. This method suffers the usual non-modularity</span><br><span class="hljs-comment">     * problems of optimistic retry code, relying on rechecked sets of</span><br><span class="hljs-comment">     * reads.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> x the value</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> fn the update function, or null for add (this convention</span><br><span class="hljs-comment">     * avoids the need for an extra field or function in LongAdder).</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> wasUncontended false if CAS failed before call</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">longAccumulate</span><span class="hljs-params">(<span class="hljs-type">long</span> x, LongBinaryOperator fn,</span><br><span class="hljs-params">                              <span class="hljs-type">boolean</span> wasUncontended)</span> &#123;<br>        <span class="hljs-type">int</span> h;<br>        <span class="hljs-keyword">if</span> ((h = getProbe()) == <span class="hljs-number">0</span>) &#123;<br>            ThreadLocalRandom.current(); <span class="hljs-comment">// force initialization</span><br>            h = getProbe();<br>            wasUncontended = <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">collide</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>;                <span class="hljs-comment">// True if last slot nonempty</span><br>        <span class="hljs-keyword">for</span> (;;) &#123;<br>            Cell[] as; Cell a; <span class="hljs-type">int</span> n; <span class="hljs-type">long</span> v;<br>            <span class="hljs-keyword">if</span> ((as = cells) != <span class="hljs-literal">null</span> &amp;&amp; (n = as.length) &gt; <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">if</span> ((a = as[(n - <span class="hljs-number">1</span>) &amp; h]) == <span class="hljs-literal">null</span>) &#123;<br>                    <span class="hljs-keyword">if</span> (cellsBusy == <span class="hljs-number">0</span>) &#123;       <span class="hljs-comment">// Try to attach new Cell</span><br>                        <span class="hljs-type">Cell</span> <span class="hljs-variable">r</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Cell</span>(x);   <span class="hljs-comment">// Optimistically create</span><br>                        <span class="hljs-keyword">if</span> (cellsBusy == <span class="hljs-number">0</span> &amp;&amp; casCellsBusy()) &#123;<br>                            <span class="hljs-type">boolean</span> <span class="hljs-variable">created</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>;<br>                            <span class="hljs-keyword">try</span> &#123;               <span class="hljs-comment">// Recheck under lock</span><br>                                Cell[] rs; <span class="hljs-type">int</span> m, j;<br>                                <span class="hljs-keyword">if</span> ((rs = cells) != <span class="hljs-literal">null</span> &amp;&amp;<br>                                    (m = rs.length) &gt; <span class="hljs-number">0</span> &amp;&amp;<br>                                    rs[j = (m - <span class="hljs-number">1</span>) &amp; h] == <span class="hljs-literal">null</span>) &#123;<br>                                    rs[j] = r;<br>                                    created = <span class="hljs-literal">true</span>;<br>                                &#125;<br>                            &#125; <span class="hljs-keyword">finally</span> &#123;<br>                                cellsBusy = <span class="hljs-number">0</span>;<br>                            &#125;<br>                            <span class="hljs-keyword">if</span> (created)<br>                                <span class="hljs-keyword">break</span>;<br>                            <span class="hljs-keyword">continue</span>;           <span class="hljs-comment">// Slot is now non-empty</span><br>                        &#125;<br>                    &#125;<br>                    collide = <span class="hljs-literal">false</span>;<br>                &#125;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!wasUncontended)       <span class="hljs-comment">// CAS already known to fail</span><br>                    wasUncontended = <span class="hljs-literal">true</span>;      <span class="hljs-comment">// Continue after rehash</span><br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (a.cas(v = a.value, ((fn == <span class="hljs-literal">null</span>) ? v + x :<br>                                             fn.applyAsLong(v, x))))<br>                    <span class="hljs-keyword">break</span>;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (n &gt;= NCPU || cells != as)<br>                    collide = <span class="hljs-literal">false</span>;            <span class="hljs-comment">// At max size or stale</span><br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!collide)<br>                    collide = <span class="hljs-literal">true</span>;<br>                <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cellsBusy == <span class="hljs-number">0</span> &amp;&amp; casCellsBusy()) &#123;<br>                    <span class="hljs-keyword">try</span> &#123;<br>                        <span class="hljs-keyword">if</span> (cells == as) &#123;      <span class="hljs-comment">// Expand table unless stale</span><br>                            Cell[] rs = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Cell</span>[n &lt;&lt; <span class="hljs-number">1</span>];<br>                            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; n; ++i)<br>                                rs[i] = as[i];<br>                            cells = rs;<br>                        &#125;<br>                    &#125; <span class="hljs-keyword">finally</span> &#123;<br>                        cellsBusy = <span class="hljs-number">0</span>;<br>                    &#125;<br>                    collide = <span class="hljs-literal">false</span>;<br>                    <span class="hljs-keyword">continue</span>;                   <span class="hljs-comment">// Retry with expanded table</span><br>                &#125;<br>                h = advanceProbe(h);<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cellsBusy == <span class="hljs-number">0</span> &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123;<br>                <span class="hljs-type">boolean</span> <span class="hljs-variable">init</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>;<br>                <span class="hljs-keyword">try</span> &#123;                           <span class="hljs-comment">// Initialize table</span><br>                    <span class="hljs-keyword">if</span> (cells == as) &#123;<br>                        Cell[] rs = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Cell</span>[<span class="hljs-number">2</span>];<br>                        rs[h &amp; <span class="hljs-number">1</span>] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Cell</span>(x);<br>                        cells = rs;<br>                        init = <span class="hljs-literal">true</span>;<br>                    &#125;<br>                &#125; <span class="hljs-keyword">finally</span> &#123;<br>                    cellsBusy = <span class="hljs-number">0</span>;<br>                &#125;<br>                <span class="hljs-keyword">if</span> (init)<br>                    <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (casBase(v = base, ((fn == <span class="hljs-literal">null</span>) ? v + x :<br>                                        fn.applyAsLong(v, x))))<br>                <span class="hljs-keyword">break</span>;                          <span class="hljs-comment">// Fall back on using base</span><br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><ul><li>小结：<ol><li>AtomicLong<ol><li>原理：<ol><li>CAS+自旋</li><li>incremenAndGet</li></ol></li><li>场景：<ol><li>低并发下的全局计算</li><li>AtomicLong能保证并发情况下计算准确性，内部通过CAS来解决并发安全性问题</li></ol></li><li>缺陷:<ol><li>高并发下性能急剧下降，原因：自旋会成为瓶颈</li></ol></li></ol></li><li>LongAdder<ol><li>原理：<ol><li>CAS+BASE+Cell数组分散</li><li>空间换时间并分散了热点数据</li></ol></li><li>场景：<ol><li>高并发下的全局计算</li></ol></li><li>缺陷：<ol><li>sum求和后还有计算线程计算的话，结果不准，需所有线程完成后求和，最终结果准确。</li></ol></li></ol></li></ol></li></ul><h2 id="10-ThreadLocal"><a href="#10-ThreadLocal" class="headerlink" title="10. ThreadLocal"></a>10. ThreadLocal</h2><p>每个线程都有自己的专属本地变量副本，人手一份。解决线程安全问题。</p><p>Thread </p><p>ThreadLocal.ThreadLocalMap localMap &#x3D; null</p><p>ThreadLocalMap&lt;WeakRefrence<ThreadLocal>,Object&gt; </p><p>演变：</p><p><a href="https://www.bilibili.com/video/BV1ar4y1x727?p=100&spm_id_from=pageDriver&vd_source=225ceefcd8902367a0cec6eb7334a132&t=469.2">https://www.bilibili.com/video/BV1ar4y1x727?p=100&spm_id_from&#x3D;pageDriver&amp;vd_source&#x3D;225ceefcd8902367a0cec6eb7334a132&amp;t&#x3D;469.2</a></p><p>before： 群雄逐鹿起纷争</p><p>after： 人手一份天下安</p><p><img src="/img/Java-JUC-IMGS/Untitled%2017.png" alt="Untitled"></p><p><strong>注意</strong></p><p>使用完ThreadLocal后，需使用ThreadLocal.remove()清空，防止内存泄漏（因为ThreadLocalMap中的k是弱引用，但是V是强引用，会导致V不能被回收，需要手动remove去将V设置为Null，进行手动回收）。</p><p>Thread-ThreadLocal-ThrealocalMap三者关系：</p><p><img src="/img/Java-JUC-IMGS/Untitled%2018.png" alt="Untitled"></p><p>几个引用：</p><ol><li>强引用 Reference （默认创建的对象均为强引用，垃圾回收不能回收）</li><li>软引用  SoftReference 空间充足时GC不回收，空间不足GC会回收</li><li>弱引用  WareReference 只要有GC，就会回收</li><li>虚引用  PhantomReference  get一致返回null，需配合引用队列使用ReferenceQueue使用</li></ol><p>软引用和弱引用应用场景：</p><p>图片高速缓存。防止OOM</p><p>GCRoot 和 四个引用的关系</p><p><img src="/img/Java-JUC-IMGS/Untitled%2019.png" alt="Untitled"></p><p>为什么源码中ThreadLocalMap的K使用弱引用：减少内存泄漏  </p><p><img src="/img/Java-JUC-IMGS/Untitled%2020.png" alt="Untitled"></p><ul><li><strong>使用小结</strong></li></ul><ol><li>使用 <code>ThreadLocal.*withInitial*(() -&gt; 0)</code> 初始化</li><li>建议使用static 修饰ThreadLocal</li><li>一定要记得使用Thread.remove()方法进行清理，防止内存泄漏。</li></ol><p>ThreadLocal小结：</p><ol><li>TL并不解决线程间共享数据问题</li><li>适用于变量在线程间隔离且在方法间共享场景</li><li>通过隐式的在不同线程内创建独立副本，避免线程安全问题。</li><li>每个线程持有一个只属于自己的Map，并维护TheadLocalMap对象与具体实例的映射，该Map只被持有它的线程访问，故不存在线程安全问题。</li><li>ThreadLocalMap的Entry对ThreadLocalMap为弱引用，避免了ThreadLocal对象无法被回收问题。</li><li>都会通过remove()- expungStaleEntry,cleanSomeSlots,replcaceStateEntry三个三个方法回收键为null的entry对象的值，防止内存泄漏,属于安全加固方法。</li></ol><p><img src="/img/Java-JUC-IMGS/Untitled%2021.png" alt="Untitled"></p><h2 id="Java对象内存布局与对象头"><a href="#Java对象内存布局与对象头" class="headerlink" title="Java对象内存布局与对象头"></a>Java对象内存布局与对象头</h2><p>new Object在JVM中存放位置 和 构成</p><p><img src="/img/Java-JUC-IMGS/Untitled%2022.png" alt="Untitled"></p><p>对象实例构成部分：</p><ol><li>对象头<ol><li>对象标记Mark Word<ol><li>HashCode</li><li>分代年龄</li><li>锁标记等信息</li></ol></li><li>类元信息（类型指针）Class Pointer</li><li>长度 length（对象数组专有）</li></ol></li><li>实例数据</li><li>对其填充</li></ol><p><img src="/img/Java-JUC-IMGS/Untitled%2023.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%2024.png" alt="Untitled"></p><h3 id="对象标记的结构组成"><a href="#对象标记的结构组成" class="headerlink" title="对象标记的结构组成"></a>对象标记的结构组成</h3><p><img src="/img/Java-JUC-IMGS/Untitled%2025.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%2026.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%2027.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%2028.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%2029.png" alt="Untitled"></p><h3 id="类元信息-类型指针）Class-Pointer"><a href="#类元信息-类型指针）Class-Pointer" class="headerlink" title="类元信息 (类型指针）Class Pointer"></a>类元信息 (类型指针）Class Pointer</h3><p>Object o &#x3D; new Object</p><p>Object  即为类型指针</p><p><img src="/img/Java-JUC-IMGS/Untitled%2030.png" alt="Untitled"></p><p>  对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象属于那个类的实例。</p><h3 id="JOL打印对象头信息"><a href="#JOL打印对象头信息" class="headerlink" title="JOL打印对象头信息"></a>JOL打印对象头信息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> org.openjdk.jol.info.ClassLayout;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ObjectJOLDemo</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-type">Object</span> <span class="hljs-variable">o</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>();<br>        System.out.println(ClassLayout.parseInstance(o).toPrintable());<br>        <span class="hljs-type">Consumer</span> <span class="hljs-variable">consumer</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Consumer</span>();<br>        System.out.println(ClassLayout.parseInstance(consumer).toPrintable());<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Consumer</span>&#123;<br><span class="hljs-comment">// 1. 第一种情况，无属性时，dv&#x27;xd&#x27;tb</span><br>    <span class="hljs-type">int</span> age;<br>    <span class="hljs-type">boolean</span> flag;<br>&#125; <br></code></pre></td></tr></table></figure><p>输出信息：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs prolog">java.lang.<span class="hljs-symbol">Object</span> object internals:<br> <span class="hljs-symbol">OFFSET</span>  <span class="hljs-symbol">SIZE</span>   <span class="hljs-symbol">TYPE</span> <span class="hljs-symbol">DESCRIPTION</span>                               <span class="hljs-symbol">VALUE</span><br>      <span class="hljs-number">0</span>     <span class="hljs-number">4</span>        (object header)                           <span class="hljs-number">01</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> (<span class="hljs-number">00000001</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span>) (<span class="hljs-number">1</span>)<br>      <span class="hljs-number">4</span>     <span class="hljs-number">4</span>        (object header)                           <span class="hljs-number">00</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> (<span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span>) (<span class="hljs-number">0</span>)<br>      <span class="hljs-number">8</span>     <span class="hljs-number">4</span>        (object header)                           <span class="hljs-number">28</span> <span class="hljs-number">0</span>f <span class="hljs-number">00</span> <span class="hljs-number">00</span> (<span class="hljs-number">00101000</span> <span class="hljs-number">00001111</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span>) (<span class="hljs-number">3880</span>)<br>     <span class="hljs-number">12</span>     <span class="hljs-number">4</span>        (loss due to the next object alignment)<br><span class="hljs-symbol">Instance</span> size: <span class="hljs-number">16</span> bytes<br><span class="hljs-symbol">Space</span> losses: <span class="hljs-number">0</span> bytes internal + <span class="hljs-number">4</span> bytes external = <span class="hljs-number">4</span> bytes total<br><br>com.company.<span class="hljs-symbol">Consumer</span> object internals:<br> <span class="hljs-symbol">OFFSET</span>  <span class="hljs-symbol">SIZE</span>      <span class="hljs-symbol">TYPE</span> <span class="hljs-symbol">DESCRIPTION</span>                               <span class="hljs-symbol">VALUE</span><br>      <span class="hljs-number">0</span>     <span class="hljs-number">4</span>           (object header)                           <span class="hljs-number">01</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> (<span class="hljs-number">00000001</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span>) (<span class="hljs-number">1</span>)<br>      <span class="hljs-number">4</span>     <span class="hljs-number">4</span>           (object header)                           <span class="hljs-number">00</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> <span class="hljs-number">00</span> (<span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span> <span class="hljs-number">00000000</span>) (<span class="hljs-number">0</span>)<br>      <span class="hljs-number">8</span>     <span class="hljs-number">4</span>           (object header)                           <span class="hljs-number">00</span> <span class="hljs-number">8</span>a <span class="hljs-number">07</span> <span class="hljs-number">00</span> (<span class="hljs-number">00000000</span> <span class="hljs-number">10001010</span> <span class="hljs-number">00000111</span> <span class="hljs-number">00000000</span>) (<span class="hljs-number">494080</span>)<br>     <span class="hljs-number">12</span>     <span class="hljs-number">4</span>       int <span class="hljs-symbol">Consumer</span>.age                              <span class="hljs-number">0</span><br>     <span class="hljs-number">16</span>     <span class="hljs-number">1</span>   boolean <span class="hljs-symbol">Consumer</span>.flag                             false<br>     <span class="hljs-number">17</span>     <span class="hljs-number">7</span>           (loss due to the next object alignment)<br><span class="hljs-symbol">Instance</span> size: <span class="hljs-number">24</span> bytes<br><span class="hljs-symbol">Space</span> losses: <span class="hljs-number">0</span> bytes internal + <span class="hljs-number">7</span> bytes external = <span class="hljs-number">7</span> bytes total<br></code></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs prolog">java -<span class="hljs-symbol">XX</span>:+<span class="hljs-symbol">PrintCommandLineFlags</span> -version<br>-<span class="hljs-symbol">XX</span>:<span class="hljs-symbol">InitialHeapSize</span>=<span class="hljs-number">1073741824</span> -<span class="hljs-symbol">XX</span>:<span class="hljs-symbol">MaxHeapSize</span>=<span class="hljs-number">17179869184</span> -<span class="hljs-symbol">XX</span>:+<span class="hljs-symbol">PrintCommandLineFlags</span> -<span class="hljs-symbol">XX</span>:+<span class="hljs-symbol">UseCompressedClassPointers</span> -<span class="hljs-symbol">XX</span>:+<span class="hljs-symbol">UseCompressedOops</span> -<span class="hljs-symbol">XX</span>:+<span class="hljs-symbol">UseParallelGC</span><br>openjdk version <span class="hljs-string">&quot;1.8.0_312&quot;</span><br></code></pre></td></tr></table></figure><p>java 默认开启了类型指针压缩</p><ol><li><p>开启压缩后对象头占用 8(mark_word)+4(class_pointer)+4(对其补充) &#x3D; 16字节</p></li><li><p>关闭压缩（-XX:-UseCompressedClassPointers）</p><p> 对象头占用：8(mark_word)+8(class_pointer)&#x3D;16字节</p></li></ol><p>结论： 对象头占用16个字节。</p><h2 id="12-synchronized与锁升级"><a href="#12-synchronized与锁升级" class="headerlink" title="12. synchronized与锁升级"></a>12. synchronized与锁升级</h2><p><a href="https://www.bilibili.com/video/BV1ar4y1x727?p=121&share_source=copy_pc">https://www.bilibili.com/video/BV1ar4y1x727?p=121&share_source&#x3D;copy_pc</a></p><p>synchronized用的锁是存在Java对象头里的Mark Word中，锁升级主要依赖MarkWord中锁标志位 和 释放偏向锁标志位。</p><p>锁状态升级和对象头(mark-word)中的锁位关系 </p><p><img src="/img/Java-JUC-IMGS/Untitled%2031.png" alt="Untitled"></p><p><img src="/img/Java-JUC-IMGS/Untitled%2032.png" alt="Untitled"></p><p> 无锁： 0 01</p><ol><li><p><strong>偏向锁：单线程竞争 1 01</strong></p><ol><li>当线程A第一次竞争到锁时，通过操作修改MarkWord中的偏向线程ID、偏向模式。如果不存在其他线程竞争，则持有偏向锁的线程将永远不需要同步。</li><li>当一个对象一直被同一个线程竞争得到。此时锁的等级为偏向锁。（由于只有一个线程，那么该线程在后续访问时便自动获得锁）</li></ol></li><li><p><strong>轻量级锁  0 00</strong></p><ol><li><p>是什么？多线程竞争，但任一时刻最多只有一个线程竞争;不存在过于激烈，且没有线程阻塞。</p></li><li><p>主要作用</p><ol><li>有线程参与竞争，但是获取锁的冲突时间极短</li><li>本质就是自旋锁CAS.</li></ol><p> 作用总结：</p><ol><li>目的是在没有多线程竞争下，通过CAS减少重量级锁使用操作系统互斥量产生的性能消耗；先自旋，CAS自旋到达一定次数才升级阻塞（重量级锁）。</li><li>升级时机：当关闭偏向锁功能或多线程竞争偏向锁会导致锁升级为轻量锁。</li></ol></li><li><p>与偏向锁区别：</p><ol><li>争夺轻量锁失败时，自旋尝试抢占锁。</li><li>轻量锁每次退出同步块都需要释放锁，而偏向锁在竞争发生时才释放锁。</li></ol></li></ol></li><li><p><strong>重量级锁 010 指向互斥量的指针（monitor对象）</strong></p><ol><li>大量线程参与锁竞争，冲突性很高</li></ol></li><li><p><strong>小结</strong>：</p><ol><li><p>锁升级后hashcode去哪了？</p><ol><li>无锁状态下，hashcode和gc-age存放于对象头的mark-word中</li><li>偏向锁和hashCode无法一起共存，及对象计算过hashcode()则该对象无法被设置为偏向锁，直接升级为轻量级锁。若当前对象处于偏向锁时，再计算hashcode，则该对象会立刻升级为重量级锁。 </li><li>升级为轻量锁时，JVM会在当前线程的栈中创建一个锁记录（Lock Record) 用于存储对象的MarkWord拷贝。该拷贝可包含hashcode，gc-age等，释放锁后将这些信息写回到对象头中。轻量级锁可以与hashcode共存。</li><li>升级为重量级锁后， MarkWord保存的重量级锁指针，代表重量级锁的ObjectMonitor类里有字段记录非加锁状态下的MarkWord，锁释放后，也会将信息写回到对象头中。</li></ol></li><li><p>各个锁优缺点，synchronized锁升级和实现原理</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2033.png" alt="Untitled"></p></li><li><p>JIT-锁消除-锁粗化</p></li></ol><p> <strong>锁升级过程和逻辑图</strong> </p><p> <img src="/img/Java-JUC-IMGS/Untitled%2034.png" alt="Untitled"></p></li></ol><h2 id="13-AbstractQueuedSynchronizer之AQS"><a href="#13-AbstractQueuedSynchronizer之AQS" class="headerlink" title="13. AbstractQueuedSynchronizer之AQS"></a>13. AbstractQueuedSynchronizer之A<strong>QS</strong></h2><h3 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h3><ol><li><p>是什么?</p><ol><li><p>AQS 抽象队列同步器</p></li><li><p>用来实现锁或者其他同步组件的公共基础部分的抽象实现，是重量级基础框架及整个JUC体系基石，主要用于解决分配给”谁“的问题。</p></li><li><p>整体就是抽象一个FIFO队列来完成资源获取线程排队工作，通过Int变量表示持有锁的状态。</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2035.png" alt="Untitled"></p></li><li><p>基本结构：</p><p> 源码：</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2036.png" alt="Untitled"></p><p> CLH队列（双向队列）尾入头出</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2037.png" alt="Untitled"></p><p> AQS体系结构</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2038.png" alt="Untitled"></p></li><li><p>小结：</p><ol><li>AQS&#x3D;state（状态变量）+ CLH双端队列</li><li>有阻塞就需要排队，实现排队就必然有队列。</li><li><strong>volatile+cas机制实现了锁模板，保证了代码的同步性和可见性，而AQS封装了线程阻塞等待挂起，解锁唤醒其他线程的逻辑，AQS子类只需根据状态变量（state）判断获取锁，是否释放锁，使用LockSupport挂起，唤醒线程即可。</strong></li></ol></li></ol></li><li><p>AQS-内部类Node</p><ol><li><p>结构和属性说明：</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2039.png" alt="Untitled"></p><p> <img src="/img/Java-JUC-IMGS/Untitled%2040.png" alt="Untitled"></p></li></ol></li><li><p>ReentrantLock为例</p><ol><li><p>公平锁</p></li><li><p>非公平锁</p><p> 两者区别：</p><p> 公平锁比非公平锁多了一个判断列队中是否有前置Node <code>hasQueuedPredecessors()</code>，如果有则进入AQS队列进行排队，非公平则不判断直接进行抢锁。</p><p> 源码</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Acquires in exclusive mode, ignoring interrupts.  Implemented</span><br><span class="hljs-comment">     * by invoking at least once &#123;<span class="hljs-doctag">@link</span> #tryAcquire&#125;,</span><br><span class="hljs-comment">     * returning on success.  Otherwise the thread is queued, possibly</span><br><span class="hljs-comment">     * repeatedly blocking and unblocking, invoking &#123;<span class="hljs-doctag">@link</span></span><br><span class="hljs-comment">     * #tryAcquire&#125; until success.  This method can be used</span><br><span class="hljs-comment">     * to implement method &#123;<span class="hljs-doctag">@link</span> Lock#lock&#125;.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> arg the acquire argument.  This value is conveyed to</span><br><span class="hljs-comment">     *        &#123;<span class="hljs-doctag">@link</span> #tryAcquire&#125; but is otherwise uninterpreted and</span><br><span class="hljs-comment">     *        can represent anything you like.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@ReservedStackAccess</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">acquire</span><span class="hljs-params">(<span class="hljs-type">int</span> arg)</span> &#123;<br>        <span class="hljs-keyword">if</span> (!tryAcquire(arg) &amp;&amp;<br>            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))<br>            selfInterrupt();<br>    &#125;<br></code></pre></td></tr></table></figure></li></ol></li></ol><h3 id="ReentrantLock源码解析"><a href="#ReentrantLock源码解析" class="headerlink" title="ReentrantLock源码解析"></a>ReentrantLock源码解析</h3><p>总体步骤：非公平为例</p><ol><li>重试获取锁（cas获取state状态为）</li><li>获取不到锁进入队列进行排队(addWaiter)</li><li>队列中由上一个进程完成后，触发LockSupport.unpeak(thread)唤醒触发下一个线程的运行或锁的再次争抢。</li></ol><p>NonfairSync extends Sync extends AQS </p><p>lock.lock()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">NonfairSync</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Sync</span> &#123;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">serialVersionUID</span> <span class="hljs-operator">=</span> <span class="hljs-number">7316153563782823691L</span>;<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Performs lock.  Try immediate barge, backing up to normal</span><br><span class="hljs-comment">         * acquire on failure.</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-meta">@ReservedStackAccess</span><br>        <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">lock</span><span class="hljs-params">()</span> &#123;<br>            <span class="hljs-keyword">if</span> (compareAndSetState(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br>                setExclusiveOwnerThread(Thread.currentThread());<br>            <span class="hljs-keyword">else</span><br>                acquire(<span class="hljs-number">1</span>);<br>        &#125;<br><br>        <span class="hljs-keyword">protected</span> <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">(<span class="hljs-type">int</span> acquires)</span> &#123;<br>            <span class="hljs-keyword">return</span> nonfairTryAcquire(acquires);<br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><p>acquire(1)： 整体步骤：</p><ol><li>尝试获取锁，</li><li>如果尝试获取锁失败，则加入等待队列的队尾中。</li><li>在队列中排队，无限判断前一个线程是否Head，如果是Head  尝试获取锁执行，若不是在Head则利用LockSupport.peak()对线程进行挂起，直到其他线程完成后unlock锁后，当前线程排到Head再进行抢占锁。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@ReservedStackAccess</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">acquire</span><span class="hljs-params">(<span class="hljs-type">int</span> arg)</span> &#123;<br>        <span class="hljs-keyword">if</span> (!tryAcquire(arg) &amp;&amp;<br>            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))<br>            selfInterrupt();<br>    &#125;<br></code></pre></td></tr></table></figure><pre><code class="hljs"> nonfairTryAcquire(1)</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Performs non-fair tryLock.  tryAcquire is implemented in</span><br><span class="hljs-comment">         * subclasses, but both need nonfair try for trylock method.</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-meta">@ReservedStackAccess</span><br>        <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">nonfairTryAcquire</span><span class="hljs-params">(<span class="hljs-type">int</span> acquires)</span> &#123;<br>            <span class="hljs-keyword">final</span> <span class="hljs-type">Thread</span> <span class="hljs-variable">current</span> <span class="hljs-operator">=</span> Thread.currentThread();<br>            <span class="hljs-type">int</span> <span class="hljs-variable">c</span> <span class="hljs-operator">=</span> getState();<br>            <span class="hljs-keyword">if</span> (c == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">if</span> (compareAndSetState(<span class="hljs-number">0</span>, acquires)) &#123;<br>                    setExclusiveOwnerThread(current);<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (current == getExclusiveOwnerThread()) &#123;<br>                <span class="hljs-type">int</span> <span class="hljs-variable">nextc</span> <span class="hljs-operator">=</span> c + acquires;<br>                <span class="hljs-keyword">if</span> (nextc &lt; <span class="hljs-number">0</span>) <span class="hljs-comment">// overflow</span><br>                    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Error</span>(<span class="hljs-string">&quot;Maximum lock count exceeded&quot;</span>);<br>                setState(nextc);<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br></code></pre></td></tr></table></figure><p>addWaiter(Node mode)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Creates and enqueues node for current thread and given mode.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> the new node</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> Node <span class="hljs-title function_">addWaiter</span><span class="hljs-params">(Node mode)</span> &#123;<br>        <span class="hljs-type">Node</span> <span class="hljs-variable">node</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Node</span>(Thread.currentThread(), mode);<br>        <span class="hljs-comment">// Try the fast path of enq; backup to full enq on failure</span><br>        <span class="hljs-type">Node</span> <span class="hljs-variable">pred</span> <span class="hljs-operator">=</span> tail;<br>        <span class="hljs-keyword">if</span> (pred != <span class="hljs-literal">null</span>) &#123;<br>            node.prev = pred;<br>            <span class="hljs-keyword">if</span> (compareAndSetTail(pred, node)) &#123;<br>                pred.next = node;<br>                <span class="hljs-keyword">return</span> node;<br>            &#125;<br>        &#125;<br>        enq(node);<br>        <span class="hljs-keyword">return</span> node;<br>    &#125;<br></code></pre></td></tr></table></figure><p>acquireQueued(final Node node, int arg)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Acquires in exclusive uninterruptible mode for thread already in</span><br><span class="hljs-comment">     * queue. Used by condition wait methods as well as acquire.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> node the node</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> arg the acquire argument</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> &#123;<span class="hljs-doctag">@code</span> true&#125; if interrupted while waiting</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@ReservedStackAccess</span><br>    <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">acquireQueued</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Node node, <span class="hljs-type">int</span> arg)</span> &#123;<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">failed</span> <span class="hljs-operator">=</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-type">boolean</span> <span class="hljs-variable">interrupted</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>;<br>            <span class="hljs-keyword">for</span> (;;) &#123;<br>                <span class="hljs-keyword">final</span> <span class="hljs-type">Node</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> node.predecessor();<br>                <span class="hljs-keyword">if</span> (p == head &amp;&amp; tryAcquire(arg)) &#123;<br>                    setHead(node);<br>                    p.next = <span class="hljs-literal">null</span>; <span class="hljs-comment">// help GC</span><br>                    failed = <span class="hljs-literal">false</span>;<br>                    <span class="hljs-keyword">return</span> interrupted;<br>                &#125;<br>                <span class="hljs-keyword">if</span> (shouldParkAfterFailedAcquire(p, node) &amp;&amp;<br>                    parkAndCheckInterrupt())<br>                    interrupted = <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125; <span class="hljs-keyword">finally</span> &#123;<br>            <span class="hljs-keyword">if</span> (failed)<br>                cancelAcquire(node);<br>        &#125;<br>    &#125;<br><br>  <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Checks and updates status for a node that failed to acquire.</span><br><span class="hljs-comment">     * Returns true if thread should block. This is the main signal</span><br><span class="hljs-comment">     * control in all acquire loops.  Requires that pred == node.prev.</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> pred node&#x27;s predecessor holding status</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> node the node</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> &#123;<span class="hljs-doctag">@code</span> true&#125; if thread should block</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">shouldParkAfterFailedAcquire</span><span class="hljs-params">(Node pred, Node node)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">ws</span> <span class="hljs-operator">=</span> pred.waitStatus;<br>        <span class="hljs-keyword">if</span> (ws == Node.SIGNAL)<br>            <span class="hljs-comment">/*</span><br><span class="hljs-comment">             * This node has already set status asking a release</span><br><span class="hljs-comment">             * to signal it, so it can safely park.</span><br><span class="hljs-comment">             */</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">if</span> (ws &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-comment">/*</span><br><span class="hljs-comment">             * Predecessor was cancelled. Skip over predecessors and</span><br><span class="hljs-comment">             * indicate retry.</span><br><span class="hljs-comment">             */</span><br>            <span class="hljs-keyword">do</span> &#123;<br>                node.prev = pred = pred.prev;<br>            &#125; <span class="hljs-keyword">while</span> (pred.waitStatus &gt; <span class="hljs-number">0</span>);<br>            pred.next = node;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">/*</span><br><span class="hljs-comment">             * waitStatus must be 0 or PROPAGATE.  Indicate that we</span><br><span class="hljs-comment">             * need a signal, but don&#x27;t park yet.  Caller will need to</span><br><span class="hljs-comment">             * retry to make sure it cannot acquire before parking.</span><br><span class="hljs-comment">             */</span><br>            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><br>     <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * Convenience method to park and then check if interrupted</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> &#123;<span class="hljs-doctag">@code</span> true&#125; if interrupted</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">parkAndCheckInterrupt</span><span class="hljs-params">()</span> &#123;<br>        LockSupport.park(<span class="hljs-built_in">this</span>);<br>        <span class="hljs-keyword">return</span> Thread.interrupted();<br>    &#125;<br></code></pre></td></tr></table></figure><p>cancelAcquire()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// Utilities for various versions of acquire</span><br><br>  <span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Cancels an ongoing attempt to acquire.</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * <span class="hljs-doctag">@param</span> node the node</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">cancelAcquire</span><span class="hljs-params">(Node node)</span> &#123;<br>      <span class="hljs-comment">// Ignore if node doesn&#x27;t exist</span><br>      <span class="hljs-keyword">if</span> (node == <span class="hljs-literal">null</span>)<br>          <span class="hljs-keyword">return</span>;<br><br>      node.thread = <span class="hljs-literal">null</span>;<br><br>      <span class="hljs-comment">// Skip cancelled predecessors</span><br>      <span class="hljs-type">Node</span> <span class="hljs-variable">pred</span> <span class="hljs-operator">=</span> node.prev;<br>      <span class="hljs-keyword">while</span> (pred.waitStatus &gt; <span class="hljs-number">0</span>)<br>          node.prev = pred = pred.prev;<br><br>      <span class="hljs-comment">// predNext is the apparent node to unsplice. CASes below will</span><br>      <span class="hljs-comment">// fail if not, in which case, we lost race vs another cancel</span><br>      <span class="hljs-comment">// or signal, so no further action is necessary.</span><br>      <span class="hljs-type">Node</span> <span class="hljs-variable">predNext</span> <span class="hljs-operator">=</span> pred.next;<br><br>      <span class="hljs-comment">// Can use unconditional write instead of CAS here.</span><br>      <span class="hljs-comment">// After this atomic step, other Nodes can skip past us.</span><br>      <span class="hljs-comment">// Before, we are free of interference from other threads.</span><br>      node.waitStatus = Node.CANCELLED;<br><br>      <span class="hljs-comment">// If we are the tail, remove ourselves.</span><br>      <span class="hljs-keyword">if</span> (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123;<br>          compareAndSetNext(pred, predNext, <span class="hljs-literal">null</span>);<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>          <span class="hljs-comment">// If successor needs signal, try to set pred&#x27;s next-link</span><br>          <span class="hljs-comment">// so it will get one. Otherwise wake it up to propagate.</span><br>          <span class="hljs-type">int</span> ws;<br>          <span class="hljs-keyword">if</span> (pred != head &amp;&amp;<br>              ((ws = pred.waitStatus) == Node.SIGNAL ||<br>               (ws &lt;= <span class="hljs-number">0</span> &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp;<br>              pred.thread != <span class="hljs-literal">null</span>) &#123;<br>              <span class="hljs-type">Node</span> <span class="hljs-variable">next</span> <span class="hljs-operator">=</span> node.next;<br>              <span class="hljs-keyword">if</span> (next != <span class="hljs-literal">null</span> &amp;&amp; next.waitStatus &lt;= <span class="hljs-number">0</span>)<br>                  compareAndSetNext(pred, predNext, next);<br>          &#125; <span class="hljs-keyword">else</span> &#123;<br>              unparkSuccessor(node);<br>          &#125;<br><br>          node.next = node; <span class="hljs-comment">// help GC</span><br>      &#125;<br>  &#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">   * Wakes up node&#x27;s successor, if one exists.</span><br><span class="hljs-comment">   *</span><br><span class="hljs-comment">   * <span class="hljs-doctag">@param</span> node the node</span><br><span class="hljs-comment">   */</span><br>  <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">unparkSuccessor</span><span class="hljs-params">(Node node)</span> &#123;<br>      <span class="hljs-comment">/*</span><br><span class="hljs-comment">       * If status is negative (i.e., possibly needing signal) try</span><br><span class="hljs-comment">       * to clear in anticipation of signalling.  It is OK if this</span><br><span class="hljs-comment">       * fails or if status is changed by waiting thread.</span><br><span class="hljs-comment">       */</span><br>      <span class="hljs-type">int</span> <span class="hljs-variable">ws</span> <span class="hljs-operator">=</span> node.waitStatus;<br>      <span class="hljs-keyword">if</span> (ws &lt; <span class="hljs-number">0</span>)<br>          compareAndSetWaitStatus(node, ws, <span class="hljs-number">0</span>);<br><br>      <span class="hljs-comment">/*</span><br><span class="hljs-comment">       * Thread to unpark is held in successor, which is normally</span><br><span class="hljs-comment">       * just the next node.  But if cancelled or apparently null,</span><br><span class="hljs-comment">       * traverse backwards from tail to find the actual</span><br><span class="hljs-comment">       * non-cancelled successor.</span><br><span class="hljs-comment">       */</span><br>      <span class="hljs-type">Node</span> <span class="hljs-variable">s</span> <span class="hljs-operator">=</span> node.next;<br>      <span class="hljs-keyword">if</span> (s == <span class="hljs-literal">null</span> || s.waitStatus &gt; <span class="hljs-number">0</span>) &#123;<br>          s = <span class="hljs-literal">null</span>;<br>          <span class="hljs-keyword">for</span> (<span class="hljs-type">Node</span> <span class="hljs-variable">t</span> <span class="hljs-operator">=</span> tail; t != <span class="hljs-literal">null</span> &amp;&amp; t != node; t = t.prev)<br>              <span class="hljs-keyword">if</span> (t.waitStatus &lt;= <span class="hljs-number">0</span>)<br>                  s = t;<br>      &#125;<br>      <span class="hljs-keyword">if</span> (s != <span class="hljs-literal">null</span>)<br>          LockSupport.unpark(s.thread);<br>  &#125;<br></code></pre></td></tr></table></figure><p>公平锁：</p><p>相比较非公平，会提前判断当前队列中是否有前置的Node，如果有前置Node则直接进行排队等待，不直接参与抢占锁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">         * Fair version of tryAcquire.  Don&#x27;t grant access unless</span><br><span class="hljs-comment">         * recursive call or no waiters or is first.</span><br><span class="hljs-comment">         */</span><br>        <span class="hljs-meta">@ReservedStackAccess</span><br>        <span class="hljs-keyword">protected</span> <span class="hljs-keyword">final</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">tryAcquire</span><span class="hljs-params">(<span class="hljs-type">int</span> acquires)</span> &#123;<br>            <span class="hljs-keyword">final</span> <span class="hljs-type">Thread</span> <span class="hljs-variable">current</span> <span class="hljs-operator">=</span> Thread.currentThread();<br>            <span class="hljs-type">int</span> <span class="hljs-variable">c</span> <span class="hljs-operator">=</span> getState();<br>            <span class="hljs-keyword">if</span> (c == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-keyword">if</span> (!hasQueuedPredecessors() &amp;&amp;<br>                    compareAndSetState(<span class="hljs-number">0</span>, acquires)) &#123;<br>                    setExclusiveOwnerThread(current);<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (current == getExclusiveOwnerThread()) &#123;<br>                <span class="hljs-type">int</span> <span class="hljs-variable">nextc</span> <span class="hljs-operator">=</span> c + acquires;<br>                <span class="hljs-keyword">if</span> (nextc &lt; <span class="hljs-number">0</span>)<br>                    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Error</span>(<span class="hljs-string">&quot;Maximum lock count exceeded&quot;</span>);<br>                setState(nextc);<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>    &#125;<br></code></pre></td></tr></table></figure><h2 id="14-ReentrantLock-ReentrantReadWriteLock-StampedLock"><a href="#14-ReentrantLock-ReentrantReadWriteLock-StampedLock" class="headerlink" title="14. ReentrantLock,ReentrantReadWriteLock,StampedLock"></a>14. ReentrantLock,ReentrantReadWriteLock,StampedLock</h2><p>独占锁，读写锁，邮戳锁</p><p><img src="/img/Java-JUC-IMGS/Untitled%2041.png" alt="Untitled"></p><p>ReentrantReadWriteLock extends  <code>ReadWriteLock</code></p><ol><li>读写锁定义：<ol><li>一个资源类能够被多个读线程访问或被一个写线程访问，但不能同时存在读写线程。</li><li>一体两面，读写互斥，读读共享。</li><li></li></ol></li><li>2</li><li>3</li></ol><h3 id="锁演化"><a href="#锁演化" class="headerlink" title="锁演化"></a>锁演化</h3><p><img src="/img/Java-JUC-IMGS/Untitled%2042.png" alt="Untitled"></p><p>无锁→ synchronized、lock(RentrantLock) → ReentrantReadWriteLock  → stampedLock(邮戳锁）</p><p>synchronized, lock接口</p><p>多线程，不管读还是写，每次都只有一个线程获取锁，onlyone</p><ul><li><p>ReentrantReadWriteLock：</p><p>  优点：</p><ol><li>读写互斥，写写互斥。</li><li>读读共享，多线程并行</li><li>读多写少，读写锁Good</li></ol><p>  缺点：</p><ol><li>写锁饥饿问题（读没有完成时，写线程不能获取锁）</li><li>注意，锁降级</li></ol><p>  可重用—锁降级 写锁的降级，降级为读锁 </p><ol><li><p>如果同一个线程持有写锁，在没有释放写锁之前，可以继续获得读锁。这就是写锁的降级，降级为读锁 （可重入锁）</p></li><li><p>惯例规定，先获得写锁然后获得读锁，在释放写锁的 次序。</p></li><li><p>如果释放了写锁，那么就完全转换为读锁。</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2043.png" alt="Untitled"></p></li></ol><p>  <strong>释放写锁前立刻获得写锁，写后读，防止其他线程进行抢占，保证一个完整的锁降级过程。目的是保证数据可见性。</strong></p><p>  <strong>利用锁降级替代释放锁</strong>，防止数据出错。</p><p>  锁升级不可用（读锁升级 到写锁不可行）：线程持有读锁，写锁无法再获得，写线程会进入阻塞，需等待读锁完后写线程才能获得锁。</p><p>  ReentrantReadWriteLock 的读锁是悲观锁，即读的过程中不允许写。    </p></li><li><p>StampedLock（邮戳锁，版本锁）比读写锁更快</p><p>   <strong>读的过程中也允许写锁介入</strong></p><ol><li>是什么？<ol><li>是对ReentrantReadWriteLock优化，缓解（解决）写锁饥饿问题。</li><li>stamp（戳记，标签，时间戳）</li><li>不可重入，危险</li></ol></li><li>解决锁饥饿问题<ol><li>使用公平锁new ReentrantReadWriteLock(true),但会牺牲系统吞吐量。</li><li>StampedLock乐观读锁；获得乐观读锁后，还需要对结果进行校验，读的时候允许其他线程尝试获取写锁不会被阻塞。</li></ol></li><li>3中控制读，写访问模式。<ol><li>写模式，writelock</li><li>读模式（悲观），readlock </li><li>乐观读 optimistic reading:无锁控制，类似数据库中的乐观锁，支持读写并发，很乐观认为读取时没人修改，假如被修改再实现升级为悲观读模式。</li></ol></li><li>缺点：<ol><li>stampedLock不支持可重入，没有Re开头 </li><li>StampedLock的悲观读和写锁都不支持条件变量（Condition）</li><li>使用StampedLock一定不要调用中断操作，即：interrupt()方法。</li></ol><h2 id="JUC总结-回顾"><a href="#JUC总结-回顾" class="headerlink" title="JUC总结-回顾"></a>JUC总结-回顾</h2><p> <img src="/img/Java-JUC-IMGS/Untitled%2044.png" alt="Untitled"></p><p> <img src="/img/Java-JUC-IMGS/Untitled%2045.png" alt="Untitled"></p><ol><li>锁</li></ol><p> <img src="/img/Java-JUC-IMGS/Untitled%2046.png" alt="Untitled"></p><ol><li><p>JMM Java内存定义规范。</p></li><li><p>synchronized</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2047.png" alt="Untitled"></p><p> <img src="/img/Java-JUC-IMGS/Untitled%2048.png" alt="Untitled"></p></li></ol><p> CAS</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2049.png" alt="Untitled"></p><p> volatile</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2050.png" alt="Untitled"></p><p> LockSupport</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2051.png" alt="Untitled"></p><p> AQS</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2052.png" alt="Untitled"></p><p> <img src="/img/Java-JUC-IMGS/Untitled%2053.png" alt="Untitled"></p><p> ThreadLocal</p><p> <img src="/img/Java-JUC-IMGS/Untitled%2054.png" alt="Untitled"></p><p> 原子增强类Atomic</p></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu22设置静态IP</title>
      <link href="/linux/Ubuntu22%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81IP/"/>
      <url>/linux/Ubuntu22%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81IP/</url>
      
        <content type="html"><![CDATA[<h1 id="Ubuntu设置静态IP"><a href="#Ubuntu设置静态IP" class="headerlink" title="Ubuntu设置静态IP"></a>Ubuntu设置静态IP</h1><p>通过netplan设置静态IP</p><h2 id="1-编辑配置文件"><a href="#1-编辑配置文件" class="headerlink" title="1. 编辑配置文件"></a>1. 编辑配置文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /etc/netplan <br>sudo vim 00-installer-config.yaml<br></code></pre></td></tr></table></figure><p>设置为：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-comment"># This is the network config written by &#x27;subiquity&#x27;</span><br><span class="hljs-attr">network:</span><br>  <span class="hljs-attr">ethernets:</span><br>    <span class="hljs-attr">enp0s1:</span><br>      <span class="hljs-comment">#dhcp4: true</span><br>      <span class="hljs-attr">dhcp4:</span> <span class="hljs-literal">false</span><br>      <span class="hljs-attr">addresses:</span><br>        <span class="hljs-comment">#设置想要的不冲突的静态IP地址</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.64</span><span class="hljs-number">.30</span><span class="hljs-string">/24</span><br>      <span class="hljs-attr">routes:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">to:</span> <span class="hljs-string">default</span><br>          <span class="hljs-attr">via:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.64</span><span class="hljs-number">.1</span><br>      <span class="hljs-attr">nameservers:</span><br>        <span class="hljs-attr">addresses:</span> [<span class="hljs-number">8.8</span><span class="hljs-number">.8</span><span class="hljs-number">.8</span>,<span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span>,<span class="hljs-number">192.168</span><span class="hljs-number">.64</span><span class="hljs-number">.1</span>]<br>  <span class="hljs-attr">version:</span> <span class="hljs-number">2</span><br><br></code></pre></td></tr></table></figure><h2 id="2-使配置文件生效"><a href="#2-使配置文件生效" class="headerlink" title="2.使配置文件生效"></a>2.使配置文件生效</h2><p>保存退出后,apply使设置生效。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo netplan apply<br></code></pre></td></tr></table></figure><p>查看ip</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ip a<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo-GithubCI(github-actions)自动部署</title>
      <link href="/blog/2022-07-19-Hexo-GithubCI%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"/>
      <url>/blog/2022-07-19-Hexo-GithubCI%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>正常部署博客时，需手动执行命令进行部署；期望每次写完代码后，提交代码到源码仓库后自动编译部署到xxx.github.io中。</p><h1 id="手动部署"><a href="#手动部署" class="headerlink" title="手动部署"></a>手动部署</h1><p>先配置theme主题下的_config.yml</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repository:</span> <span class="hljs-string">git@github.com:xxx/xxx.github.io.git</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">main</span><br></code></pre></td></tr></table></figure><p>手动执行部署命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d<br></code></pre></td></tr></table></figure><h1 id="Github-Actions部署"><a href="#Github-Actions部署" class="headerlink" title="Github-Actions部署"></a>Github-Actions部署</h1><ol><li><p>博客源码存放yyy仓库<br>当源码提交到源码仓库yyy主分支，执行github-actions将代码编译，部署到git-pages(xxx.github.io)仓库中。</p></li><li><p>git-pages仓库：为xxx.github.io</p></li></ol><h2 id="创建ssh-key"><a href="#创建ssh-key" class="headerlink" title="创建ssh-key"></a>创建ssh-key</h2><p>在源码跟目录中执行创建ssh-key命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -f github-page-deploy-key<br></code></pre></td></tr></table></figure><p>此时会得到两个文件：github-page-deploy-key，github-page-deploy-key.pub<br>github-page-deploy-key为私钥；<br>github-page-deploy-key.pub为公钥</p><h2 id="将私钥添加到源码仓库的actions中"><a href="#将私钥添加到源码仓库的actions中" class="headerlink" title="将私钥添加到源码仓库的actions中"></a>将私钥添加到源码仓库的actions中</h2><p><img src="/img/blog/github_actions1.png"><br>填写name，记住此name(此处称为部署KEY)，value填写私钥(github-page-deploy-key)中的内容，用vscode打开复制出<br><img src="/img/blog/github_actions2.png"></p><h2 id="将公钥添加到xxx-github-io仓库中"><a href="#将公钥添加到xxx-github-io仓库中" class="headerlink" title="将公钥添加到xxx.github.io仓库中"></a>将公钥添加到xxx.github.io仓库中</h2><p>复制公钥github-page-deploy-key.pub中的内容。添加到xxx.github.io仓库中的deploy_keys中,title随意取名。<br><img src="/img/blog/github_actions3.png"><br><img src="/img/blog/github_actions4.png"></p><h2 id="编辑deploy-yml文件"><a href="#编辑deploy-yml文件" class="headerlink" title="编辑deploy.yml文件"></a>编辑deploy.yml文件</h2><p>在源码根目录中创建如下目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p .github/workflows/<br></code></pre></td></tr></table></figure><p>.github&#x2F;workflows&#x2F;目录下新建 deploy.yml文件<br>deploy.yml文件内容：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">name:</span> <span class="hljs-string">blog_ci</span><br><span class="hljs-attr">on:</span> [<span class="hljs-string">push</span>]<br><span class="hljs-attr">jobs:</span><br>  <span class="hljs-attr">build_and_deploy:</span><br>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br>    <span class="hljs-attr">if:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">contains(github.event.head_commit.message,</span> <span class="hljs-string">&#x27;#deploy&#x27;</span><span class="hljs-string">)</span> <span class="hljs-string">&#125;&#125;</span><br>    <span class="hljs-attr">steps:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v2</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-node@v2</span><br>        <span class="hljs-attr">with:</span><br>          <span class="hljs-attr">node-version:</span> <span class="hljs-string">&#x27;12&#x27;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Prepare</span> <span class="hljs-string">ssh</span> <span class="hljs-string">env</span><br>        <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">          mkdir -p ~/.ssh</span><br><span class="hljs-string">          echo &quot;$SSH_DEPLOY_KEY&quot; | tr -d &#x27;\r&#x27; &gt; ~/.ssh/id_rsa</span><br><span class="hljs-string">          chmod 600 ~/.ssh/id_rsa</span><br><span class="hljs-string">          ssh-keyscan -H &#x27;github.com&#x27; &gt;&gt; ~/.ssh/known_hosts</span><br><span class="hljs-string"></span>        <span class="hljs-attr">env:</span><br>          <span class="hljs-attr">SSH_DEPLOY_KEY:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">secrets.部署KEY</span> <span class="hljs-string">&#125;&#125;</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Prepare</span> <span class="hljs-string">hexo</span> <span class="hljs-string">and</span> <span class="hljs-string">npm</span> <span class="hljs-string">env</span><br>        <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">          npm install -g hexo-cli</span><br><span class="hljs-string">          npm install</span><br><span class="hljs-string"></span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Prepare</span> <span class="hljs-string">git</span> <span class="hljs-string">env</span><br>        <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">          git config --global user.email your@qq.com</span><br><span class="hljs-string">          git config --global user.name your_username</span><br><span class="hljs-string"></span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Deploy</span> <span class="hljs-string">Blog</span><br>        <span class="hljs-attr">run:</span> <span class="hljs-string">| </span><br><span class="hljs-string">          hexo clean</span><br><span class="hljs-string">          hexo g</span><br><span class="hljs-string">          hexo d</span><br></code></pre></td></tr></table></figure><p>记住替换 部署KEY名称；<br>替换git的user.email 和 user.name为你的xxx.github.io仓库的登录邮箱和登录名。</p><h2 id="自动部署历史查看"><a href="#自动部署历史查看" class="headerlink" title="自动部署历史查看"></a>自动部署历史查看</h2><p>将源码推送到源码仓库yyy主分支后，触发执行deploy.yml编译提交流程。<br><img src="/img/blog/github_actions5.png"></p><p>参考：</p><ul><li><a href="https://docs.github.com/cn/actions/quickstart">github-actions</a></li><li><a href="https://razeen.me/posts/use-github-action-to-deploy-your-hexo-blog/">Github Actions 初体验之自动化部署 Hexo 博客</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>迁移博客使用Hexo</title>
      <link href="/blog/2022-07-08-%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8Hexo/"/>
      <url>/blog/2022-07-08-%E8%BF%81%E7%A7%BB%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8Hexo/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>就觉得Fluid这个主题好看，但是在jekyll中没找到合适的替代品，所以迁移使用Hexo。</p><h1 id="Hexo使用"><a href="#Hexo使用" class="headerlink" title="Hexo使用"></a>Hexo使用</h1><p><a href="https://hexo.io/zh-cn/docs/index.html">Hexo使用文档</a></p><h1 id="主题使用"><a href="#主题使用" class="headerlink" title="主题使用"></a>主题使用</h1><p><a href="https://hexo.fluid-dev.com/docs/guide/">Hexo-Theme-Fluid</a></p>]]></content>
      
      
      <categories>
          
          <category> Blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink消费Kafka时遇到的一些问题汇总</title>
      <link href="/flink/2021-12-31-Flink-kafka%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/"/>
      <url>/flink/2021-12-31-Flink-kafka%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>记录一些在使用flink消费kafka时,遇到一些优化问题和框架问题,不定时更新一些新的问题.</p><h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown">flink: 1.13.2<br>kafka: 2.5.0<br>hadoop: 3.2.1<br>centos 7<br></code></pre></td></tr></table></figure><h2 id="flink-checkpoint警告日志"><a href="#flink-checkpoint警告日志" class="headerlink" title="flink checkpoint警告日志"></a>flink checkpoint警告日志</h2><ul><li><p>日志1:</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs log">[DataStreamer for file /flink/checkpoints/xxx083408/097a5dc4d32c739760d33baea57f9679/shared/7832d571-5039-4c15-ae7f-99c874c64c55] WARN  org.apache.hadoop.hdfs.DataStreamer  - Caught exception<br>java.lang.InterruptedException: null<br>        at java.lang.Object.wait(Native Method)<br>        at java.lang.Thread.join(Thread.java:1252)<br>        at java.lang.Thread.join(Thread.java:1326)<br>        at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)<br></code></pre></td></tr></table></figure></li><li><p>原因:</p><p>  hadoop自身BUG<br>  文档说明: <a href="https://issues.apache.org/jira/browse/HDFS-10429">https://issues.apache.org/jira/browse/HDFS-10429</a></p></li><li><p>日志2:</p>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs log">block BP-1644493283-172.34.242.137-1636089673161:blk_1076991017_3256384] WARN  org.apache.hadoop.hdfs.DataStreamer  - DataStreamer Exception<br>java.nio.channels.ClosedByInterruptException: null<br>        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)<br>        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:477)<br>        at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:63)<br>        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)<br>        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:159)<br>        at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:117)<br>        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)<br>        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)<br>        at java.io.DataOutputStream.flush(DataOutputStream.java:123)<br>        at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:775)<br></code></pre></td></tr></table></figure><ul><li>原因:<br>  flink论坛给出由于hadoop bug造成.<br>  link: <a href="https://issues.apache.org/jira/browse/FLINK-13228">https://issues.apache.org/jira/browse/FLINK-13228</a></li></ul></li></ul><h2 id="flink消费kafka事务超时问题"><a href="#flink消费kafka事务超时问题" class="headerlink" title="flink消费kafka事务超时问题"></a>flink消费kafka事务超时问题</h2><p>日志现象:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs log">Map -&gt; Sink: late_log_to_kafka)-xxxxx-51, producerId=19575, epoch=9071] has been open for 304327 ms. This is close to or even exceeding the transaction timeout of 300000 ms.<br></code></pre></td></tr></table></figure><ul><li>flink官网文档建议<br>增加超时时间: <figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pf"><span class="hljs-number">1</span>. 调整kafka-broker中transaction.<span class="hljs-keyword">max</span>.<span class="hljs-keyword">timeout</span>.ms时间<br>transaction.<span class="hljs-keyword">max</span>.<span class="hljs-keyword">timeout</span>.ms:默认<span class="hljs-number">15</span><span class="hljs-keyword">min</span><br><br><span class="hljs-number">2</span>. 调整flink-kafka-producer<br>transaction.<span class="hljs-keyword">timeout</span>.ms: 默认<span class="hljs-number">1</span>hour<br>实际使用中 transaction.<span class="hljs-keyword">timeout</span>.ms设置了 <span class="hljs-number">5</span><span class="hljs-keyword">min</span>,因为出现此问题,增大到<span class="hljs-number">12</span><span class="hljs-keyword">min</span>.(主要是不想去设置kafka-borker,需要重启)<br><br>kafkaProp.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, <span class="hljs-number">12</span> * <span class="hljs-number">60</span> * <span class="hljs-number">1000</span>);//<span class="hljs-number">12</span><span class="hljs-keyword">min</span><br><br></code></pre></td></tr></table></figure>link: <a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/datastream/kafka/#kafka-producers-and-fault-tolerance">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/datastream/kafka/#kafka-producers-and-fault-tolerance</a></li></ul><h2 id="flink-checkpoint失败优化"><a href="#flink-checkpoint失败优化" class="headerlink" title="flink-checkpoint失败优化"></a>flink-checkpoint失败优化</h2><ul><li><p>现象</p><p>  flink exactly_one 消费kafka时,kafka峰值流量过大,且分区较多时(且机器资源有限),容易导致checkpoint-data过大,checkpoint失败或超时.</p></li><li><p>解决方法: </p><p>  增加 kafkaProducersPoolSize 大小,默认5.根据实际情况增大其值.</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">* &lt;li&gt;decrease number of max concurrent checkpoints<br>* &lt;li&gt;make checkpoints more <span class="hljs-title function_">reliable</span> <span class="hljs-params">(so that they complete faster)</span><br>* &lt;li&gt;increase the delay between checkpoints<br>* &lt;li&gt;increase the size of &#123;<span class="hljs-meta">@link</span> FlinkKafkaInternalProducer&#125;s pool<br></code></pre></td></tr></table></figure></li><li><p>参考源码:</p><p>  flink-kafka-producer</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">    * Creates a FlinkKafkaProducer for a given topic. The sink produces its input to the topic. It</span><br><span class="hljs-comment">    * accepts a &#123;<span class="hljs-doctag">@link</span> KafkaSerializationSchema&#125; and possibly a custom &#123;<span class="hljs-doctag">@link</span></span><br><span class="hljs-comment">    * FlinkKafkaPartitioner&#125;.</span><br><span class="hljs-comment">    *</span><br><span class="hljs-comment">    * <span class="hljs-doctag">@param</span> defaultTopic The default topic to write data to</span><br><span class="hljs-comment">    * <span class="hljs-doctag">@param</span> serializationSchema A serializable serialization schema for turning user objects into</span><br><span class="hljs-comment">    *     a kafka-consumable byte[] supporting key/value messages</span><br><span class="hljs-comment">    * <span class="hljs-doctag">@param</span> producerConfig Configuration properties for the KafkaProducer. &#x27;bootstrap.servers.&#x27; is</span><br><span class="hljs-comment">    *     the only required argument.</span><br><span class="hljs-comment">    * <span class="hljs-doctag">@param</span> semantic Defines semantic that will be used by this producer (see &#123;<span class="hljs-doctag">@link</span></span><br><span class="hljs-comment">    *     FlinkKafkaProducer.Semantic&#125;).</span><br><span class="hljs-comment">    * <span class="hljs-doctag">@param</span> kafkaProducersPoolSize Overwrite default KafkaProducers pool size (see &#123;<span class="hljs-doctag">@link</span></span><br><span class="hljs-comment">    *     FlinkKafkaProducer.Semantic#EXACTLY_ONCE&#125;).</span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">FlinkKafkaProducer</span><span class="hljs-params">(</span><br><span class="hljs-params">            String defaultTopic,</span><br><span class="hljs-params">            KafkaSerializationSchema&lt;IN&gt; serializationSchema,</span><br><span class="hljs-params">            Properties producerConfig,</span><br><span class="hljs-params">            FlinkKafkaProducer.Semantic semantic,</span><br><span class="hljs-params">            <span class="hljs-type">int</span> kafkaProducersPoolSize)</span> &#123;<br>        <span class="hljs-built_in">this</span>(<br>                defaultTopic,<br>                <span class="hljs-literal">null</span>,<br>                <span class="hljs-literal">null</span>, <span class="hljs-comment">/* keyed schema and FlinkKafkaPartitioner */</span><br>                serializationSchema,<br>                producerConfig,<br>                semantic,<br>                kafkaProducersPoolSize);<br>    &#125;<br></code></pre></td></tr></table></figure><p>  Semantic.EXACTLY_ONCE</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">    * Semantics that can be chosen.</span><br><span class="hljs-comment">    * &lt;li&gt;&#123;<span class="hljs-doctag">@link</span> #EXACTLY_ONCE&#125;</span><br><span class="hljs-comment">    * &lt;li&gt;&#123;<span class="hljs-doctag">@link</span> #AT_LEAST_ONCE&#125;</span><br><span class="hljs-comment">    * &lt;li&gt;&#123;<span class="hljs-doctag">@link</span> #NONE&#125;</span><br><span class="hljs-comment">    */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">enum</span> <span class="hljs-title class_">Semantic</span> &#123;<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">        * Semantic.EXACTLY_ONCE the Flink producer will write all messages in a Kafka transaction</span><br><span class="hljs-comment">        * that will be committed to Kafka on a checkpoint.</span><br><span class="hljs-comment">        *</span><br><span class="hljs-comment">        * &lt;p&gt;In this mode &#123;<span class="hljs-doctag">@link</span> FlinkKafkaProducer&#125; sets up a pool of &#123;<span class="hljs-doctag">@link</span></span><br><span class="hljs-comment">        * FlinkKafkaInternalProducer&#125;. Between each checkpoint a Kafka transaction is created,</span><br><span class="hljs-comment">        * which is committed on &#123;<span class="hljs-doctag">@link</span> FlinkKafkaProducer#notifyCheckpointComplete(long)&#125;. If</span><br><span class="hljs-comment">        * checkpoint complete notifications are running late, &#123;<span class="hljs-doctag">@link</span> FlinkKafkaProducer&#125; can run</span><br><span class="hljs-comment">        * out of &#123;<span class="hljs-doctag">@link</span> FlinkKafkaInternalProducer&#125;s in the pool. In that case any subsequent</span><br><span class="hljs-comment">        * &#123;<span class="hljs-doctag">@link</span> FlinkKafkaProducer#snapshotState(FunctionSnapshotContext)&#125; requests will fail and</span><br><span class="hljs-comment">        * &#123;<span class="hljs-doctag">@link</span> FlinkKafkaProducer&#125; will keep using the &#123;<span class="hljs-doctag">@link</span> FlinkKafkaInternalProducer&#125; from</span><br><span class="hljs-comment">        * the previous checkpoint. To decrease the chance of failing checkpoints there are four</span><br><span class="hljs-comment">        * options:</span><br><span class="hljs-comment">        * &lt;li&gt;decrease number of max concurrent checkpoints</span><br><span class="hljs-comment">        * &lt;li&gt;make checkpoints more reliable (so that they complete faster)</span><br><span class="hljs-comment">        * &lt;li&gt;increase the delay between checkpoints</span><br><span class="hljs-comment">        * &lt;li&gt;increase the size of &#123;<span class="hljs-doctag">@link</span> FlinkKafkaInternalProducer&#125;s pool</span><br><span class="hljs-comment">        */</span><br>        EXACTLY_ONCE,<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">        * Semantic.AT_LEAST_ONCE the Flink producer will wait for all outstanding messages in the</span><br><span class="hljs-comment">        * Kafka buffers to be acknowledged by the Kafka producer on a checkpoint.</span><br><span class="hljs-comment">        */</span><br>        AT_LEAST_ONCE,<br><br>        <span class="hljs-comment">/**</span><br><span class="hljs-comment">        * Semantic.NONE means that nothing will be guaranteed. Messages can be lost and/or</span><br><span class="hljs-comment">        * duplicated in case of failure.</span><br><span class="hljs-comment">        */</span><br>        NONE<br>    &#125;<br></code></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> Kafka </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Write Data to Clickhouse 遇到的一些问题.</title>
      <link href="/flink/2021-11-29-FlinkWriteToClickhouse%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/"/>
      <url>/flink/2021-11-29-FlinkWriteToClickhouse%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>由于公司业务和框架因素,目前将Clickhouse作为数仓唯一的存储选择.<br>现将一些个人在使用Flink写数据到Clickhouse遇到的一些问题做一些笔记.</p><h2 id="Clickhouse简介"><a href="#Clickhouse简介" class="headerlink" title="Clickhouse简介:"></a>Clickhouse简介:</h2><p>clickhouse是列式分布式存储系统,ClickHouse是一个用于联机分析(OLAP)的列式数据库管理系统(DBMS)。<br><a href="https://clickhouse.com/docs/zh/">官网简介</a></p><h2 id="问题一-如果保证-Flink-Sink-to-Clickhouse-有效一次"><a href="#问题一-如果保证-Flink-Sink-to-Clickhouse-有效一次" class="headerlink" title="问题一: 如果保证 Flink Sink to Clickhouse 有效一次"></a>问题一: 如果保证 Flink Sink to Clickhouse 有效一次</h2><p>这个问题是刚到公司,分配给我的. 这里说一下我简单的思路和方案.<br>截至目前(2021年11月29日),前几天看到网上阿里已经实现了基于自身Clickhouse的有效一次性入库方案(类似于StreamSinkFile的二次提交)<br>但是需要结合clickhouse的源码修改才能完成</p><p><a href="https://mp.weixin.qq.com/s/8H2bxYUBmPzHl3Ae6WVWJg">阿里巴巴相关文档</a></p><p>目前官方版本Clickhouse不具备事务.</p><h3 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h3><ol><li><p>将Clickhouse的表引擎改为:  ReplacingMergeTree (目前是MergeTree)</p><ul><li>优点: 满足幂等性,多次写入后数据最终能保证正确性.</li><li>缺点: 当表数据很多时,ReplacingMergeTree对CPU和内存消耗很高.不适用于目前业务中.(目前业务将ods层数据都存到CH中,且是单节点.)</li></ul></li><li><p>将kf_partition,kf_offset写入ch的表中,使topic和表一一对应.offset由kafka维护,不一致时,删除ch中多余数据.</p><ul><li>优点: 能基本保证数据正确性.</li><li>缺点: 不能使用Flink的自动重启机制,需要每次重启时,比对CH与Kafka的对应分区offset.</li><li>缺点: 当CH负载过于高时,重启任务删除数据时,不能正常删除掉.数据准确性受限于CH负载.</li></ul></li><li><p>当任务重启时,使用kafka中的offset点直接启动任务,下一个小时通过hive或者具备事务性或幂等性的存储结构回插到CH(CH删除当前小时数据或分钟) </p><ul><li>优点: 能保证数据准确性</li><li>缺点: 资源消耗更多(需要额外的事务性分布式存储系统或集群资源消耗,目前公司不希望使用更多资源,就是”优化”.)</li><li>缺点: 当前重启小时CH中数据不够准确,需要下一个小时数据回插后数据才具备准确性.</li></ul></li></ol><p>最终使用了方案2.不要问为啥(成本控制?)</p><h2 id="问题二-Clickhouse删除数据时提示-空间不足"><a href="#问题二-Clickhouse删除数据时提示-空间不足" class="headerlink" title="问题二: Clickhouse删除数据时提示 空间不足"></a>问题二: Clickhouse删除数据时提示 空间不足</h2><ol><li>问题场景:</li></ol><p>因为问题一解决方案2是基于保持clickhouse中数据的分区和offset与kafka的分区和offset一致,<br>当任务重启(失败重启或手动重启)时,回去校验offset一致情况 .<br>如果有不一致情况会将clickhouse中多余的数据删除其实保持一致.<br>同时:<br>users.xml 设置了同步修改数据属性.(因为是单节点所以设置1.多节点和副本情况设置2)</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">mutations_sync</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">mutations_sync</span>&gt;</span> <br></code></pre></td></tr></table></figure><p>导致了任务重启时删除多个按分区删除语句时提示空间不足:<br>日志如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs log">dealCkAndKfOffsetNoEqual count=[8211] ;exec-sql=[alter table  db01.test_table  delete where toDate(`logdate`)=&#x27;2021-11-30&#x27; and kf_partition=6 and kf_partition&gt;=14152053083 and kf_offset&lt;=14152061943]<br>ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 341, host: 172.34.6.84, port: 8123; Code: 341, e.displayText() = DB::Exception: Exception hap<br>pened during execution of mutation &#x27;mutation_8222580.txt&#x27; with part &#x27;20210819_662942_690500_6_8222579&#x27; reason: &#x27;Code: 243, e.displayText() = DB::Exception: Cannot reserve<br> 54.68 GiB, not enough space (version 21.8.11.4 (official build))&#x27;. This error maybe retryable or not. In case of unretryable error, mutation can be killed with KILL MUTA<br>TION query (version 21.8.11.4 (official build))<br><br>        at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:58)<br>        at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:28)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.checkForErrorAndThrow(ClickHouseStatementImpl.java:876)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.getInputStream(ClickHouseStatementImpl.java:616)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:117)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:100)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:95)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:90)<br>        at ru.yandex.clickhouse.ClickHouseStatementImpl.execute(ClickHouseStatementImpl.java:226)<br>        at flink_demo.utils.ClickhouseUtils.execSql(ClickhouseUtils.java:44)<br>        at flink_demo.utils.ClickhouseUtils.execSql(ClickhouseUtils.java:32)<br>        at flink_demo.utils.FlinkUtils.dealCkAndKfOffsetNoEqual(FlinkUtils.java:373)<br>        at flink_demo.FlinkWriteLogOdsCKQueue.main(FlinkWriteLogOdsCKQueue.java:52)<br>        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br>        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br>        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br>        at java.lang.reflect.Method.invoke(Method.java:498)<br>        at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:355)<br>        at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:222)<br>        at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:114)<br>        at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:812)<br>        at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:246)<br>        at org.apache.flink.client.cli.CliFrontend.parseAndRun(CliFrontend.java:1054)<br>        at org.apache.flink.client.cli.CliFrontend.lambda$main$10(CliFrontend.java:1132)<br>        at java.security.AccessController.doPrivileged(Native Method)<br>        at javax.security.auth.Subject.doAs(Subject.java:422)<br>        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)<br>        at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)<br>        at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1132)<br>Caused by: java.lang.Throwable: Code: 341, e.displayText() = DB::Exception: Exception happened during execution of mutation &#x27;mutation_8222580.txt&#x27; with part &#x27;20210819_662<br>942_690500_6_8222579&#x27; reason: &#x27;Code: 243, e.displayText() = DB::Exception: Cannot reserve 54.68 GiB, not enough space (version 21.8.11.4 (official build))&#x27;. This error ma<br>ybe retryable or not. In case of unretryable error, mutation can be killed with KILL MUTATION query (version 21.8.11.4 (official build))<br><br>                at ru.yandex.clickhouse.except.ClickHouseExceptionSpecifier.specify(ClickHouseExceptionSpecifier.java:53)<br>        ... 28 more<br>ru.yandex.clickhouse.except.ClickHouseException: ClickHouse exception, code: 341, host: 172.34.6.84, port: 8123; Code: 341, e.displayText() = DB::Exception: Exception hap<br>pened during execution of mutation &#x27;mutation_8222580.txt&#x27; with part &#x27;20210819_662942_690500_6_8222579&#x27; reason: &#x27;Code: 243, e.displayText() = DB::Exception: Cannot reserve<br> 54.68 GiB, not enough space (version 21.8.11.4 (official build))&#x27;. This error maybe retryable or not. In case of unretryable error, mutation can be killed with KILL MUTA<br>TION query (version 21.8.11.4 (official build))<br></code></pre></td></tr></table></figure><p>在执行时CH内存使用较高,如图<br><img src="https://i.loli.net/2021/11/30/mnYWsLOuB35Adrj.png" alt="内存使用图"><br>同时参考了文章: <a href="https://cloud.tencent.com/developer/article/1704570">https://cloud.tencent.com/developer/article/1704570</a> </p><p>发现执行sql报错提示空间不足,是由因为对指定分区执行了 DELETE WHERE 条件删除，不在删除分区的分区文件，这些分区文件进入了 clone 流程,所以造成提示空间不足</p><p>如有其他关键问题.后期再继续更新.</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> Clickhouse </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flume 优化</title>
      <link href="/flume/2021-11-19-flume-%E4%BC%98%E5%8C%96/"/>
      <url>/flume/2021-11-19-flume-%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="Flume优化"><a href="#Flume优化" class="headerlink" title="Flume优化"></a>Flume优化</h1><h2 id="背景和现象"><a href="#背景和现象" class="headerlink" title="背景和现象"></a>背景和现象</h2><ul><li><p>现象 </p><p>  因数据堆积(job停止没有自动重启)后,flink任务将数据消费完成到kafka-topic中,flume消费堆积数据到hdfs(s3)时,数据消费过慢.</p></li><li><p>原因</p><p>  修改了kafka的压缩方式,由snappy改为了 zstd,zstd在解压时速率较慢,同时由于堆积造成flume消费kafka时,网速远没达到预期.</p></li></ul><h2 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h2><h3 id="升级机器配置"><a href="#升级机器配置" class="headerlink" title="升级机器配置"></a>升级机器配置</h3><p>在原有机器上调整了以下配置后,flume机器网速依然没有提升.平均值大约在42MB&#x2F;s</p><p>原机器 配置: 4C 16GB</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs conf"># source<br>a1.sources.r1.batchSize = 40000 # 原有值 10000<br>a1.sources.r1.batchDurationMillis = 500 # 原有值 1000<br><br># sink<br>a1.sinks.k1.hdfs.batchSize = 5000 # 原有1000<br></code></pre></td></tr></table></figure><p>升级了新机器</p><p>32C 64GB后调整了批次大小和间隔时间,依然没有对消费能力有较大提升,最终平均网速也只在50MB&#x2F;s左右,没有达到预想中的提升.</p><h3 id="修改自定义拦截器"><a href="#修改自定义拦截器" class="headerlink" title="修改自定义拦截器"></a>修改自定义拦截器</h3><p>通过火焰图发现了拦截效果过慢,大约占用了40-45%的效率时间.</p><p>火焰图使用参考其官网: <a href="https://github.com/jvm-profiling-tools/async-profiler">火焰图github官网</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">ps -ef |grep flume<br><span class="hljs-comment">#拿到进程id -&gt; pid</span><br><br>/profiler.sh -d 30 -f pid_xxx.html pid<br><br></code></pre></td></tr></table></figure><p>优化前火焰图:<br><img src="https://i.loli.net/2021/11/29/azbCdjQGpK8OEsn.png"></p><p>通过查看自定义拦截器代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br>   <span class="hljs-keyword">public</span> Event <span class="hljs-title function_">intercept</span><span class="hljs-params">(Event event)</span> &#123;<br>       Map&lt;String, String&gt; headers = event.getHeaders();<br>       <span class="hljs-type">String</span> <span class="hljs-variable">log</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(event.getBody(), StandardCharsets.UTF_8);<br>       JSONObject.parseObject(log);<br>       <span class="hljs-type">JSONObject</span> <span class="hljs-variable">jsonObject</span> <span class="hljs-operator">=</span> JSON.parseObject(log);<br>       <span class="hljs-keyword">if</span> (jsonObject.containsKey(<span class="hljs-string">&quot;key&quot;</span>)) &#123;<br>           headers.put(<span class="hljs-string">&quot;timestamp&quot;</span>, jsonObject.getString(<span class="hljs-string">&quot;timestamp&quot;</span>));<br>           headers.put(<span class="hljs-string">&quot;xxx&quot;</span>, jsonObject.getString(<span class="hljs-string">&quot;xxx&quot;</span>));<br>           headers.put(<span class="hljs-string">&quot;yyy&quot;</span>, jsonObject.getString(<span class="hljs-string">&quot;yyy&quot;</span>));<br>           <span class="hljs-keyword">return</span> event;<br>       &#125; <span class="hljs-keyword">else</span> &#123;<br>           <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>       &#125;<br>   &#125;<br><br>   <span class="hljs-meta">@Override</span><br>   <span class="hljs-keyword">public</span> List&lt;Event&gt; <span class="hljs-title function_">intercept</span><span class="hljs-params">(List&lt;Event&gt; events)</span> &#123;<br>       List&lt;Event&gt; list = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>       <span class="hljs-keyword">for</span> (Event event : events) &#123;<br>           <span class="hljs-type">Event</span> <span class="hljs-variable">intercept</span> <span class="hljs-operator">=</span> intercept(event);<br>           <span class="hljs-keyword">if</span>(intercept != <span class="hljs-literal">null</span>)&#123;<br>               list.add(intercept);<br>           &#125;<br>       &#125;<br>       <span class="hljs-keyword">return</span> list;<br>   &#125;<br></code></pre></td></tr></table></figure><p>优化后的拦截器代码:使用多多线程解析 List<Event> events,同时去除了重复的JSONObject.parseObject(log);</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> Event <span class="hljs-title function_">intercept</span><span class="hljs-params">(Event event)</span> &#123;<br>    Map&lt;String, String&gt; headers = event.getHeaders();<br>    <span class="hljs-type">JSONObject</span> <span class="hljs-variable">jsonObject</span> <span class="hljs-operator">=</span> JSON.parseObject(<span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(event.getBody(), StandardCharsets.UTF_8));<br>    <span class="hljs-keyword">if</span> (jsonObject.containsKey(<span class="hljs-string">&quot;key&quot;</span>)) &#123;<br>        headers.put(<span class="hljs-string">&quot;timestamp&quot;</span>, jsonObject.getString(<span class="hljs-string">&quot;timestamp&quot;</span>));<br>        headers.put(<span class="hljs-string">&quot;xxx&quot;</span>, jsonObject.getString(<span class="hljs-string">&quot;xxx&quot;</span>));<br>        headers.put(<span class="hljs-string">&quot;yyy&quot;</span>, jsonObject.getString(<span class="hljs-string">&quot;yyy&quot;</span>));<br>        <span class="hljs-keyword">return</span> event;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>    &#125;<br><br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> List&lt;Event&gt; <span class="hljs-title function_">intercept</span><span class="hljs-params">(List&lt;Event&gt; events)</span> &#123;<br>    List&lt;Event&gt; list = events.stream()<br>            .parallel()<br>            .map(event -&gt; intercept(event))<br>            .filter(e -&gt; e != <span class="hljs-literal">null</span>).collect(Collectors.toList());<br>    <span class="hljs-keyword">return</span> list;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>小结:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">这里总结以下:  events.stream().parallel() 并行执行,当events 个数多的时候效果更好.<br>同时需要属性jdk8+的lamada表达式及内部原理.<br>这里涉及到后期优化kafka消费者的读取批次参数了.<br>这对拦截器的效率提升巨大.<br></code></pre></td></tr></table></figure></li></ul><p>来看一下优化拦截器后的火焰图:<br><img src="https://i.loli.net/2021/11/29/8ohcMwQ7tWx6kIr.png"></p><h3 id="修改kafka读取批次和channel大小及sink的批次大小"><a href="#修改kafka读取批次和channel大小及sink的批次大小" class="headerlink" title="修改kafka读取批次和channel大小及sink的批次大小."></a>修改kafka读取批次和channel大小及sink的批次大小.</h3><p>在高配机器上上传修改后拦截器jar后,不修改kafka消费参数时,提升效果来到了72MB&#x2F;s,但是还是没有达到预期100MB+的理想情况.</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">a1.sources.r1.batchSize</span> <span class="hljs-string">=</span> <span class="hljs-number">40000</span><br><span class="hljs-string">a1.sources.r1.batchDurationMillis</span> <span class="hljs-string">=</span> <span class="hljs-number">500</span><br><span class="hljs-string">a1.sources.r1.kafka.consumer.max.poll.records</span> <span class="hljs-string">=</span> <span class="hljs-number">40000</span> <span class="hljs-comment">#这个和a1.sources.r1.batchSize很关键</span><br></code></pre></td></tr></table></figure><p>kafka.consumer.max.poll.records: 消费者批次拉取数据大小<br>a1.sources.r1.batchSize : flume的source批次写入channel时的大小.</p><p>修改上了上述参数后,重启flume,flume消费机器网速来到120MB&#x2F;s达到了理想情况.</p><h2 id="优化总结"><a href="#优化总结" class="headerlink" title="优化总结"></a>优化总结</h2><ol><li>在flume拦截使用多线程时,首先需要批次数据更多更有利,同时和cpu个数和频率也有关一定关系.</li><li>flume-source:kafka-consumer批次拉取也很关键.如果设置大小.对1也有影响.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Flume </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>macos中遇到的一些问题</title>
      <link href="/other/2021-11-03-macos%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/"/>
      <url>/other/2021-11-03-macos%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>记录自己在使用MacOS中遇到的一些问题.</p><h2 id="Bash版本问题-gt-date命令问题"><a href="#Bash版本问题-gt-date命令问题" class="headerlink" title="Bash版本问题-&gt;date命令问题"></a>Bash版本问题-&gt;date命令问题</h2><ul><li>场景:<br>自己在使用date命令时发现,本机mac和linux环境的中执行效果不一样;<br>linux可以正常执行,但是mac不行</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># linux 环境下</span><br>[root@localhost]~<span class="hljs-comment"># date -d &quot;2021-01-01 00:00:00&quot; +&quot;%Y%m%d&quot;</span><br>20210101<br><br><span class="hljs-comment"># mac</span><br>~ ❯ <span class="hljs-built_in">date</span> -d <span class="hljs-string">&quot;2021-01-01 00:00:00&quot;</span> +<span class="hljs-string">&quot;%Y%m%d&quot;</span><br>usage: <span class="hljs-built_in">date</span> [-jnRu] [-d dst] [-r seconds] [-t west] [-v[+|-]val[ymwdHMS]] ...<br>            [-f <span class="hljs-built_in">fmt</span> <span class="hljs-built_in">date</span> | [[[mm]<span class="hljs-built_in">dd</span>]HH]MM[[cc]yy][.ss]] [+format]<br></code></pre></td></tr></table></figure><ul><li>原因<br>查看bash版本发现:疑是版本问题.同时在升级完bash版本后无效,发现原因是: macos date 命令未遵循Linux规范</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#mac bash version</span><br>~ ❯ bash -version <br>GNU bash, version 3.2.57(1)-release (arm64-apple-darwin21)<br>Copyright (C) 2007 Free Software Foundation, Inc.<br><br><span class="hljs-comment"># linux bash version</span><br>[root@localhost]~<span class="hljs-comment"># bash -version</span><br>GNU bash， 版本 4.2.46(2)-release (x86_64-redhat-linux-gnu)<br>Copyright (C) 2011 Free Software Foundation, Inc.<br>许可证 GPLv3+: GNU GPL 许可证版本3或者更高 &lt;http://gnu.org/licenses/gpl.html&gt;<br></code></pre></td></tr></table></figure><ul><li>解决方案</li></ul><p>升级bash,升级后无效; 最后发现:macos date 命令未遵循Linux规范,暂时无解.</p><ol><li>macos date <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">date</span> -v -1d -j -f <span class="hljs-string">&#x27;%Y-%m-%d&#x27;</span> <span class="hljs-string">&#x27;2021-10-01&#x27;</span> +<span class="hljs-string">&quot;%Y/%m/%d&quot;</span><br>2021/09/30<br></code></pre></td></tr></table></figure></li><li>linux date<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">date</span> -d<span class="hljs-string">&#x27;-1 day 2021-10-01&#x27;</span> +<span class="hljs-string">&quot;%Y/%m/%d&quot;</span><br>2021/09/30<br></code></pre></td></tr></table></figure></li></ol><h2 id="M1-MacOS-RocksDB报错"><a href="#M1-MacOS-RocksDB报错" class="headerlink" title="M1 MacOS RocksDB报错"></a>M1 MacOS RocksDB报错</h2><p>librocksdbjni-osx.jnilib’ (mach-o file, but is an incompatible architecture (have ‘x86_64’, need ‘arm64e’))</p><p>现象: </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs log">Caused by: java.lang.UnsatisfiedLinkError: /private/var/folders/yy/bzy10qzx6tqdtl8c6rglyc5m0000gn/T/rocksdb-lib-3af5f881382477b5f054b9f48837917c/librocksdbjni-osx.jnilib: dlopen(/private/var/folders/yy/bzy10qzx6tqdtl8c6rglyc5m0000gn/T/rocksdb-lib-3af5f881382477b5f054b9f48837917c/librocksdbjni-osx.jnilib, 0x0001): tried: &#x27;/private/var/folders/yy/bzy10qzx6tqdtl8c6rglyc5m0000gn/T/rocksdb-lib-3af5f881382477b5f054b9f48837917c/librocksdbjni-osx.jnilib&#x27; (mach-o file, but is an incompatible architecture (have &#x27;x86_64&#x27;, need &#x27;arm64e&#x27;)), &#x27;/usr/lib/librocksdbjni-osx.jnilib&#x27; (no such file)<br>at java.lang.ClassLoader$NativeLibrary.load(Native Method)<br>at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1950)<br>at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1832)<br>at java.lang.Runtime.load0(Runtime.java:811)<br>at java.lang.System.load(System.java:1088)<br>at org.rocksdb.NativeLibraryLoader.loadLibraryFromJar(NativeLibraryLoader.java:78)<br>at org.rocksdb.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:56)<br>at org.apache.flink.contrib.streaming.state.EmbeddedRocksDBStateBackend.ensureRocksDBIsLoaded(EmbeddedRocksDBStateBackend.java:860)<br>... 17 more<br><br></code></pre></td></tr></table></figure><p>暂时无法解决,尚未支持M1 <a href="https://github.com/facebook/rocksdb/issues/7720">https://github.com/facebook/rocksdb/issues/7720</a></p><p>2022年07月19日更新：<br>RocksDB 6.29.4.1 版本已更新支持：<a href="https://github.com/facebook/rocksdb/issues/7720#issuecomment-1079648907">https://github.com/facebook/rocksdb/issues/7720#issuecomment-1079648907</a><br>maven: <a href="https://mvnrepository.com/artifact/org.rocksdb/rocksdbjni">https://mvnrepository.com/artifact/org.rocksdb/rocksdbjni</a></p><h2 id="“xxxxxx”已损坏，无法打开。-您应该将它移到废纸篓。"><a href="#“xxxxxx”已损坏，无法打开。-您应该将它移到废纸篓。" class="headerlink" title="“xxxxxx”已损坏，无法打开。 您应该将它移到废纸篓。"></a>“xxxxxx”已损坏，无法打开。 您应该将它移到废纸篓。</h2><p>发生这种情况是因为app开发者没有付费获得Apple开发者许可证；导致app对于Macos系统没有得到公证许可。<br>解决方案</p><ul><li>方法1：绕过公证<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo xattr -rd com.apple.quarantine /Applications/xxxxxx.app<br></code></pre></td></tr></table></figure>或<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo xattr -rd com.apple.quarantine <br></code></pre></td></tr></table></figure></li><li>方案2：安装时绕过公证<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">brew install librewolf --no-quarantine <br></code></pre></td></tr></table></figure></li></ul><p>参考文章：<br>方法1：<a href="https://macwk.com/article/macos-file-damage">https://macwk.com/article/macos-file-damage</a><br>方法2：<a href="https://librewolf.net/docs/faq/#how-do-i-get-native-messaging-to-work-1">https://librewolf.net/docs/faq/#how-do-i-get-native-messaging-to-work-1</a></p><h1 id="打开终端提示-”You-have-mail“"><a href="#打开终端提示-”You-have-mail“" class="headerlink" title="打开终端提示 ”You have mail“"></a>打开终端提示 ”You have mail“</h1><p>执行mail命令，接着删除文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">mail<br>d *<br></code></pre></td></tr></table></figure><p>删除mail相关文件 <strong>记得替换USERNAME为本地电脑的用户名</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">rm</span> -rf /var/mail/USENAME<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink1.13.2手动编译</title>
      <link href="/flink/2021-09-10-Flink1.13.2%E6%89%8B%E5%8A%A8%E7%BC%96%E8%AF%91/"/>
      <url>/flink/2021-09-10-Flink1.13.2%E6%89%8B%E5%8A%A8%E7%BC%96%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink1-13-2手动编译"><a href="#Flink1-13-2手动编译" class="headerlink" title="Flink1.13.2手动编译"></a>Flink1.13.2手动编译</h1><h2 id="编译环境"><a href="#编译环境" class="headerlink" title="编译环境"></a>编译环境</h2><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 系统</span><br><span class="hljs-attribute">Linux</span> <span class="hljs-number">3</span>.<span class="hljs-number">10</span>.<span class="hljs-number">0</span>-<span class="hljs-number">1127</span>.el7.x86_64 #<span class="hljs-number">1</span> SMP Tue Mar <span class="hljs-number">31</span> <span class="hljs-number">23</span>:<span class="hljs-number">36</span>:<span class="hljs-number">51</span> UTC <span class="hljs-number">2020</span> x86_64 x86_64 x86_64 GNU/Linux<br><br><span class="hljs-comment"># jdk maven</span><br><span class="hljs-attribute">Apache</span> Maven <span class="hljs-number">3</span>.<span class="hljs-number">6</span>.<span class="hljs-number">3</span> (cecedd343002696d0abb50b32b541b8a6ba2883f)<br><span class="hljs-attribute">Maven</span> home: /home/apache-maven-<span class="hljs-number">3</span>.<span class="hljs-number">6</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">Java</span> version: <span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span>_252, vendor: Oracle Corporation, runtime: /usr/lib/jvm/java-<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span>-openjdk-<span class="hljs-number">1.8.0.252</span>.b09-<span class="hljs-number">2</span>.el7_8.x86_64/jre<br><span class="hljs-attribute">Default</span> locale: en_US, platform encoding: UTF-<span class="hljs-number">8</span><br><span class="hljs-attribute">OS</span> name: <span class="hljs-string">&quot;linux&quot;</span>, version: <span class="hljs-string">&quot;3.10.0-1127.el7.x86_64&quot;</span>, arch: <span class="hljs-string">&quot;amd64&quot;</span>, family: <span class="hljs-string">&quot;unix&quot;</span><br><span class="hljs-comment"># flink</span><br><span class="hljs-attribute">flink</span>-<span class="hljs-number">1</span>.<span class="hljs-number">13</span>.<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h2 id="编译步骤"><a href="#编译步骤" class="headerlink" title="编译步骤"></a>编译步骤</h2><h3 id="1-解压源码"><a href="#1-解压源码" class="headerlink" title="1.解压源码"></a>1.解压源码</h3><h3 id="2-执行编译"><a href="#2-执行编译" class="headerlink" title="2.执行编译"></a>2.执行编译</h3><p>指定hadoop版本，scala版本，hive版本等信息</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">mvn</span> clean install -T4C -DskipTests -Dfast -Dhadoop.version=<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">1</span> -Dscala-<span class="hljs-number">2</span>.<span class="hljs-number">11</span> -Dhive.version=<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p><strong>如果环境中正常的情况，上述步骤可以正常编译出符合自己环境的flink运行包</strong></p><h3 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h3><ul><li><p>flink-shaded-hadoop编译失败时，下载flink-shaded编译后在进行flink编译</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">mvn clean install -DskipTests -Dmaven.javadoc.<span class="hljs-attribute">skip</span>=<span class="hljs-literal">true</span> -Dcheckstyle.<span class="hljs-attribute">skip</span>=<span class="hljs-literal">true</span> -Drat.<span class="hljs-attribute">skip</span>=<span class="hljs-literal">true</span> -pl flink-shaded-hadoop-2-parent/flink-shaded-hadoop-2-uber -am -Dhadoop.<span class="hljs-attribute">version</span>=3.2.1<br></code></pre></td></tr></table></figure></li><li><p>如果出现依赖问题增加仓库</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">repositories</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>jetty<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>jetty Repository<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>http://repo.hortonworks.com/content/groups/public/<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">releases</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">enabled</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">enabled</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">updatePolicy</span>&gt;</span>daily<span class="hljs-tag">&lt;/<span class="hljs-name">updatePolicy</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">releases</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">snapshots</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">enabled</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">enabled</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">checksumPolicy</span>&gt;</span>warn<span class="hljs-tag">&lt;/<span class="hljs-name">checksumPolicy</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">snapshots</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">layout</span>&gt;</span>default<span class="hljs-tag">&lt;/<span class="hljs-name">layout</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span>      <br><span class="hljs-tag">&lt;/<span class="hljs-name">repositories</span>&gt;</span><br><br></code></pre></td></tr></table></figure></li><li><p>flink-yarn-test编译失败，跳过</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs xml"><br><span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.8.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>$&#123;java.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>$&#123;java.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- 略过测试代码的编译 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">skip</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">skip</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- The semantics of this option are reversed, see MCOMPILER-209. --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">useIncrementalCompilation</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">useIncrementalCompilation</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">compilerArgs</span>&gt;</span><br>                <span class="hljs-comment">&lt;!-- Prevents recompilation due to missing package-info.class, see MCOMPILER-205 --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">arg</span>&gt;</span>-Xpkginfo:always<span class="hljs-tag">&lt;/<span class="hljs-name">arg</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">compilerArgs</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span>  <br><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> Complie </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Python编译打包为并生成deb(带桌面图标)</title>
      <link href="/python/2021-09-08-Python%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E4%B8%BA%E5%B9%B6%E7%94%9F%E6%88%90deb(%E5%B8%A6%E6%A1%8C%E9%9D%A2%E5%9B%BE%E6%A0%87)/"/>
      <url>/python/2021-09-08-Python%E7%BC%96%E8%AF%91%E6%89%93%E5%8C%85%E4%B8%BA%E5%B9%B6%E7%94%9F%E6%88%90deb(%E5%B8%A6%E6%A1%8C%E9%9D%A2%E5%9B%BE%E6%A0%87)/</url>
      
        <content type="html"><![CDATA[<h1 id="Python编译打包为并生成deb-带桌面图标"><a href="#Python编译打包为并生成deb-带桌面图标" class="headerlink" title="Python编译打包为并生成deb(带桌面图标)"></a>Python编译打包为并生成deb(带桌面图标)</h1><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs vim">Ubuntu20.<span class="hljs-number">04</span><br>Python3.<span class="hljs-number">8</span><br><br># 项目未打包前目录结构<br>tree -L <span class="hljs-number">2</span><br>❯ tree -L <span class="hljs-number">2</span><br>.<br>├── application.png<br>├── debbuild<br>│   ├── DEBIAN<br>│   └── usr<br>├── exec_cmd.<span class="hljs-keyword">py</span><br>├── main.<span class="hljs-keyword">py</span><br>├── __pycache__<br>│   └── main.cpython-<span class="hljs-number">38</span>.pyc<br>├── random_wallpaper.<span class="hljs-keyword">py</span><br><br><br></code></pre></td></tr></table></figure><h2 id="1-安装pyinstaller"><a href="#1-安装pyinstaller" class="headerlink" title="1 安装pyinstaller"></a>1 安装pyinstaller</h2><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip3 <span class="hljs-keyword">install</span> pyinstaller<br></code></pre></td></tr></table></figure><h2 id="2-将main编译为二进制可执行文件"><a href="#2-将main编译为二进制可执行文件" class="headerlink" title="2 将main编译为二进制可执行文件"></a>2 将main编译为二进制可执行文件</h2><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs css">pyinstaller -F <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span>  打包ubuntu下的可执行文件<br>pyinstaller -F -w <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span>  不带控制台的打包<br># 带有图标的<br>pyinstaller -F -w -<span class="hljs-selector-tag">i</span> application<span class="hljs-selector-class">.png</span> <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span>  打包指定ubuntu下的可执行文件的图标打包<br><br># 编译完成后目录：<br>❯ tree -L <span class="hljs-number">2</span><br>.<br>├── application<span class="hljs-selector-class">.png</span><br>├── build<br>│   └── <span class="hljs-selector-tag">main</span><br>├── dist<br>│   └── <span class="hljs-selector-tag">main</span><br>├── exec_cmd<span class="hljs-selector-class">.py</span><br>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span><br>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.spec</span><br>├── __pycache__<br>│   └── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>├── random_wallpaper<span class="hljs-selector-class">.py</span><br>└── venv<br>    ├── bin<br>    ├── include<br>    ├── lib<br>    ├── lib64 -&gt; lib<br>    └── pyvenv<span class="hljs-selector-class">.cfg</span><br><br></code></pre></td></tr></table></figure><p><strong>dist&#x2F;main为当前系统可执行文件</strong></p><h2 id="3-将可执行文件打包为deb并且设置桌面图标（Ubuntu环境）"><a href="#3-将可执行文件打包为deb并且设置桌面图标（Ubuntu环境）" class="headerlink" title="3 将可执行文件打包为deb并且设置桌面图标（Ubuntu环境）"></a>3 将可执行文件打包为deb并且设置桌面图标（Ubuntu环境）</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs awk">mkdir debbuild &amp;&amp; cd debbuild<br><span class="hljs-comment">#以 debbuild 根目录，创建如下目录和文件</span><br>DEBIAN,usr<span class="hljs-regexp">/lib/</span>RandomWallPaper ,usr<span class="hljs-regexp">/lib/</span>share<span class="hljs-regexp">/applications ,usr/</span>lib<span class="hljs-regexp">/share/i</span>cons<br>❯ tree<br>.<br>├── DEBIAN<br>│   └── control<br>└── usr<br>    ├── lib<br>    │   └── RandomWallpaper<br>    │       └── main<br>    └── share<br>        ├── applications<br>        │   └── RandomWallpaper.desktop<br>        └── icons<br>            └── RandomWallpaper.png<br><br></code></pre></td></tr></table></figure><p><strong>usr&#x2F;lib&#x2F;RandomWallPaper&#x2F;main 这个文件就是可执行二进制文件，来自于dist&#x2F;main ; RandomWallpaper.png 图标文件为自定义</strong></p><h3 id="3-1-control"><a href="#3-1-control" class="headerlink" title="3.1 control"></a>3.1 control</h3><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">Package:</span> RandomWallpaper<br><span class="hljs-symbol">Version:</span> <span class="hljs-number">1.0</span><span class="hljs-number">.0</span><br><span class="hljs-symbol">Architecture:</span> amd64<br><span class="hljs-symbol">Maintainer:</span> lius<br><span class="hljs-symbol">Description:</span> random <span class="hljs-keyword">set</span> desktop background img <span class="hljs-keyword">and</span> lock img<br></code></pre></td></tr></table></figure><h3 id="3-2-RandomWallpaper-desktop"><a href="#3-2-RandomWallpaper-desktop" class="headerlink" title="3.2 RandomWallpaper.desktop"></a>3.2 RandomWallpaper.desktop</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Desktop Entry]</span><br><span class="hljs-attr">Name</span>=RandomWallpaper<br><span class="hljs-attr">Comment</span>=An example<br><span class="hljs-attr">Exec</span>=/usr/lib/RandomWallpaper/main<br><span class="hljs-attr">Icon</span>=/usr/share/icons/RandomWallpaper.png<br><span class="hljs-attr">Terminal</span>=<span class="hljs-literal">false</span><br><span class="hljs-attr">Type</span>=Application<br><span class="hljs-attr">X-Ubuntu-Touch</span>=<span class="hljs-literal">true</span><br><span class="hljs-attr">Categories</span>=Development<br></code></pre></td></tr></table></figure><h2 id="4-执行打包"><a href="#4-执行打包" class="headerlink" title="4 执行打包"></a>4 执行打包</h2><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">cd</span> ..<br><span class="hljs-selector-id">#---------------</span>#<br>❯ <span class="hljs-selector-tag">tree</span> <span class="hljs-selector-tag">-L</span> <span class="hljs-number">2</span><br>.<br>├── <span class="hljs-selector-tag">application</span><span class="hljs-selector-class">.ico</span><br>├── <span class="hljs-selector-tag">application</span><span class="hljs-selector-class">.png</span><br>├── <span class="hljs-selector-tag">build</span><br>│   └── <span class="hljs-selector-tag">main</span><br>├── <span class="hljs-selector-tag">debbuild</span><br>│   ├── <span class="hljs-selector-tag">DEBIAN</span><br>│   └── <span class="hljs-selector-tag">usr</span><br>├── <span class="hljs-selector-tag">dist</span><br>│   └── <span class="hljs-selector-tag">main</span><br>├── <span class="hljs-selector-tag">exec_cmd</span><span class="hljs-selector-class">.py</span><br>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span><br>├── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.spec</span><br>├── <span class="hljs-selector-tag">pk</span><span class="hljs-selector-class">.sh</span><br>├── <span class="hljs-selector-tag">__pycache__</span><br>│   └── <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>├── <span class="hljs-selector-tag">randomWallpaper1</span><span class="hljs-selector-class">.0</span><span class="hljs-selector-class">.0</span><span class="hljs-selector-class">.amd64</span><span class="hljs-selector-class">.deb</span><br>├── <span class="hljs-selector-tag">random_wallpaper</span><span class="hljs-selector-class">.py</span><br>└── <span class="hljs-selector-tag">venv</span><br>    ├── <span class="hljs-selector-tag">bin</span><br>    ├── <span class="hljs-selector-tag">include</span><br>    ├── <span class="hljs-selector-tag">lib</span><br>    ├── <span class="hljs-selector-tag">lib64</span> <span class="hljs-selector-tag">-</span>&gt; <span class="hljs-selector-tag">lib</span><br>    └── <span class="hljs-selector-tag">pyvenv</span><span class="hljs-selector-class">.cfg</span><br><span class="hljs-selector-id">#----------------------</span>#<br><br><span class="hljs-selector-tag">sudo</span> <span class="hljs-selector-tag">dpkg</span> <span class="hljs-selector-tag">-b</span> <span class="hljs-selector-tag">debbuild</span>  <span class="hljs-selector-tag">randomWallpaper1</span><span class="hljs-selector-class">.0</span><span class="hljs-selector-class">.0</span><span class="hljs-selector-class">.amd64</span><span class="hljs-selector-class">.deb</span><br></code></pre></td></tr></table></figure><h2 id="5-验证安装"><a href="#5-验证安装" class="headerlink" title="5 验证安装"></a>5 验证安装</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">sudo dpkg -<span class="hljs-selector-tag">i</span> randomWallpaper1.<span class="hljs-number">0.0</span><span class="hljs-selector-class">.amd64</span><span class="hljs-selector-class">.deb</span><br><br></code></pre></td></tr></table></figure><h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><p>翻阅资料发现pyinstaller在某个版本后，不再支持交叉编译，因为兼容性太差。需要对应操作系统的可执行文件，需要到相应的操作系统下进行编译。 </p><p><strong>（But Golang 可以，所以后期有类似的应用程序，尽量都会使用go进行编写）</strong></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink-Sink-ElasticSearch部分字段追加数据</title>
      <link href="/flink/2021-08-13-Flink-Sink-ElasticSearch%E9%83%A8%E5%88%86%E5%AD%97%E6%AE%B5%E8%BF%BD%E5%8A%A0%E6%95%B0%E6%8D%AE/"/>
      <url>/flink/2021-08-13-Flink-Sink-ElasticSearch%E9%83%A8%E5%88%86%E5%AD%97%E6%AE%B5%E8%BF%BD%E5%8A%A0%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink-Flink-Sink-ElasticSearch部分字段追加数据"><a href="#Flink-Flink-Sink-ElasticSearch部分字段追加数据" class="headerlink" title="Flink Flink-Sink-ElasticSearch部分字段追加数据"></a>Flink Flink-Sink-ElasticSearch部分字段追加数据</h1><h2 id="背景需求"><a href="#背景需求" class="headerlink" title="背景需求"></a>背景需求</h2><p>因flink消费kafka，其中数据需要进行补维操作，正常补维的数据都保存了最新属性数据到mysql。当任务正常流通时，从mysql拿取属性数据进行维度补充没有问题。<br>现有需求：当数据重放时：需要拿到对应时间状态的维度数据。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="方案一："><a href="#方案一：" class="headerlink" title="方案一："></a>方案一：</h3><p>flink 双流join 关联用户ID，或其他关键值进行双流join完成。<br><a href="https://ci.apache.org/projects/flink/flink-docs-master/docs/dev/datastream/operators/joining/#interval-join">https://ci.apache.org/projects/flink/flink-docs-master/docs/dev/datastream/operators/joining/#interval-join</a></p><p>方案一缺点：</p><ol><li>存在重放数据中没有属性数据时，关联不上的问题。当然这个也可以依赖外部储存解决</li><li>增加程序的关联复杂度。</li></ol><p>优点：</p><ol><li>利用flink join机制 ，降低对外部存储系统依赖</li><li>高效。可以解决大部分的关联数据，但是有部分可能还是关联不上。</li></ol><h3 id="方案二"><a href="#方案二" class="headerlink" title="方案二:"></a>方案二:</h3><p>通过保存历史版本数据，当回放数据时，判断当前数据与最新本的版本号是否一致。<br>不一致时，使用相对应的版本的属性数据。<br>优点：</p><ol><li>不存在数据丢失。</li><li>相对程序来说简单一点</li></ol><p>缺点：</p><ol><li>严重依赖外部存储。特别是数据量巨大的情况。</li></ol><h2 id="最终选择"><a href="#最终选择" class="headerlink" title="最终选择"></a>最终选择</h2><p>综合考虑下来，选择了方案二<br>因公司相关程序都是跑在云（Flink on Yarn-EMR)上，没有自己的分布式存储系统。<br>本来想使用HBase,但是hbase强依赖hdfs，公司没有自建的HDFS集群，放弃。<br>选择使用ES。</p><p>说了这么多，好像都跟ES没有啥关系。。。。</p><p>选择ES来存储属性维度版本数据。<br>版本号就是属性数据中的timestamp字段（时间戳字段）<br>分别两个索性<br>1：存储版本的索性  user_versions<br>2：存储对应版本的数据索引 user_property_index </p><p>其中索引user_versions专门用来存储用户数据的版本信息<br>eg:<br>user_versions<br>id&#x3D;pid_uid<br>source&#x3D;timestamps:[1628823667951]</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>       <span class="hljs-attr">&quot;_index&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user_versions&quot;</span><span class="hljs-punctuation">,</span><br>       <span class="hljs-attr">&quot;_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;_doc&quot;</span><span class="hljs-punctuation">,</span><br>       <span class="hljs-attr">&quot;_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1_100007140&quot;</span><span class="hljs-punctuation">,</span><br>       <span class="hljs-attr">&quot;_score&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1.0</span><span class="hljs-punctuation">,</span><br>       <span class="hljs-attr">&quot;_source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>         <span class="hljs-attr">&quot;timestamps&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>           <span class="hljs-number">1628823667951</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628823667952</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628823668001</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628823855026</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628823856738</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628823873136</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628823958514</span><span class="hljs-punctuation">,</span><br>           <span class="hljs-number">1628824061838</span><br>         <span class="hljs-punctuation">]</span><br>       <span class="hljs-punctuation">&#125;</span><br>     <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>user_property_index<br>id&#x3D;pid_uid_timestamp<br>eg:其余字段省略了。只列出关键数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">GET user_property_index/_doc/1_100007140_1628824061838<br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;_index&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;user_property_index&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_type&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;_doc&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1_100007140_1628824061838&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_version&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_seq_no&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">3360</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_primary_term&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;found&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-keyword">true</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;_source&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;data&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;&#123;</span><br><span class="hljs-string">        &quot;</span>pid<span class="hljs-string">&quot;: &quot;</span><span class="hljs-number">1</span><span class="hljs-string">&quot;,</span><br><span class="hljs-string">        &quot;</span>uid<span class="hljs-string">&quot;: &quot;</span><span class="hljs-number">100007140</span><span class="hljs-string">&quot;,</span><br><span class="hljs-string">        &quot;</span>timestamp<span class="hljs-string">&quot;: &quot;</span><span class="hljs-number">1628824061838</span><span class="hljs-string">&quot;,</span><br><span class="hljs-string">        &quot;</span>md5<span class="hljs-string">&quot;: &quot;</span>f83874b7742c78bd916cc430c44df527<span class="hljs-string">&quot;</span><br><span class="hljs-string">    &#125;&quot;</span><span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;update_at&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-number">1628841996</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;id&quot;</span> <span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;1_100007140&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>当存储用户信息时，选择数据追加方式，<br>ES中有关于数据追加方式的介绍<br><a href="https://www.huaweicloud.com/articles/da7557ae10f7f6153d23b000ec2d4015.html">华为云文档</a><br>简陋的<a href="https://www.elastic.co/guide/cn/elasticsearch/php/current/_updating_documents.html">官网文档</a>（应该是我找的方式不对）</p><p>在flink中使用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> ElasticsearchSink&lt;JSONObject&gt; <span class="hljs-title function_">genESSink</span><span class="hljs-params">(List&lt;HttpHost&gt; httpHosts)</span> &#123;<br>        ElasticsearchSink.<span class="hljs-type">Builder</span> <span class="hljs-variable">esBuilder</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ElasticsearchSink</span>.Builder(httpHosts, <span class="hljs-keyword">new</span> <span class="hljs-title class_">ElasticsearchSinkFunction</span>&lt;JSONObject&gt;() &#123;<br><br>            <span class="hljs-keyword">public</span> UpdateRequest <span class="hljs-title function_">createUserPropertySnapshotRequest</span><span class="hljs-params">(JSONObject element)</span> &#123;<br>                <span class="hljs-type">String</span> <span class="hljs-variable">pid</span> <span class="hljs-operator">=</span> element.getString(<span class="hljs-string">&quot;pid&quot;</span>);<br>                <span class="hljs-type">String</span> <span class="hljs-variable">uid</span> <span class="hljs-operator">=</span> element.getString(<span class="hljs-string">&quot;uid&quot;</span>);<br>                <span class="hljs-type">Long</span> <span class="hljs-variable">timestamp</span> <span class="hljs-operator">=</span> element.getLong(<span class="hljs-string">&quot;timestamp&quot;</span>);<br><br>                <span class="hljs-comment">//保存property 信息</span><br>                <span class="hljs-type">String</span> <span class="hljs-variable">propertyId</span> <span class="hljs-operator">=</span> pid + <span class="hljs-string">&quot;_&quot;</span> + uid + <span class="hljs-string">&quot;_&quot;</span> + timestamp;<br>                <span class="hljs-type">UpdateRequest</span> <span class="hljs-variable">updateReq</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">UpdateRequest</span>(ESClient.userPropertyIndex, propertyId);<br>                Map&lt;String, Object&gt; sourceMap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>                sourceMap.put(<span class="hljs-string">&quot;id&quot;</span>, pid + <span class="hljs-string">&quot;_&quot;</span> + uid);<br>                sourceMap.put(<span class="hljs-string">&quot;data&quot;</span>, element.toJSONString());<br>                sourceMap.put(<span class="hljs-string">&quot;update_at&quot;</span>, System.currentTimeMillis() / <span class="hljs-number">1000</span>);<br><br>                <span class="hljs-type">IndexRequest</span> <span class="hljs-variable">indexReq</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IndexRequest</span>(ESClient.userPropertyIndex);<br>                indexReq.id(propertyId);<br>                indexReq.source(sourceMap);<br>                indexReq.timeout(TimeValue.timeValueSeconds(<span class="hljs-number">60</span>));<br><br>                updateReq.doc(sourceMap)<br>                        .upsert(indexReq)<br>                        .timeout(TimeValue.timeValueSeconds(<span class="hljs-number">60</span>));<br>                <span class="hljs-keyword">return</span> updateReq;<br>            &#125;<br><br>            <span class="hljs-meta">@Override</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">process</span><span class="hljs-params">(JSONObject element, RuntimeContext ctx, RequestIndexer indexer)</span> &#123;<br>                indexer.add(<br>                        createUserPropertySnapshotRequest(element),<br>                        createPropertyVersionRequest(element));<br>            &#125;<br><br>            <span class="hljs-keyword">private</span> UpdateRequest <span class="hljs-title function_">createPropertyVersionRequest</span><span class="hljs-params">(JSONObject element)</span> &#123;<br>                <span class="hljs-type">String</span> <span class="hljs-variable">pid</span> <span class="hljs-operator">=</span> element.getString(<span class="hljs-string">&quot;pid&quot;</span>);<br>                <span class="hljs-type">String</span> <span class="hljs-variable">uid</span> <span class="hljs-operator">=</span> element.getString(<span class="hljs-string">&quot;uid&quot;</span>);<br>                <span class="hljs-type">Long</span> <span class="hljs-variable">timestamp</span> <span class="hljs-operator">=</span> element.getLong(<span class="hljs-string">&quot;timestamp&quot;</span>);<br><br>                <span class="hljs-type">String</span> <span class="hljs-variable">versionId</span> <span class="hljs-operator">=</span> pid + <span class="hljs-string">&quot;_&quot;</span> + uid;<br>                <span class="hljs-comment">//保存版本信息</span><br>                <span class="hljs-type">UpdateRequest</span> <span class="hljs-variable">updateReq</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">UpdateRequest</span>(ESClient.versionIndex, versionId);<br>                Map&lt;String, Object&gt; params = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>                params.put(<span class="hljs-string">&quot;new_timestamp&quot;</span>, timestamp);<br>                <span class="hljs-type">String</span> <span class="hljs-variable">idOrCode</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;ctx._source.timestamps.add(params.new_timestamp)&quot;</span>;<br>                <span class="hljs-type">Script</span> <span class="hljs-variable">script</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Script</span>(ScriptType.INLINE, Script.DEFAULT_SCRIPT_LANG, idOrCode, params);<br>                updateReq.script(script);<br><br>                Map&lt;String, Object&gt; sourceMap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>                sourceMap.put(<span class="hljs-string">&quot;timestamps&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">Long</span>[]&#123;timestamp&#125;);<br>                <span class="hljs-type">IndexRequest</span> <span class="hljs-variable">indexReq</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IndexRequest</span>(ESClient.versionIndex);<br>                indexReq.id(versionId);<br>                indexReq.source(sourceMap);<br>                indexReq.timeout(TimeValue.timeValueSeconds(<span class="hljs-number">60</span>));<br>                updateReq.upsert(indexReq)<br>                        .timeout(TimeValue.timeValueSeconds(<span class="hljs-number">60</span>));<br><br>                <span class="hljs-keyword">return</span> updateReq;<br>            &#125;<br>        &#125;);<br><br>        esBuilder.setBulkFlushMaxActions(<span class="hljs-number">3</span>);<br>      <br>        <span class="hljs-keyword">return</span> esBuilder.build();<br>    &#125;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 获取离时间参数版本最近的一个版本</span><br><span class="hljs-comment">     *</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> pid              product_id</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> uid              userId</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> versionTimestamp 时间参数版本号</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span> user_property dataJson</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">getUserVersionProperty</span><span class="hljs-params">(String pid, String uid, Long versionTimestamp)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">versionId</span> <span class="hljs-operator">=</span> pid + <span class="hljs-string">&quot;_&quot;</span> + uid;<br>        <span class="hljs-keyword">try</span> (<span class="hljs-type">RestHighLevelClient</span> <span class="hljs-variable">client</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RestHighLevelClient</span>(clientBuilder)) &#123;<br>            <span class="hljs-comment">//获取最近版本</span><br>            <span class="hljs-type">GetRequest</span> <span class="hljs-variable">getRequest</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">GetRequest</span>(versionIndex, versionId);<br>            <span class="hljs-type">GetResponse</span> <span class="hljs-variable">resp</span> <span class="hljs-operator">=</span> client.get(getRequest, RequestOptions.DEFAULT);<br>            <span class="hljs-keyword">if</span> (resp.isExists()) &#123;<br>                <span class="hljs-type">Object</span> <span class="hljs-variable">timestamps</span> <span class="hljs-operator">=</span> resp.getSource().get(<span class="hljs-string">&quot;timestamps&quot;</span>);<br>                ArrayList&lt;Long&gt; versionList = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>                <span class="hljs-keyword">if</span> (timestamps != <span class="hljs-literal">null</span> &amp;&amp; timestamps <span class="hljs-keyword">instanceof</span> ArrayList) &#123;<br>                    versionList = (ArrayList&lt;Long&gt;) timestamps;<br>                &#125;<br>                <span class="hljs-type">long</span> <span class="hljs-variable">sub</span> <span class="hljs-operator">=</span> versionTimestamp;<br>                <span class="hljs-type">long</span> <span class="hljs-variable">resVersion</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span>;<br>                HashSet&lt;Long&gt; versionSet = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>                versionSet.addAll(versionList);<br>                <span class="hljs-keyword">for</span> (Long version : versionSet) &#123;<br>                    <span class="hljs-type">long</span> <span class="hljs-variable">tempSub</span> <span class="hljs-operator">=</span> versionTimestamp - version;<span class="hljs-comment">//</span><br>                    <span class="hljs-keyword">if</span> (tempSub &gt;= <span class="hljs-number">0</span> &amp;&amp; tempSub &lt; sub) &#123;<span class="hljs-comment">//找到差值最小前一个版本</span><br>                        sub = tempSub;<br>                        resVersion = version;<br>                    &#125;<br>                &#125;<br>                <span class="hljs-keyword">if</span> (resVersion != -<span class="hljs-number">1L</span>) &#123;<br>                    <span class="hljs-type">GetRequest</span> <span class="hljs-variable">proGet</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">GetRequest</span>(userPropertyIndex, pid + <span class="hljs-string">&quot;_&quot;</span> + uid + <span class="hljs-string">&quot;_&quot;</span> + resVersion);<br>                    resp = client.get(proGet, RequestOptions.DEFAULT);<br>                    <span class="hljs-keyword">if</span> (resp.isExists()) &#123;<br>                        Map&lt;String, Object&gt; source = resp.getSource();<br>                        <span class="hljs-keyword">if</span> (source != <span class="hljs-literal">null</span> &amp;&amp; !source.isEmpty()) &#123;<br>                            <span class="hljs-keyword">return</span> source.get(<span class="hljs-string">&quot;data&quot;</span>) == <span class="hljs-literal">null</span> ? <span class="hljs-literal">null</span> : source.get(<span class="hljs-string">&quot;data&quot;</span>).toString();<br>                        &#125; <span class="hljs-keyword">else</span> &#123;<br>                            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>                        &#125;<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>            log.error(<span class="hljs-string">&quot;getUserVersionProperty exception : &quot;</span>, e.getMessage(), e);<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>    &#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> ElasticSearch </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>记一次Kafka-Manager JMX异常处理</title>
      <link href="/kafka/2021-08-02-%E8%AE%B0%E4%B8%80%E6%AC%A1Kafka-Manager-JMX%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"/>
      <url>/kafka/2021-08-02-%E8%AE%B0%E4%B8%80%E6%AC%A1Kafka-Manager-JMX%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="记一次Kafka-Manager-JMX异常处理"><a href="#记一次Kafka-Manager-JMX异常处理" class="headerlink" title="记一次Kafka-Manager JMX异常处理"></a>记一次Kafka-Manager JMX异常处理</h1><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>直接上日志：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs log">2021-08-02 03:49:15,548 - [ERROR] k.m.a.c.BrokerViewCacheActor - Failed to get broker metrics for BrokerIdentity(0,172.34.10.2,9999,false,true,Map(PLAINTEXT -&gt; 9092))<br>java.rmi.ConnectException: Connection refused to host: 127.0.0.1; nested exception is: <br>        java.net.ConnectException: Connection refused (Connection refused)<br>        at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:623)<br>        at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)<br>        at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)<br>        at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:131)<br>        at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:235)<br>        at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:180)<br>        at com.sun.proxy.$Proxy5.newClient(Unknown Source)<br>        at javax.management.remote.rmi.RMIConnector.getConnection(RMIConnector.java:2430)<br>        at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:308)<br>        at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270)<br>Caused by: java.net.ConnectException: Connection refused (Connection refused)<br>        at java.net.PlainSocketImpl.socketConnect(Native Method)<br>        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)<br>        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)<br>        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)<br>        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)<br>        at java.net.Socket.connect(Socket.java:606)<br>        at java.net.Socket.connect(Socket.java:555)<br>        at java.net.Socket.&lt;init&gt;(Socket.java:451)<br>        at java.net.Socket.&lt;init&gt;(Socket.java:228)<br>2021-08-02 03:49:15,559 - [ERROR] k.m.j.KafkaJMX$ - Failed to connect to service:jmx:rmi:///jndi/rmi://172.34.56.7:9999/jmxrmi<br>java.rmi.ConnectException: Connection refused to host: 127.0.0.1; nested exception is: <br>        java.net.ConnectException: Connection refused (Connection refused)<br>        at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:623)<br>        at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)<br>        at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)<br>        at sun.rmi.server.UnicastRef.invoke(UnicastRef.java:131)<br>        at java.rmi.server.RemoteObjectInvocationHandler.invokeRemoteMethod(RemoteObjectInvocationHandler.java:235)<br>        at java.rmi.server.RemoteObjectInvocationHandler.invoke(RemoteObjectInvocationHandler.java:180)<br>        at com.sun.proxy.$Proxy5.newClient(Unknown Source)<br>        at javax.management.remote.rmi.RMIConnector.getConnection(RMIConnector.java:2430)<br>        at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:308)<br>        at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270)<br>Caused by: java.net.ConnectException: Connection refused (Connection refused)<br>        at java.net.PlainSocketImpl.socketConnect(Native Method)<br>        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)<br>        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)<br>        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)<br>        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)<br>        at java.net.Socket.connect(Socket.java:606)<br>        at java.net.Socket.connect(Socket.java:555)<br>        at java.net.Socket.&lt;init&gt;(Socket.java:451)<br>        at java.net.Socket.&lt;init&gt;(Socket.java:228)<br><br></code></pre></td></tr></table></figure><p>启动时已经启动了JMX_PORT端口监控</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">env</span> JMX_PORT=9999 bin/kafka-server-start.sh -daemon ./config/server.properties &amp;<br></code></pre></td></tr></table></figure><h2 id="原因："><a href="#原因：" class="headerlink" title="原因："></a>原因：</h2><p>172.34.56.7，172.34.10.2为broker地址，其中 Connection refused to host: 127.0.0.1 中的127.0.0.1是Broker的JMX上报的地址，当kafka-manager去127.0.0.1连接JMX获取数据时，被拒绝了。实际上应该是去broker的ip:172.34.56.7，172.34.10.2中去获取。</p><p>网上找了很多帖子，发现配置kafka的conf<br>-Djava.rmi.server.hostname&#x3D;172.34.56.7<br>-Dcom.sun.management.jmxremote.local.only&#x3D;false</p><p>这种方式可行，但是想了想不太友好。<br>受此篇文章启发：<a href="https://blog.csdn.net/chenchaofuck1/article/details/51558995">https://blog.csdn.net/chenchaofuck1/article/details/51558995</a><br>通过hostname -i 发现<br>返回了127.0.0.1<br>猜测JMX上报时，java.rmi.server.hostname 地址上报的应该是hostname -i得到的值</p><h2 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h2><p>修改&#x2F;etc&#x2F;hosts<br>增加<br>172.34.56.7 <code>hostname</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cat</span> /etc/hosts<br>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4<br>::1         localhost6 localhost6.localdomain6<br>172.34.56.7  ip-172-34-56-7.compute.internal<br></code></pre></td></tr></table></figure><p>再hostname -i 返回了机器的内网地址。<br>然后重启kafka-broker，kafka-manager可以正常监控了。</p><h2 id="附录：hostname相关知识"><a href="#附录：hostname相关知识" class="headerlink" title="附录：hostname相关知识"></a>附录：hostname相关知识</h2><p><a href="https://www.huaweicloud.com/articles/e06cc282064a70fb8101ca48944ab64a.html">https://www.huaweicloud.com/articles/e06cc282064a70fb8101ca48944ab64a.html</a></p><p>对于-Djava.rmi.server.hostname orcale-jdk文档说明：<br><a href="https://docs.oracle.com/javase/9/management/monitoring-and-management-using-jmx-technology.htm#JSMGM-GUID-F08985BB-629A-4FBF-A0CB-8762DF7590E0">https://docs.oracle.com/javase/9/management/monitoring-and-management-using-jmx-technology.htm#JSMGM-GUID-F08985BB-629A-4FBF-A0CB-8762DF7590E0</a></p>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>利用logstash迁移MySQL数据至Elasticsearch</title>
      <link href="/datasource/2021-07-06-%E5%88%A9%E7%94%A8logstash%E8%BF%81%E7%A7%BBMySQL%E6%95%B0%E6%8D%AE%E8%87%B3Elasticsearch/"/>
      <url>/datasource/2021-07-06-%E5%88%A9%E7%94%A8logstash%E8%BF%81%E7%A7%BBMySQL%E6%95%B0%E6%8D%AE%E8%87%B3Elasticsearch/</url>
      
        <content type="html"><![CDATA[<h1 id="利用logstash迁移MySQL数据至Elasticsearch"><a href="#利用logstash迁移MySQL数据至Elasticsearch" class="headerlink" title="利用logstash迁移MySQL数据至Elasticsearch"></a>利用logstash迁移MySQL数据至Elasticsearch</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>公司某个表A，目前时mysql单库单表，对接Flink，主要用于读取和写入操作，后期考虑到量大后，对读写性能要求一定抗压，现将mysql迁移至Elasticsearch.</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">MySql</span> Version: <span class="hljs-number">5</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">Elasticsearch</span> Version： <span class="hljs-number">7</span>.<span class="hljs-number">9</span>.<span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><h2 id="安装logstash"><a href="#安装logstash" class="headerlink" title="安装logstash"></a>安装logstash</h2><p>下载对应Elasticsearch版本的logstash</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/ &amp;&amp; <span class="hljs-built_in">mkdir</span> ~/opt &amp;&amp; <span class="hljs-built_in">cd</span> opt/<br>wget https://artifacts.elastic.co/downloads/logstash/logstash-7.9.3.tar.gz<br><br>tar -zxvf logstash-7.9.3.tar.gz<br><br><span class="hljs-built_in">cd</span> logstash-7.9.3 &amp;&amp; <span class="hljs-built_in">mkdir</span> mysql <br><br>wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.49/mysql-connector-java-5.1.49.jar -o mysql/mysql-connector-java-5.1.49.jar<br><br><span class="hljs-built_in">cp</span> config/logstash-sample.conf mysql/logstash-mysql-es.conf<br><br><br>bin/logstash-plugin install logstash-input-jdbc<br>bin/logstash-plugin install logstash-output-elasticsearch<br><br>vim mysql/logstash-mysql-es.conf<br><br></code></pre></td></tr></table></figure><h2 id="配置-logstash-mysql-es-conf"><a href="#配置-logstash-mysql-es-conf" class="headerlink" title="配置 logstash-mysql-es.conf"></a>配置 logstash-mysql-es.conf</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">input</span> &#123;<br>    <span class="hljs-string">jdbc</span> &#123;<br>        <span class="hljs-comment"># 设置 MySql/MariaDB 数据库url以及数据库名称</span><br>        <span class="hljs-string">jdbc_connection_string</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;jdbc:mysql://10.0.xx.xx:3306/dimension?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&quot;</span><br>        <span class="hljs-comment"># 用户名和密码</span><br>        <span class="hljs-string">jdbc_user</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;xxxxx&quot;</span><br>        <span class="hljs-string">jdbc_password</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;xxxxx&quot;</span><br>        <span class="hljs-comment"># 数据库驱动所在位置，可以是绝对路径或者相对路径</span><br>        <span class="hljs-string">jdbc_driver_library</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/home/elex/opt/logstash-7.9.3/mysql/mysql-connector-java-5.1.49.jar&quot;</span><br>        <span class="hljs-comment"># 驱动类名</span><br>        <span class="hljs-string">jdbc_driver_class</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;com.mysql.jdbc.Driver&quot;</span><br>        <span class="hljs-comment"># 开启分页</span><br>        <span class="hljs-string">jdbc_paging_enabled</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;true&quot;</span><br>        <span class="hljs-comment"># 分页每页数量，可以自定义</span><br>        <span class="hljs-string">jdbc_page_size</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;500000&quot;</span><br>        <span class="hljs-comment"># 执行的sql文件路径</span><br>        <span class="hljs-comment">#statement_filepath =&gt; &quot;/usr/local/logstash-7.9.3/sync/foodie-items.sql&quot;</span><br>        <span class="hljs-string">statement</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;SELECT id,data,update_at,xxx,xxx FROM user&quot;</span><br>        <span class="hljs-comment"># 设置定时任务间隔  含义：分、时、天、月、年，全部为*默认含义为每分钟跑一次任务,配合statement中的语句可以做增量同步。</span><br>        <span class="hljs-comment">#schedule =&gt; &quot;* * * * *&quot;</span><br>        <span class="hljs-comment"># 是否开启记录上次追踪的结果，也就是上次更新的时间，这个会记录到 last_run_metadata_path 的文件</span><br>        <span class="hljs-string">use_column_value</span> <span class="hljs-string">=&gt;</span> <span class="hljs-literal">true</span><br>        <span class="hljs-comment"># 记录上一次追踪的结果值</span><br>        <span class="hljs-string">last_run_metadata_path</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;/home/elex/opt/logstash-7.9.3/mysql/track_time&quot;</span><br>        <span class="hljs-comment"># 如果 use_column_value 为true， 配置本参数，追踪的 column 名，可以是自增id或者时间</span><br>        <span class="hljs-string">tracking_column</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;update_at&quot;</span><br>        <span class="hljs-comment"># tracking_column 对应字段的类型</span><br>        <span class="hljs-string">tracking_column_type</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;numeric&quot;</span><br>        <span class="hljs-comment"># 是否清除 last_run_metadata_path 的记录，true则每次都从头开始查询所有的数据库记录</span><br>        <span class="hljs-string">clean_run</span> <span class="hljs-string">=&gt;</span> <span class="hljs-literal">false</span><br>        <span class="hljs-comment"># 数据库字段名称大写转小写</span><br>        <span class="hljs-string">lowercase_column_names</span> <span class="hljs-string">=&gt;</span> <span class="hljs-literal">false</span><br>    &#125;<br>&#125;<br><span class="hljs-string">filter</span> &#123;<br>    <br>  <span class="hljs-string">mutate</span> &#123;<br>       <span class="hljs-string">remove_field</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;@timestamp&quot;</span>]<br>  &#125;<br>    <span class="hljs-string">mutate</span> &#123;<br>       <span class="hljs-string">remove_field</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;@version&quot;</span>]<br>  &#125;<br>&#125;<br><br><br><span class="hljs-string">output</span> &#123;<br>    <span class="hljs-string">elasticsearch</span> &#123;<br>        <span class="hljs-string">hosts</span> <span class="hljs-string">=&gt;</span> [<span class="hljs-string">&quot;10.0.xx.xx:9200&quot;</span>]<br>        <span class="hljs-comment"># 索引名字，必须小写</span><br>        <span class="hljs-string">index</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;dimension-user&quot;</span><br>        <span class="hljs-string">document_id</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">%&#123;id&#125;</span>&quot;</span><br>        <span class="hljs-string">action</span> <span class="hljs-string">=&gt;</span> <span class="hljs-string">&quot;index&quot;</span><br><br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="执行迁移"><a href="#执行迁移" class="headerlink" title="执行迁移"></a>执行迁移</h2><p>执行过程中需要不要终止任务<br>也可放到后台运行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/logstash -f mysql/logstash-mysql-es.conf<br><span class="hljs-comment"># 或者</span><br><span class="hljs-built_in">nohup</span> ./bin/logstash -f mysql/logstash-mysql-es.conf &gt; log.out 2&gt;&amp;1 &amp; <br></code></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>在迁移过程中，发现利用logstash迁移时，读取数据库时是全表扫描，对mysql压力极大。这个是问题。</li><li>ES7版本和6版本有很多不同，需要注意配置的使用。</li></ol><p>1的解决方案： 可以通过手动程序，读取mysql数据，导入ES。<br>由于目前mysql数据量在百万，还能接受。所以就没有写程序。<br>如有遇到千万或上亿级数据时，最好不要使用logstash同步数据，或者测试通过在使用。</p>]]></content>
      
      
      <categories>
          
          <category> MySql </category>
          
          <category> Elasticsearch </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper_Kafka单节点模式升级为集群模式</title>
      <link href="/kafka/2021-07-01-Kafka_Zookeeper%E5%8D%95%E8%8A%82%E7%82%B9%E5%8D%87%E7%BA%A7%E4%B8%BA%E9%9B%86%E7%BE%A4/"/>
      <url>/kafka/2021-07-01-Kafka_Zookeeper%E5%8D%95%E8%8A%82%E7%82%B9%E5%8D%87%E7%BA%A7%E4%B8%BA%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>目前集群中zk,kafka为单节点模式（standlone），flume上传数据到kafka中，kafka依赖zk，flink相关任务消费kafka数据。<br>将zk和kafka升级为集群模式时，最好将flume停止和flink相关任务停止。<br>且最后升级完成后，需要对zk和kafka进行测试。<br>需要将kafka中的topic重新分配到不同broker中，然后再启动Flume，观察每个broker中的流量。<br>最后再启动Flink任务。观察消费流量。（升级过程中开启kafka的JMX端口进行流量查看）</p><h1 id="1-增加zk节点"><a href="#1-增加zk节点" class="headerlink" title="1. 增加zk节点"></a>1. 增加zk节点</h1><p><strong>1.1  将现有节点停止，编辑配置文件zoo.cfg，将其设为集群模式。</strong></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-string">dataDir=/home/elex/zookeeper/data</span><br><span class="hljs-string">dataLogDir=/home/elex/zookeeper/log</span><br><span class="hljs-comment"># the port at which the clients will connect</span><br><span class="hljs-string">clientPort=2181</span><br><span class="hljs-comment">#admin.serverPort=8888</span><br><span class="hljs-string">server.1=127.0.0.1:2287:3387</span><br><span class="hljs-string">server.2=127.0.0.1:2288:3388</span><br><span class="hljs-string">server.3=127.0.0.1:2289:3389</span><br><br><span class="hljs-comment">#线上时：------------------------------------------</span><br><br><span class="hljs-string">dataDir=/home/elex/zookeeper/data</span><br><span class="hljs-string">dataLogDir=/home/elex/zookeeper/log</span><br><span class="hljs-comment"># the port at which the clients will connect</span><br><span class="hljs-string">clientPort=2181</span><br><span class="hljs-string">server.1=ip1:2288:3388</span><br><span class="hljs-string">server.2=ip2:2288:3388</span><br><span class="hljs-string">server.3=ip3:2288:3388</span><br><br></code></pre></td></tr></table></figure><p><strong>1.2 添加新节点。配置 myid文件</strong><br>同步主节点zookeeper目录到其他节点。修改myid文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># dataDir,dataLogDir目录</span><br><span class="hljs-built_in">mkdir</span> -p /home/elex/zookeeper/data<br><span class="hljs-built_in">mkdir</span> -p /home/elex/zookeeper/log<br><span class="hljs-comment">#在节点1，2，3上分别执行 myid中值记得都不同，和server.x保持一致。</span><br><span class="hljs-built_in">echo</span> 1 &gt; /home/elex/zookeeper/data/myid<br></code></pre></td></tr></table></figure><p><strong>1.3 增加完新节后，启动集群，分别到每个节点启动</strong><br>后期考虑写脚本一件启停。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/zkServer.sh start conf/zoo.cfg<br><br>./bin/zkServer.sh status<br><br><span class="hljs-comment">#全部启动后，可以停止leader看，是否其他节点可以主动选举为新的leader</span><br>./bin/zkServer.sh stop<br></code></pre></td></tr></table></figure><h1 id="2-增加kafka节点"><a href="#2-增加kafka节点" class="headerlink" title="2.增加kafka节点"></a>2.增加kafka节点</h1><p>(以下配置为测试环境，单机模拟集群模式，线上环境需要换上真实ip和端口)<br><strong>2.1 修改现有kafka节点，将其设为集群模式（如果已经为集群模式，跳过）。</strong></p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-comment">#broker.id每个节点不一样，记得修改</span><br><span class="hljs-string">broker.id=0</span><br><span class="hljs-comment">#数据目录，记得改为真实的数据目录。</span><br><span class="hljs-string">log.dirs=/home/test1/kafkalog,/home/test2/kafkalog</span><br><span class="hljs-comment">#zk地址改成zk的集群地址</span><br><span class="hljs-string">zookeeper.connect=10.0.3.151:2181,10.0.3.151:2182,10.0.3.151:2183</span><br></code></pre></td></tr></table></figure><p><strong>2.2 增加新的kafka节点</strong> <strong>broker.id不能重复</strong><br>将kafka目录拷贝到其他节点，然后删除新加节点的dataDir和dataLogDir。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp kafka root@ip1:xxx<br><span class="hljs-built_in">cd</span> kafka <br><span class="hljs-built_in">rm</span> -rf data/*<br><span class="hljs-built_in">rm</span> -rf <span class="hljs-built_in">log</span>/*<br><span class="hljs-comment"># 修改 </span><br>vim conf/server.properties<br>broker.id=1<br>broker.id=2<br><span class="hljs-comment">#根据新节点的实际IP和目录修改</span><br>listeners=PLAINTEXT://10.0.3.151:9092<br>zookeeper.connect=10.0.3.151:2181,10.0.3.151:2182,10.0.3.151:2183<br>log.dirs=/home/test1/kafkalog,/home/test2/kafkalog<br></code></pre></td></tr></table></figure><p>增加完成后，启动每一个节点的kafka进程,并启用JMX监控</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">env</span> JMX_PORT=9999 bin/kafka-server-start.sh -daemon ./config/server.properties &amp;<br><span class="hljs-comment"># 或者 修改kafka-run-class.sh脚本，第一行增加JMX_PORT=9988开启监控。</span><br></code></pre></td></tr></table></figure><p><strong>2.3将现有的topic分配到不同的broker中。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">vim event-topic.json<br><span class="hljs-built_in">cat</span> &lt;&lt; <span class="hljs-string">EOF &gt; event-topic.json</span><br><span class="hljs-string">&#123;&quot;topics&quot;:  [&#123;&quot;topic&quot;: &quot;event&quot;&#125;],</span><br><span class="hljs-string">&quot;version&quot;:1</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">EOF</span><br><br></code></pre></td></tr></table></figure><p><strong>注意： 后期增加的topic不用指定，会自动分配到不同的broker中。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 查看当前topic分布</span><br>./bin/kafka-topics.sh --describe --zookeeper 10.0.3.151:2181 --topic event<br>Topic: event    PartitionCount: 3       ReplicationFactor: 1    Configs: <br>        Topic: event    Partition: 0    Leader: 0       Replicas: 0     Isr: 0<br>        Topic: event    Partition: 1    Leader: 1       Replicas: 0     Isr: 1<br>        Topic: event    Partition: 2    Leader: 2       Replicas: 0     Isr: 2<br><br><span class="hljs-comment"># 生成计划</span><br>./bin/kafka-reassign-partitions.sh --zookeeper 10.0.3.151:2181  --topics-to-move-json-file event-topic.json --broker-list <span class="hljs-string">&quot;0,1,2&quot;</span> --generate<br>Current partition replica assignment<br>&#123;<span class="hljs-string">&quot;version&quot;</span>:1,<span class="hljs-string">&quot;partitions&quot;</span>:[&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:2,<span class="hljs-string">&quot;replicas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:1,<span class="hljs-string">&quot;replicas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:0,<span class="hljs-string">&quot;replicas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;]&#125;<br><br>Proposed partition reassignment configuration<br><span class="hljs-comment">#将这部分信息 得到一个  event-move.json 文件用于执行计划</span><br>&#123;<span class="hljs-string">&quot;version&quot;</span>:1,<span class="hljs-string">&quot;partitions&quot;</span>:[&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:0,<span class="hljs-string">&quot;replicas&quot;</span>:[1],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:2,<span class="hljs-string">&quot;replicas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:1,<span class="hljs-string">&quot;replicas&quot;</span>:[2],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;]&#125;<br><br><span class="hljs-comment">#执行计划</span><br>./bin/kafka-reassign-partitions.sh --zookeeper 10.0.3.151:2181 --reassignment-json-file event-move.json --execute<br><br>Current partition replica assignment<br>                                                                                                <br>&#123;<span class="hljs-string">&quot;version&quot;</span>:1,<span class="hljs-string">&quot;partitions&quot;</span>:[&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:2,<span class="hljs-string">&quot;replicas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:1,<span class="hljs-string">&quot;replicas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;,&#123;<span class="hljs-string">&quot;topic&quot;</span>:<span class="hljs-string">&quot;event&quot;</span>,<span class="hljs-string">&quot;partition&quot;</span>:0,<span class="hljs-string">&quot;repl</span><br><span class="hljs-string">icas&quot;</span>:[0],<span class="hljs-string">&quot;log_dirs&quot;</span>:[<span class="hljs-string">&quot;any&quot;</span>]&#125;]&#125;   <br>                                                                                                <br>Save this to use as the --reassignment-json-file option during rollback<br>Successfully started reassignment of partitions.<br><br><span class="hljs-comment">#校验执行计划</span><br>./bin/kafka-reassign-partitions.sh --zookeeper 10.0.3.151:2181 --reassignment-json-file event-move.json  --verify<br>Status of partition reassignment: <br>Reassignment of partition event-2 completed successfully<br>Reassignment of partition event-1 completed successfully<br>Reassignment of partition event-0 completed successfully<br><br><span class="hljs-comment">#再次查看，分区分布在不同的broker上了</span><br>./bin/kafka-topics.sh --describe --zookeeper 10.0.3.151:2181 --topic event<br><br>Topic: event    PartitionCount: 3       ReplicationFactor: 1    Configs: <br>    Topic: event    Partition: 0    Leader: 0       Replicas: 0     Isr: 0<br>    Topic: event    Partition: 1    Leader: 1       Replicas: 1     Isr: 1<br>    Topic: event    Partition: 2    Leader: 2       Replicas: 2     Isr: 2<br><br></code></pre></td></tr></table></figure><ul><li>kafka迁移校验<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/kafka-reassign-partitions.sh --zookeeper 10.0.3.151:2181 --reassignment-json-file event-move.json  --verify<br><span class="hljs-comment">#输出</span><br>Status of partition reassignment: <br>Reassignment of partition event-2 completed successfully<br>Reassignment of partition event-1 completed successfully<br>Reassignment of partition event-0 completed successfully<br></code></pre></td></tr></table></figure><strong>注意： 在执行kafka迁移计划验证时，视topic数据量大小，可能需要很长时间。</strong><br>需要等待结果：Reassignment of xxx completed successfully均为Sucessfully才算完成，<br>如果有Progress的，需要等待。<br>上线环境时，数据量过大，topic数量也比较多，等待了大约2个小时。</li></ul><p><strong>2.4 增加topic分区</strong>（若后期数据量过大，效率低的情况再酌情增加分区）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/kafka-topics.sh --zookeeper zk01:2181,zk02:2181,zk03:2181 --alter --topic track_pc --partitions 3<br><span class="hljs-comment"># 或使用kafka-manager进行修改</span><br><br></code></pre></td></tr></table></figure><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><ol><li><p>项目经验之Kafka机器数量计算<br> Kafka机器数量（经验公式）&#x3D;2<em>（峰值生产速度</em>副本数&#x2F;100）+1</p><p> 峰值生产速度，再根据设定的副本数，就能预估出需要部署Kafka的数量。<br> 比如我们的峰值生产速度是50M&#x2F;s。副本数为2。<br> Kafka机器数量&#x3D;2<em>（50</em>2&#x2F;100）+ 1&#x3D;3台</p></li><li><p>项目经验值Kafka分区数计算<br> 创建一个只有1个分区的topic<br> 测试这个topic的producer吞吐量和consumer吞吐量。<br> 假设他们的值分别是Tp和Tc，单位可以是MB&#x2F;s。<br> 然后假设总的目标吞吐量是Tt，那么分区数&#x3D;Tt &#x2F; min（Tp，Tc）</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Kafka </category>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Checkpoint AWS S3中</title>
      <link href="/flink/2021-06-27-Flink-Checkpoint-AWS-S3/"/>
      <url>/flink/2021-06-27-Flink-Checkpoint-AWS-S3/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司目前flink集群采用standlone模式，目前一个jobmanager，一个taskmanager，checkpoint目前只在taskmanager本机文件系统中，后期考虑到数据量上涨，将扩展机器集群模式或flink on yarn。<br>需要将checkpoint 存储到分布式文件系统，由于集群在国外，选择了aws s3.<br>简单使用，已做备注。</p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><p>以下操作均在Flink客户端家目录下操作</p><h2 id="1-拷贝插件jar包到插件目录"><a href="#1-拷贝插件jar包到插件目录" class="headerlink" title="1.拷贝插件jar包到插件目录"></a>1.拷贝插件jar包到插件目录</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> plugins/s3-fs-presto/<br><span class="hljs-built_in">cp</span> opt/flink-s3-fs-presto-1.10.1.jar  plugins/s3-fs-presto/<br><span class="hljs-comment">#如果使用hadoop文件系统与s3交互,则使用flink-s3-fs-hadoop-1.10.1.jar包，对应 plugins目录s3-fs-hadoop</span><br></code></pre></td></tr></table></figure><h2 id="2-修改conf-x2F-flink-conf-ymal"><a href="#2-修改conf-x2F-flink-conf-ymal" class="headerlink" title="2.修改conf&#x2F;flink-conf.ymal"></a>2.修改conf&#x2F;flink-conf.ymal</h2><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">s3.access-key:</span> <span class="hljs-string">xxxxxxxx</span><br><span class="hljs-attr">s3.secret-key:</span> <span class="hljs-string">xxxxxx</span><br><span class="hljs-attr">s3.ssl.enabled:</span> <span class="hljs-literal">false</span><br><span class="hljs-attr">s3.path.style.access:</span> <span class="hljs-literal">true</span><br><span class="hljs-attr">s3.endpoint:</span> <span class="hljs-string">s3.us-xxx-1.amazonaws.com</span><br><br><span class="hljs-comment">#state.backend: filesystem</span><br><span class="hljs-attr">state.backend:</span> <span class="hljs-string">rocksdb</span><br><br><span class="hljs-comment"># Directory for checkpoints filesystem, when using any of the default bundled</span><br><span class="hljs-comment"># state backends.</span><br><span class="hljs-comment">#</span><br><span class="hljs-attr">state.checkpoints.dir:</span> <span class="hljs-string">s3://flink-rt/flink/checkpoints/</span><br><span class="hljs-comment">#state.checkpoints.dir: file:///home/ec2-user/flink/checkpointDir/flink-checkpoints</span><br><br><span class="hljs-comment"># Default target directory for savepoints, optional.</span><br><span class="hljs-comment">#</span><br><span class="hljs-attr">state.savepoints.dir:</span> <span class="hljs-string">s3://flink-rt/flink/savepoints/</span><br><span class="hljs-comment">#state.savepoints.dir: file:///home/ec2-user/flink/checkpointDir/flink-savepoints</span><br><span class="hljs-attr">state.backend.incremental:</span> <span class="hljs-literal">true</span><br><br></code></pre></td></tr></table></figure><p><a href="https://ci.apache.org/projects/flink/flink-docs-master/zh/docs/deployment/filesystems/s3/">Flink官网文档</a></p><h2 id="3-重启Flink集群"><a href="#3-重启Flink集群" class="headerlink" title="3.重启Flink集群"></a>3.重启Flink集群</h2><p><strong>注意：修改完配置记得同步配置到各个节点</strong></p><ul><li>如果是flink集群模式要重启集群</li><li>如果是flink on yarn(no session mode)重启任务即可。</li><li>如果是flink on yarn（yarn session mode）需要重启Flink-jobmanager集群任务</li></ul>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>记一次线上Flink-JVM-FullGC问题总结</title>
      <link href="/flink/2021-06-27-Flink-JVM-FullGC%E9%97%AE%E9%A2%98%E6%9F%A5%E6%89%BE%E5%92%8C%E6%80%BB%E7%BB%93/"/>
      <url>/flink/2021-06-27-Flink-JVM-FullGC%E9%97%AE%E9%A2%98%E6%9F%A5%E6%89%BE%E5%92%8C%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="背景和现象"><a href="#背景和现象" class="headerlink" title="背景和现象"></a>背景和现象</h1><p>目前公司线上数据量小，线上环境采用standlone模式部署的taskmanager，通过zabbix监控看到，taskmanager每5-10分钟有一次fullgc问题。<br>推测： </p><ol><li>代码问题，有对象使用后没有做进行关闭或回收</li><li>JVM参数配置问题</li></ol><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>先说结论，通过阅读项目代码，发现写入mysql和clickhouse的api代码存在问题， statement，connection再使用完毕后没有关闭，以及类似的问题。<br>因为插入数据库时使用的是批量插入，这部分存在很大问题。（备注：刚进入公司，代码非本人编写。） 这证明了推测1。</p><p>观察线上环境的jvm参数配置 ，发现jvm中新生代内存配置不合理。8G的堆内存，只有332M的新生代，不符合3&#x2F;8常规配比，证明了推测2.</p><p>JVM配置参考 <a href="https://www.huaweicloud.com/articles/b86de23d6c3d5a161b25b1013a388d8d.html">https://www.huaweicloud.com/articles/b86de23d6c3d5a161b25b1013a388d8d.html</a></p><h1 id="解决步骤"><a href="#解决步骤" class="headerlink" title="解决步骤"></a>解决步骤</h1><ol><li>代码部分：<br>只展示部分<br><strong>Connection和PreparedStatement</strong></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-type">Connection</span> <span class="hljs-variable">connection</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-keyword">try</span> &#123;<br>    connection = pool.getConnection();<br>    connection.setAutoCommit(<span class="hljs-literal">false</span>);<br>    <span class="hljs-type">PreparedStatement</span> <span class="hljs-variable">prest</span> <span class="hljs-operator">=</span> connection.prepareStatement(sql, ResultSet.TYPE_SCROLL_SENSITIVE, ResultSet.CONCUR_READ_ONLY);<br>    <span class="hljs-keyword">for</span>(Map.Entry&lt;String, Long&gt; entry : metrics.entrySet()) &#123;<br>        prest.setLong(<span class="hljs-number">1</span>, entry.getValue()/<span class="hljs-number">1000</span>);<br>        prest.setString(<span class="hljs-number">2</span>, entry.getKey());<br>        prest.setInt(<span class="hljs-number">3</span>, Integer.parseInt(productId));<br>        prest.addBatch();<br>    &#125;<br>    prest.executeBatch();<br>    connection.commit();<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>    connection.rollback();<br>    System.err.println(sql);<br>    System.err.println(e);<br>    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Exception</span>(e.getMessage());<br>&#125; <span class="hljs-keyword">finally</span> &#123;<br>    <span class="hljs-keyword">if</span> (connection != <span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            connection.close();<br>        &#125; <span class="hljs-keyword">catch</span> (SQLException throwables) &#123;<br>            throwables.printStackTrace();<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>修改后：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-type">Connection</span> <span class="hljs-variable">connection</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-type">PreparedStatement</span> <span class="hljs-variable">prest</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-keyword">try</span> &#123;<br>    connection = pool.getConnection();<br>    connection.setAutoCommit(<span class="hljs-literal">false</span>);<br>    prest = connection.prepareStatement(sql, ResultSet.TYPE_SCROLL_SENSITIVE, ResultSet.CONCUR_READ_ONLY);<br>    <span class="hljs-keyword">for</span> (Map.Entry&lt;String, Long&gt; entry : metrics.entrySet()) &#123;<br>        prest.setLong(<span class="hljs-number">1</span>, entry.getValue() / <span class="hljs-number">1000</span>);<br>        prest.setString(<span class="hljs-number">2</span>, entry.getKey().substring(<span class="hljs-number">3</span>));<br>        prest.setInt(<span class="hljs-number">3</span>, Integer.parseInt(productId));<br>        prest.addBatch();<br>    &#125;<br>    prest.executeBatch();<br>    connection.commit();<br>    prest.clearParameters();<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>    connection.rollback();<br>    System.err.println(sql);<br>    System.err.println(e);<br>    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Exception</span>(e.getMessage());<br>&#125; <span class="hljs-keyword">finally</span> &#123;<br>    <span class="hljs-keyword">if</span> (prest != <span class="hljs-literal">null</span> &amp;&amp; !prest.isClosed()) &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            prest.close();<br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span> (connection != <span class="hljs-literal">null</span> &amp;&amp; !connection.isClosed()) &#123;<br>        <span class="hljs-keyword">try</span> &#123;<br>            connection.close();<br>        &#125; <span class="hljs-keyword">catch</span> (SQLException throwables) &#123;<br>            throwables.printStackTrace();<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>StringBuilder部分</strong></p><p>阅读源码和网络文章</p><p>源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java">java.lang.StringBuilder<br><br><span class="hljs-comment">//404行</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> String <span class="hljs-title function_">toString</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-comment">// Create a copy, don&#x27;t share the array</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(value, <span class="hljs-number">0</span>, count);<br>&#125;<br><br></code></pre></td></tr></table></figure><p>当StringBuilder.toString()时，会创建一个新的String对象。<br>当你的String很长时，多次toString，对产生很多大对象，容易把新生代使用满，但是对象还未回收进入到老年代(特别是当前项目中，批量插入数据库中时，数据足够大，基本上千升值上万条批次插入clickhouse，且数据都放在String中)。<br>应该尽量避免tostring，在StringBuilder完成后toString一次，用一个对象去接受；不要多次toString（这部分的代码优化来源于jmap -heap pid | jmap -dump:format&#x3D;b,file&#x3D;xxx.hprof pid 统计得出。<br>）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br>jmap -dump:format=b,file=./06281330.hprof 10058<br><span class="hljs-comment">#将06281330.hprof 文件下载后 使用VirsualVM分析 hprof文件，发现有char[]中有很多StringBuilder中的字符串数据，本应该回收的，但是一直在jvm内存中。</span><br><span class="hljs-comment">#目前造成这种现象一个是因为多次引用StringBuilder中的内容时，都toString造成，还有另外一方面是因为新生代内存太小。</span><br><br></code></pre></td></tr></table></figure><p>使用参考 <a href="https://www.yiibai.com/java_data_type/java_stringbuilder_stringbuffer.html">https://www.yiibai.com/java_data_type&#x2F;java_stringbuilder_stringbuffer.html</a></p><p>代码部分优化后可以看到FullGC频率降低了。</p><ol start="2"><li>分析过程</li></ol><p>通过将线上环境的堆内存dump文件下载下来分析。（因本地环境的数据量小不是很容易复现）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">jmap -dump:format=b,file=xxx.hprof pid<br></code></pre></td></tr></table></figure><p>将上述中获取的xxx.hprof文件下载到本地。</p><p>使用VisualVM工具分析对象在堆内存中的占用情况，发现char[]中有大量的批量插入语句，占比达到了惊人的54.8%。<br>这其中的插入语句不应该有这么多存在。<br>这部分的主要原因应该是代码中StringBuilder多次toString和PreparedStatement未关闭造成；<br>还有部分原因是因为新生代内存太小，太大对象产生后直接进入到了老年代。<br>至此也证实代码中造成FullGC的一些问题。</p><ol start="3"><li>JVM参数部分：</li></ol><p>观察线上环境的jvm参数配置:</p><p>发现jvm中新生代内存配置不合理。8G的堆内存，只有332M的新生代，不符合3&#x2F;8常规配比</p><p>优化前参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs bash">jmap -heap pid<br>                                                                                                <br>Debugger attached successfully.                                                                  <br>Server compiler detected.                                                                        <br>JVM version is 25.251-b08                                                                        <br>                                                                                                 <br>using parallel threads <span class="hljs-keyword">in</span> the new generation.                                                    <br>using thread-local object allocation.                                                            <br>Concurrent Mark-Sweep GC                                                                         <br>                                                                                                 <br>Heap Configuration:                                                                              <br>   MinHeapFreeRatio         = 40                                                                 <br>   MaxHeapFreeRatio         = 70                                                                 <br>   MaxHeapSize              = 8455716864 (8064.0MB)                                              <br>   NewSize                  = 348913664 (332.75MB)                                               <br>   MaxNewSize               = 348913664 (332.75MB)                                               <br>   OldSize                  = 8106803200 (7731.25MB)                                                                                                                                               <br>   NewRatio                 = 2                                                                  <br>   SurvivorRatio            = 8                                                                  <br>   MetaspaceSize            = 536870912 (512.0MB)                                                <br>   CompressedClassSpaceSize = 536870912 (512.0MB)                                                <br>   MaxMetaspaceSize         = 1073741824 (1024.0MB)                                              <br>   G1HeapRegionSize         = 0 (0.0MB)                                                          <br><br>Heap Usage:                                                                                      <br>New Generation (Eden + 1 Survivor Space):                                                        <br>   capacity = 314048512 (299.5MB)                                                                <br>   used     = 139638808 (133.1699447631836MB)                                                    <br>   free     = 174409704 (166.3300552368164MB)                                                    <br>   44.46408840173075% used                                                                       <br>Eden Space:                                                                                      <br>   capacity = 279183360 (266.25MB)                                                               <br>   used     = 104773656 (99.9199447631836MB)                                                     <br>   free     = 174409704 (166.3300552368164MB)                                                    <br>   37.52861775143046% used                       <br>From Space:                                                                                      <br>   capacity = 34865152 (33.25MB)                                                                 <br>   used     = 34865152 (33.25MB)                                                                 <br>   free     = 0 (0.0MB)                                                                          <br>   100.0% used                                                                                   <br>To Space:                                                                                        <br>   capacity = 34865152 (33.25MB)                                                                 <br>   used     = 0 (0.0MB)                                                                          <br>   free     = 34865152 (33.25MB)                                                                 <br>   0.0% used                                                                                     <br>concurrent mark-sweep generation:                                                                <br>   capacity = 8106803200 (7731.25MB)                                                             <br>   used     = 5230841296 (4988.518997192383MB)                                                   <br>   free     = 2875961904 (2742.731002807617MB)                                                   <br>   64.52409373894756% used                                                                       <br><br>32186 interned Strings occupying 3597144 bytes.<br><br></code></pre></td></tr></table></figure><p>优化后JVM参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br>Heap Configuration:<br>   MinHeapFreeRatio         = 40<br>   MaxHeapFreeRatio         = 70<br>   MaxHeapSize              = 8455716864 (8064.0MB)<br>   NewSize                  = 2147483648 (2048.0MB)<br>   MaxNewSize               = 2147483648 (2048.0MB)<br>   OldSize                  = 6308233216 (6016.0MB)<br>   NewRatio                 = 2<br>   SurvivorRatio            = 8<br>   MetaspaceSize            = 536870912 (512.0MB)<br>   CompressedClassSpaceSize = 536870912 (512.0MB)<br>   MaxMetaspaceSize         = 1073741824 (1024.0MB)<br>   G1HeapRegionSize         = 0 (0.0MB)<br><br>Heap Usage:<br>New Generation (Eden + 1 Survivor Space):<br>   capacity = 1932787712 (1843.25MB)<br>   used     = 1211894112 (1155.7522888183594MB)<br>   free     = 720893600 (687.4977111816406MB)<br>   62.70187379999237% used<br>Eden Space:<br>   capacity = 1718091776 (1638.5MB)<br>   used     = 1165076592 (1111.1036224365234MB)<br>   free     = 553015184 (527.3963775634766MB)<br>   67.81224427442926% used<br>From Space:<br>   capacity = 214695936 (204.75MB)<br>   used     = 46817520 (44.64866638183594MB)<br>   free     = 167878416 (160.10133361816406MB)<br>   21.80643046731914% used<br>To Space:<br>   capacity = 214695936 (204.75MB)<br>   used     = 0 (0.0MB)<br>   free     = 214695936 (204.75MB)<br>   0.0% used<br>concurrent mark-sweep generation:<br>   capacity = 6308233216 (6016.0MB)<br>   used     = 1113470792 (1061.8884963989258MB)<br>   free     = 5194762424 (4954.111503601074MB)<br>   17.651072081099166% used<br><br></code></pre></td></tr></table></figure><p>优化的Flink-TaskManager启动参数<br>flink-conf.yml</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-comment">#  -Xmn2G 设置新生代为2G ，当启动Taskmanager后，没有启动任务时，发现Taskmanager的新生代已经使用了983M，占比53%，所以原来的300多M是很不合理的。也是造成FullGC的最主要原因.</span><br><span class="hljs-attr">env.java.opts.taskmanager:</span> <span class="hljs-string">-Djava.util.Arrays.useLegacyMergeSort=true</span> <span class="hljs-string">-XX:NativeMemoryTracking=detail</span> <span class="hljs-string">-Xmn2G</span>  <span class="hljs-string">-XX:+UseParNewGC</span> <span class="hljs-string">-XX:+UseConcMarkSweepGC</span> <span class="hljs-string">-XX:CMSInitiatingOccupancyFraction=70</span>  <span class="hljs-string">-XX:+UseCompressedClassPointers</span> <span class="hljs-string">-XX:CompressedClassSpaceSize=512M</span> <span class="hljs-string">-XX:MetaspaceSize=512m</span> <span class="hljs-string">-XX:MaxMetaspaceSize=1024m</span><br><br></code></pre></td></tr></table></figure><h1 id="JVM-tools"><a href="#JVM-tools" class="headerlink" title="JVM tools"></a>JVM tools</h1><p>查看实时的内存使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">jstat -gcutil pid 1000<br>更多用法 [https://www.cnblogs.com/czbcxy/p/10845193.html](https://www.cnblogs.com/czbcxy/p/10845193.html)<br></code></pre></td></tr></table></figure><p>查看JVM内存配置及使用情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">jmap -heap pid<br><span class="hljs-comment">#导出dump（hprof）文件</span><br>jmap -dump:format=b,file=xxx.hprof pid<br></code></pre></td></tr></table></figure><h1 id="JVM调优常用参数"><a href="#JVM调优常用参数" class="headerlink" title="JVM调优常用参数"></a>JVM调优常用参数</h1><p><strong>参数说明</strong> <strong><a href="https://www.huaweicloud.com/articles/b86de23d6c3d5a161b25b1013a388d8d.html">参考华为jvm调优文档</a></strong></p><figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs haml">参数名称含义默认值描述<br>-<span class="language-ruby">Xms初始堆大小物理内存的<span class="hljs-number">1</span>/<span class="hljs-number">64</span>(&lt;1gb)&lt;td&gt;默认(MinHeapFreeRatio参数可以调整)空余堆内存小于<span class="hljs-number">40</span>%时，<span class="hljs-variable constant_">JVM</span>就会增大堆直到-Xmx的最大限制.</span><br>-<span class="language-ruby">Xmx最大堆大小物理内存的<span class="hljs-number">1</span>/<span class="hljs-number">4</span>(&lt;1gb) &lt;td&gt;默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于<span class="hljs-number">70</span>%时，<span class="hljs-variable constant_">JVM</span>会减少堆直到 -Xms的最小限制</span><br>-<span class="language-ruby">Xmn年轻代大小(<span class="hljs-number">1</span>.4or lator) 注意：此处的大小是（eden+ <span class="hljs-number">2</span> survivor space).与jmap -heap中显示的New gen是不同的。</span><br>整个堆大小=年轻代大小 + 年老代大小 + 持久代大小.<br>增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8<br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:NewSize</span>设置年轻代大小(<span class="hljs-keyword">for</span> <span class="hljs-number">1.3</span>/<span class="hljs-number">1.4</span>)  </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:MaxNewSize</span>年轻代最大值(<span class="hljs-keyword">for</span> <span class="hljs-number">1.3</span>/<span class="hljs-number">1.4</span>)  </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:PermSize</span>设置持久代(perm gen)初始值物理内存的<span class="hljs-number">1</span>/<span class="hljs-number">64</span> </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:MaxPermSize</span>设置持久代最大值物理内存的<span class="hljs-number">1</span>/<span class="hljs-number">4</span> </span><br>-<span class="language-ruby">Xss每个线程的堆栈大小 <span class="hljs-variable constant_">JDK5</span>.<span class="hljs-number">0</span>以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.更具应用的线程所需内存大小进行 调整.在相同物理内存下,减小这个值能生成更多的线程.但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在<span class="hljs-number">3000</span>~<span class="hljs-number">5000</span>左右</span><br>一般小的应用， 如果栈不是很深， 应该是128k够用的 大的应用建议使用256k。这个选项对性能影响比较大，需要严格的测试。（校长）<br>和threadstacksize选项解释很类似,官方文档似乎没有解释,在论坛中有这样一句话:&quot;”<br>-<span class="language-ruby">Xss is translated <span class="hljs-keyword">in</span> a <span class="hljs-variable constant_">VM</span> flag named ThreadStackSize”</span><br>一般设置这个值就可以了。<br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:ThreadStackSize</span>Thread Stack Size (<span class="hljs-number">0</span> means use default stack size) [<span class="hljs-symbol">Sparc:</span> <span class="hljs-number">512</span>; Solaris <span class="hljs-symbol">x86:</span> <span class="hljs-number">320</span> (was <span class="hljs-number">256</span> prior <span class="hljs-keyword">in</span> <span class="hljs-number">5.0</span> <span class="hljs-keyword">and</span> earlier); Sparc <span class="hljs-number">64</span> <span class="hljs-symbol">bit:</span> <span class="hljs-number">1024</span>; Linux <span class="hljs-symbol">amd64:</span> <span class="hljs-number">1024</span> (was <span class="hljs-number">0</span> <span class="hljs-keyword">in</span> <span class="hljs-number">5.0</span> <span class="hljs-keyword">and</span> earlier); all others <span class="hljs-number">0</span>.]</span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:NewRatio</span>年轻代(包括Eden和两个Survivor区)与年老代的比值(除去持久代) -<span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:NewRatio=</span><span class="hljs-number">4</span>表示年轻代与年老代所占比值为<span class="hljs-number">1</span><span class="hljs-symbol">:</span><span class="hljs-number">4</span>,年轻代占整个堆栈的<span class="hljs-number">1</span>/<span class="hljs-number">5</span></span><br>Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。<br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:SurvivorRatio</span>Eden区与Survivor区的大小比值 设置为<span class="hljs-number">8</span>,则两个Survivor区与一个Eden区的比值为<span class="hljs-number">2</span><span class="hljs-symbol">:</span><span class="hljs-number">8</span>,一个Survivor区占整个年轻代的<span class="hljs-number">1</span>/<span class="hljs-number">10</span></span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:LargePageSizeInBytes</span>内存页的大小不可设置过大， 会影响Perm的大小 =128m</span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:+UseFastAccessorMethods</span>原始类型的快速优化  </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:+DisableExplicitGC</span>关闭System.gc() 这个参数需要严格的测试</span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:MaxTenuringThreshold</span>垃圾最大年龄 如果设置为<span class="hljs-number">0</span>的话,则年轻代对象不经过Survivor区,直接进入年老代. 对于年老代比较多的应用,可以提高效率.如果将此值设置为一个较大值,则年轻代对象会在Survivor区进行多次复制,这样可以增加对象再年轻代的存活 时间,增加在年轻代即被回收的概率</span><br>该参数只有在串行GC时才有效.<br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:+AggressiveOpts</span>加快编译  </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:+UseBiasedLocking</span>锁机制的性能改善  </span><br>-<span class="language-ruby">Xnoclassgc禁用垃圾回收  </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:SoftRefLRUPolicyMSPerMB</span>每兆堆空闲空间中SoftReference的存活时间1ssoftly reachable objects will remain alive <span class="hljs-keyword">for</span> some amount of time after the last time they were referenced. The default value is one second of lifetime per free megabyte <span class="hljs-keyword">in</span> the heap</span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:PretenureSizeThreshold</span>对象超过多大是直接在旧生代分配<span class="hljs-number">0</span>单位字节 新生代采用Parallel Scavenge <span class="hljs-variable constant_">GC</span>时无效</span><br>另一种直接在旧生代分配的情况是大的数组对象,且数组中无外部引用对象.<br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:TLABWasteTargetPercent</span><span class="hljs-variable constant_">TLAB</span>占eden区的百分比<span class="hljs-number">1</span>% </span><br>-<span class="language-ruby"><span class="hljs-variable constant_">XX</span><span class="hljs-symbol">:+CollectGen0First</span>FullGC时是否先<span class="hljs-variable constant_">YGC</span><span class="hljs-literal">false</span></span><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux中的一些不注意的小知识点,不定时更新</title>
      <link href="/linux/2021-01-01-linux%E4%B8%AD%E4%B8%80%E4%BA%9B%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9-%E4%B8%8D%E5%AE%9A%E6%97%B6%E6%9B%B4%E6%96%B0/"/>
      <url>/linux/2021-01-01-linux%E4%B8%AD%E4%B8%80%E4%BA%9B%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9-%E4%B8%8D%E5%AE%9A%E6%97%B6%E6%9B%B4%E6%96%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>不定时更新工作或学习中遇到的一些个人觉得不常用的一些Linux中一些问题和知识.</p><h2 id="Shell参数传递问题"><a href="#Shell参数传递问题" class="headerlink" title="Shell参数传递问题"></a>Shell参数传递问题</h2><p>当n&gt;&#x3D;10时，需要使用${n}来获取参数。<br><img src="https://i.loli.net/2021/12/02/hPeUv9y8EWOLYsf.png"></p><h2 id="Linux查看命令行查看网速工具"><a href="#Linux查看命令行查看网速工具" class="headerlink" title="Linux查看命令行查看网速工具"></a>Linux查看命令行查看网速工具</h2><p>nload,iftop</p><h2 id="tar打包压缩的一些问题"><a href="#tar打包压缩的一些问题" class="headerlink" title="tar打包压缩的一些问题"></a>tar打包压缩的一些问题</h2><ol><li>常用打包: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 将目标目录打包到压缩包中,包含了具体/home/test/data/路径</span><br>tar -zcvf /home/test/xxx.tar.gz /home/test/data/xxx<br><br><span class="hljs-comment"># 解压</span><br>tar -zxvf /home/test/xxx.tar.gz -C /home/test/untar/<br><br><span class="hljs-comment"># 解压完成后发现/home/test/untar/目录中 还有/home/test/data/ 更多目录</span><br><br></code></pre></td></tr></table></figure></li><li>只打包目录,不包含具体的路径<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># package and compress</span><br><span class="hljs-comment"># -c package -z compress to gzip</span><br>tar -zcvf /home/test/yyy.tar.gz -C /home/test/data/xxx .<br><br><span class="hljs-comment"># unrar</span><br>tar -zxvf /home/test/yyy.tar.gz -C /home/test/unrar/<br><br><span class="hljs-comment"># 解压完后,unrar 目录中只有会 xxx一个目录,而不会包含了/home/test/data 路径 </span><br></code></pre></td></tr></table></figure><em><strong>注意: 压缩命令时指定-C 和最后面的 “.”</strong></em></li></ol><h2 id="手动清理linux-内存缓存-buffer-x2F-cache"><a href="#手动清理linux-内存缓存-buffer-x2F-cache" class="headerlink" title="手动清理linux 内存缓存 buffer&#x2F;cache"></a>手动清理linux 内存缓存 buffer&#x2F;cache</h2><p>相关数值(0,1,2,3)说明:<br><a href="https://www.linuxidc.com/Linux/2010-03/24939.htm">https://www.linuxidc.com/Linux/2010-03/24939.htm</a><br><a href="https://colobu.com/2015/10/31/How-to-Clear-RAM-Memory-Cache-Buffer-and-Swap-Space-on-Linux/">https://colobu.com/2015/10/31/How-to-Clear-RAM-Memory-Cache-Buffer-and-Swap-Space-on-Linux/</a></p><ul><li><p>方法1: 修改 &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;drop_caches</p><p>  drop_caches默认值为: 0<br>  可直接修改,但是不建议此操作.因想再改回来不能在未停机的修改,只能重启机器.还有就是有些软件依赖cache,如果清理到导致服务报错或失败,一般不建议这样清理.<br>  <strong>不建议这样使用</strong></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/vm/drop_caches<br></code></pre></td></tr></table></figure></li><li><p>方法2: 通过软件的方式</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">apt install procps<br>sysctl -w vm.drop_caches=3<br></code></pre></td></tr></table></figure></li></ul><p>相关文档: <a href="https://stackoverflow.com/questions/65629513/reset-proc-sys-vm-drop-caches-to-default-value-0">https://stackoverflow.com/questions/65629513/reset-proc-sys-vm-drop-caches-to-default-value-0</a></p><h2 id="Flatpak应用中鼠数主题不起作用设置"><a href="#Flatpak应用中鼠数主题不起作用设置" class="headerlink" title="Flatpak应用中鼠数主题不起作用设置"></a>Flatpak应用中鼠数主题不起作用设置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">flatpak --user override --filesystem=/home/$USER/.icons/:ro<br>flatpak --user override --filesystem=/usr/share/icons/:ro<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Shell </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Streaming Write Hive Table</title>
      <link href="/flink/2020-12-01-FlinkStreamingWriteHiveTable/"/>
      <url>/flink/2020-12-01-FlinkStreamingWriteHiveTable/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink-Streaming写入Hive表"><a href="#Flink-Streaming写入Hive表" class="headerlink" title="Flink Streaming写入Hive表"></a>Flink Streaming写入Hive表</h1><ul><li><p>需求背景:</p><p> 因公司大数据后台升级,将kafka中日志流数据,实时解析,<br> 写入指定hive table不同分区中,以此,往实时数仓方向转.<br> (在写入hdfs基础上更一步,因为写入hdfs-dwd层需要手动去增加分区,直接写入hive中更直接)</p></li><li><p>相关软件版本:</p>  <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">Flink:1.11.1<br>Java: 1.8<br>Scala: 2.12<br>Kafka:2.2.0<br>Hive: 2.1.1<br>Hadoop: 3.0.0<br></code></pre></td></tr></table></figure></li></ul><h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><ul><li><p>主类</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.dz.bigdata.writer.hive;<br><br><span class="hljs-keyword">import</span> java.time.Instant;<br><span class="hljs-keyword">import</span> java.time.LocalDateTime;<br><span class="hljs-keyword">import</span> java.time.ZoneId;<br><span class="hljs-keyword">import</span> java.time.ZoneOffset;<br><span class="hljs-keyword">import</span> java.time.format.DateTimeFormatter;<br><span class="hljs-keyword">import</span> java.util.Objects;<br><span class="hljs-keyword">import</span> java.util.Optional;<br><span class="hljs-keyword">import</span> java.util.Properties;<br><br><span class="hljs-keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.typeutils.RowTypeInfo;<br><span class="hljs-keyword">import</span> org.apache.flink.configuration.CoreOptions;<br><span class="hljs-keyword">import</span> org.apache.flink.connectors.hive.HiveOptions;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.DataTypes;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.SqlDialect;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.Table;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.TableResult;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.TableSchema;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.bridge.java.StreamTableEnvironment;<br><span class="hljs-keyword">import</span> org.apache.flink.table.catalog.DataTypeFactory;<br><span class="hljs-keyword">import</span> org.apache.flink.table.catalog.hive.HiveCatalog;<br><span class="hljs-keyword">import</span> org.apache.flink.table.functions.FunctionKind;<br><span class="hljs-keyword">import</span> org.apache.flink.table.functions.ScalarFunction;<br><span class="hljs-keyword">import</span> org.apache.flink.table.functions.TableFunction;<br><span class="hljs-keyword">import</span> org.apache.flink.table.functions.UserDefinedFunction;<br><span class="hljs-keyword">import</span> org.apache.flink.table.types.DataType;<br><span class="hljs-keyword">import</span> org.apache.flink.table.types.inference.TypeInference;<br><span class="hljs-keyword">import</span> org.apache.flink.types.Row;<br><span class="hljs-keyword">import</span> org.slf4j.Logger;<br><span class="hljs-keyword">import</span> org.slf4j.LoggerFactory;<br><br><span class="hljs-keyword">import</span> com.alibaba.fastjson.JSON;<br><span class="hljs-keyword">import</span> com.alibaba.fastjson.JSONObject;<br><span class="hljs-keyword">import</span> com.dz.bigdata.common.Constants;<br><span class="hljs-keyword">import</span> com.dz.bigdata.config.Config;<br><span class="hljs-keyword">import</span> com.dz.bigdata.pojo.ServerStandardLog;<br><span class="hljs-keyword">import</span> com.dz.bigdata.utils.ObjectUtils;<br><span class="hljs-keyword">import</span> com.dz.bigdata.writer.BaseEnv;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ServerLogHiveWriter</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">BaseEnv</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">LOG</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(ServerLogHiveWriter.class);<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-variable">maxParallelism</span> <span class="hljs-operator">=</span> <span class="hljs-number">6</span>;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>        Config.initArgs(args);<br><br>        <span class="hljs-type">String</span> <span class="hljs-variable">topic</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;topic&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">groupId</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;groupId&quot;</span>);<br>        <span class="hljs-type">String</span> <span class="hljs-variable">checkpointInterval</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;checkpointInterval&quot;</span>);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">checkTime</span> <span class="hljs-operator">=</span> Integer.parseInt(checkpointInterval);<br><br>        <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> getStreamEnv(checkTime, <span class="hljs-string">&quot;/flink/checkpoints/flink_hive_writer_&quot;</span> + topic);<br><br>        <span class="hljs-type">Properties</span> <span class="hljs-variable">props</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>        props.setProperty(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, Config.getPropValue(Constants.KAFKA_SERVER));<br>        props.setProperty(<span class="hljs-string">&quot;group.id&quot;</span>, groupId);<br>        env.setParallelism(maxParallelism);<br><br>        DataStreamSource&lt;String&gt; source =<br>                env.addSource(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FlinkKafkaConsumer</span>&lt;&gt;(topic, <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleStringSchema</span>(), props));<br><br>        <span class="hljs-type">RowTypeInfo</span> <span class="hljs-variable">typeInfo</span> <span class="hljs-operator">=</span> ObjectUtils.getTypeInfo(ServerStandardLog.class);<br><br>        SingleOutputStreamOperator&lt;Row&gt; rowLog = source.map(line -&gt; &#123;<br>            <span class="hljs-keyword">try</span> &#123;<br>                <span class="hljs-type">JSONObject</span> <span class="hljs-variable">jsonObject</span> <span class="hljs-operator">=</span> JSON.parseObject(line);<br>                <span class="hljs-keyword">if</span> (jsonObject.get(<span class="hljs-string">&quot;data&quot;</span>) != <span class="hljs-literal">null</span>) &#123;<br>                    jsonObject.put(<span class="hljs-string">&quot;data&quot;</span>, jsonObject.getJSONObject(<span class="hljs-string">&quot;data&quot;</span>));<br>                &#125;<br>                <span class="hljs-type">ServerStandardLog</span> <span class="hljs-variable">serverStandardLog</span> <span class="hljs-operator">=</span><br>                        JSON.parseObject(jsonObject.toJSONString(), ServerStandardLog.class);<br>                <span class="hljs-keyword">if</span> (serverStandardLog != <span class="hljs-literal">null</span>) &#123;<br>                    Object[] values = ObjectUtils.getFieldValues(serverStandardLog);<br>                    <span class="hljs-keyword">return</span> Row.of(values);<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>                &#125;<br><br>            &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>                LOG.error(<span class="hljs-string">&quot;get log msg exception  &quot;</span>, e);<br>                e.printStackTrace();<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>            &#125;<br>        &#125;).filter(Objects::nonNull).map(e -&gt; e, typeInfo);<br><br>        <span class="hljs-type">EnvironmentSettings</span> <span class="hljs-variable">settings</span> <span class="hljs-operator">=</span> EnvironmentSettings.newInstance().inStreamingMode().build();<br>        <span class="hljs-type">StreamTableEnvironment</span> <span class="hljs-variable">tbEnv</span> <span class="hljs-operator">=</span> StreamTableEnvironment.create(env, settings);<br>        tbEnv.getConfig().getConfiguration().set(CoreOptions.DEFAULT_PARALLELISM, maxParallelism);<br>        tbEnv.getConfig().getConfiguration().set(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM, <span class="hljs-literal">true</span>);<br>        tbEnv.getConfig().getConfiguration()<br>                .set(HiveOptions.TABLE_EXEC_HIVE_INFER_SOURCE_PARALLELISM_MAX, maxParallelism);<br>        <span class="hljs-keyword">if</span> (<span class="hljs-string">&quot;dev&quot;</span>.equals(Config.getProfile())) &#123;<br>            <span class="hljs-type">Table</span> <span class="hljs-variable">cslTable</span> <span class="hljs-operator">=</span> tbEnv.fromDataStream(rowLog);<br>            <span class="hljs-type">TableSchema</span> <span class="hljs-variable">schema</span> <span class="hljs-operator">=</span> cslTable.getSchema();<br>            Optional&lt;DataType&gt; data = schema.getFieldDataType(<span class="hljs-string">&quot;data&quot;</span>);<br>            tbEnv.createTemporaryView(<span class="hljs-string">&quot;TmpLog&quot;</span>, rowLog);<br>            <span class="hljs-type">Table</span> <span class="hljs-variable">table</span> <span class="hljs-operator">=</span> tbEnv.sqlQuery(<span class="hljs-string">&quot;SELECT data as dataMap FROM TmpLog&quot;</span>);<br>            <span class="hljs-type">TableResult</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> table.execute();<br>            result.print();<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br><br>            <span class="hljs-type">String</span> <span class="hljs-variable">tbName</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;dwd.dwd_hkx_hkx_server_standard_log_direct&quot;</span>;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">defaultDatabase</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;dwd&quot;</span>;<br>            <span class="hljs-type">String</span> <span class="hljs-variable">hiveConfDir</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;/etc/hive/conf&quot;</span>; <span class="hljs-comment">// a local path</span><br>            <span class="hljs-type">String</span> <span class="hljs-variable">caName</span> <span class="hljs-operator">=</span> defaultDatabase;<br><br>            <span class="hljs-type">HiveCatalog</span> <span class="hljs-variable">hive</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">HiveCatalog</span>(caName, defaultDatabase, hiveConfDir);<br>            tbEnv.registerCatalog(caName, hive);<br><br>            tbEnv.useCatalog(caName);<br>            tbEnv.getConfig().setSqlDialect(SqlDialect.HIVE);<br><br>            tbEnv.createTemporaryFunction(<span class="hljs-string">&quot;DTFormat&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">DtFormatUDF</span>());<br>            tbEnv.createTemporaryView(<span class="hljs-string">&quot;TmpLog&quot;</span>, rowLog);<br><br>            tbEnv.useDatabase(defaultDatabase);<br><br>            <span class="hljs-type">String</span> <span class="hljs-variable">insertSql</span> <span class="hljs-operator">=</span><br>                    <span class="hljs-string">&quot;INSERT INTO &quot;</span> + tbName + <span class="hljs-string">&quot; SELECT logId as  log_id,bline,pline,reqTime as req_time,ip,country,&quot;</span><br>                            + <span class="hljs-string">&quot;province,city,uid,ua,imei,imsi,idfa,idfv,key,subKey as sub_key,data,&quot;</span><br>                            + <span class="hljs-string">&quot; DTFormat(reqTime,&#x27;0yyyyMMddHH&#x27;) as dt &quot;</span> + <span class="hljs-string">&quot; FROM TmpLog&quot;</span>;<br><br>            tbEnv.executeSql(insertSql);<br>        &#125;<br><br>    &#125;<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseEnv</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> StreamExecutionEnvironment <span class="hljs-title function_">getStreamEnv</span><span class="hljs-params">(<span class="hljs-type">int</span> checkpointTime, String checkpointPath)</span> &#123;<br>        <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.enableCheckpointing(checkpointTime * <span class="hljs-number">60</span> * <span class="hljs-number">1000</span>, CheckpointingMode.EXACTLY_ONCE);<br>        env.getCheckpointConfig().setMaxConcurrentCheckpoints(<span class="hljs-number">1</span>);<br>        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(<span class="hljs-number">500</span>);<br>        env.getCheckpointConfig().setCheckpointTimeout(checkpointTime * <span class="hljs-number">2</span> * <span class="hljs-number">60</span> * <span class="hljs-number">1000</span>);<br><br>        <span class="hljs-keyword">if</span> (!<span class="hljs-string">&quot;dev&quot;</span>.equals(Config.getProfile())) &#123;<br>            <span class="hljs-type">FsStateBackend</span> <span class="hljs-variable">fsStateBackend</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">FsStateBackend</span>(<span class="hljs-string">&quot;hdfs://&quot;</span> + checkpointPath);<br>            <span class="hljs-type">StateBackend</span> <span class="hljs-variable">rocksDBBackend</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RocksDBStateBackend</span>(fsStateBackend, TernaryBoolean.TRUE);<br>            env.setStateBackend(rocksDBBackend);<br>            env.setRestartStrategy(RestartStrategies.fixedDelayRestart(<span class="hljs-number">2</span>, Time.minutes(<span class="hljs-number">3</span>)));<br><span class="hljs-comment">//            env.setRestartStrategy(RestartStrategies.noRestart());</span><br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-type">StateBackend</span> <span class="hljs-variable">fsStateBackend</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">FsStateBackend</span>(<span class="hljs-string">&quot;file://&quot;</span> + checkpointPath);<br>            env.setStateBackend(fsStateBackend);<br>            env.setRestartStrategy(RestartStrategies.noRestart());<br>        &#125;<br><br>        env.getCheckpointConfig()<br>                .enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);<br><br>        <span class="hljs-keyword">return</span> env;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure></li><li><p>DtFormatUDF,ObjectUtils类</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.dz.bigdata.writer.hive;<br><br><span class="hljs-keyword">import</span> java.time.Instant;<br><span class="hljs-keyword">import</span> java.time.LocalDateTime;<br><span class="hljs-keyword">import</span> java.time.ZoneOffset;<br><span class="hljs-keyword">import</span> java.time.format.DateTimeFormatter;<br><br><span class="hljs-keyword">import</span> org.apache.flink.table.functions.ScalarFunction;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DtFormatUDF</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">ScalarFunction</span> &#123;<br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">eval</span><span class="hljs-params">(Long time, String format)</span> &#123;<br>        <span class="hljs-keyword">return</span> LocalDateTime.ofInstant(Instant.ofEpochMilli(time), ZoneOffset.ofHours(<span class="hljs-number">8</span>))<br>                       .format(DateTimeFormatter.ofPattern(format));<br>    &#125;<br>&#125;<br><span class="hljs-keyword">package</span> com.dz.bigdata.utils;<br><br><span class="hljs-keyword">import</span> java.lang.reflect.Field;<br><span class="hljs-keyword">import</span> java.lang.reflect.Method;<br><span class="hljs-keyword">import</span> java.lang.reflect.Modifier;<br><span class="hljs-keyword">import</span> java.util.Arrays;<br><span class="hljs-keyword">import</span> java.util.List;<br><span class="hljs-keyword">import</span> java.util.Map;<br><span class="hljs-keyword">import</span> java.util.stream.Collectors;<br><br><span class="hljs-keyword">import</span> org.apache.commons.lang3.StringUtils;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.typeinfo.TypeInformation;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.typeinfo.Types;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.typeutils.RowTypeInfo;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ObjectUtils</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> RowTypeInfo <span class="hljs-title function_">getTypeInfo</span><span class="hljs-params">(Class&lt;?&gt; cls)</span>&#123;<br><br>        List&lt;Field&gt; declaredFields = Arrays.stream(cls.getDeclaredFields()).filter(e -&gt; !Modifier.isStatic(e.getModifiers()))<br>                                      .collect(Collectors.toList());<br>        <span class="hljs-type">int</span> <span class="hljs-variable">fieldLength</span> <span class="hljs-operator">=</span> declaredFields.size();<br>        String[] fieldNames = <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>[fieldLength];<br>        TypeInformation[] typeInformation = <span class="hljs-keyword">new</span> <span class="hljs-title class_">TypeInformation</span>[fieldLength];<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; declaredFields.size(); i++) &#123;<br>            <span class="hljs-type">Field</span> <span class="hljs-variable">field</span> <span class="hljs-operator">=</span> declaredFields.get(i);<br>            fieldNames[i] =  field.getName();<br>            Class&lt;?&gt; type = field.getType();<br>            <span class="hljs-keyword">if</span>(type == Long.class)&#123;<br>                typeInformation[i] = Types.LONG;<br>            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(type == Map.class)&#123;<br>                typeInformation[i] = Types.MAP(Types.STRING,Types.STRING);<br>            &#125;<span class="hljs-keyword">else</span> &#123;<br>                typeInformation[i] = Types.STRING;<br>            &#125;<br>        &#125;<br>        <span class="hljs-type">RowTypeInfo</span> <span class="hljs-variable">outputType</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RowTypeInfo</span>(typeInformation,fieldNames);<br>        <span class="hljs-keyword">return</span> outputType;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Object[] getFieldValues(Object obj)&#123;<br>        Class&lt;?&gt; csClass = obj.getClass();<br>         List&lt;Field&gt; declaredFields =<br>                 Arrays.stream(csClass.getDeclaredFields()).filter(e -&gt; !Modifier.isStatic(e.getModifiers()))<br>                                                                     .collect(Collectors.toList());<br>        Object[] values = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>[declaredFields.size()];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">index</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">try</span>&#123;<br>            <span class="hljs-keyword">for</span> (Field field : declaredFields) &#123;<br>                <span class="hljs-keyword">if</span>(Modifier.isStatic(field.getModifiers()))&#123;<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br>                <span class="hljs-type">String</span> <span class="hljs-variable">fieldName</span> <span class="hljs-operator">=</span> field.getName();<br>                <span class="hljs-type">Method</span> <span class="hljs-variable">method</span> <span class="hljs-operator">=</span> csClass.getMethod(<span class="hljs-string">&quot;get&quot;</span> + StringUtils.upperCase(fieldName.substring(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)) + fieldName.substring(<span class="hljs-number">1</span>));<br>                <span class="hljs-type">Object</span> <span class="hljs-variable">value</span> <span class="hljs-operator">=</span> method.invoke(obj);<br>                values[index]=value;<br>                index++;<br>            &#125;<br>        &#125;<span class="hljs-keyword">catch</span> (Exception e)&#123;<br>            e.printStackTrace();<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> values;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure></li></ul><h1 id="总结和问题"><a href="#总结和问题" class="headerlink" title="总结和问题."></a>总结和问题.</h1><ul><li><p>写入hive时并行度为1,不能设置,导致写入速度很慢,公司部分日志数据量过大,导致消息积压不能消费完成<br> (1.11.x版本存在这个问题,据论坛显示,1.12后续版本将解决此问题),所以目前还是使用写入hdfs-dwd层的方式运行中</p></li><li><p>因为flink转为临时表是map类型字段转换的不是对应hive Map,是Any,导致一开始写入失败,解决方案:手动指定临时表各个字段数据类型.ObjectUtils类做此操作</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink Streaming Write HDFS(parquet)</title>
      <link href="/flink/2020-11-01-FlinkStreamingWriteHdfs/"/>
      <url>/flink/2020-11-01-FlinkStreamingWriteHdfs/</url>
      
        <content type="html"><![CDATA[<h1 id="Flink-Streaming写入hdfs"><a href="#Flink-Streaming写入hdfs" class="headerlink" title="Flink Streaming写入hdfs"></a>Flink Streaming写入hdfs</h1><ul><li><p>需求背景:</p><p> 因公司大数据后台升级,将kafka中日志流数据,实时解析,<br> 写入指定hdfs中(parquet格式,snapy压缩),以此,往实时数仓方向转.</p></li><li><p>相关软件版本:</p>  <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">Flink:1.11.1<br>Java: 1.8<br>Scala: 2.12<br>Kafka:2.2.0<br>Hive: 2.1.1<br>Hadoop: 3.0.0<br></code></pre></td></tr></table></figure></li></ul><h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><ul><li><p>主类</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><code class="hljs java"> <br><span class="hljs-keyword">package</span> com.dz.bigdata.writer.hdfs;<br>        <br>    <span class="hljs-keyword">import</span> java.util.Objects;<br>    <span class="hljs-keyword">import</span> java.util.Properties;<br>    <br>    <span class="hljs-keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;<br>    <span class="hljs-keyword">import</span> org.apache.flink.core.fs.Path;<br>    <span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;<br>    <span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;<br>    <span class="hljs-keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;<br>    <span class="hljs-keyword">import</span> org.apache.flink.streaming.api.functions.sink.filesystem.OutputFileConfig;<br>    <span class="hljs-keyword">import</span> org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink;<br>    <span class="hljs-keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;<br>    <span class="hljs-keyword">import</span> org.apache.parquet.hadoop.metadata.CompressionCodecName;<br>    <span class="hljs-keyword">import</span> org.slf4j.Logger;<br>    <span class="hljs-keyword">import</span> org.slf4j.LoggerFactory;<br>    <br>    <span class="hljs-keyword">import</span> com.alibaba.fastjson.JSON;<br>    <span class="hljs-keyword">import</span> com.alibaba.fastjson.JSONObject;<br>    <span class="hljs-keyword">import</span> com.dz.bigdata.assinger.CommonEventTimeBucketAssigner;<br>    <span class="hljs-keyword">import</span> com.dz.bigdata.common.Constants;<br>    <span class="hljs-keyword">import</span> com.dz.bigdata.config.Config;<br>    <span class="hljs-keyword">import</span> com.dz.bigdata.format.ParquetAvroWriters;<br>    <span class="hljs-keyword">import</span> com.dz.bigdata.pojo.ServerStandardLog;<br>    <span class="hljs-keyword">import</span> com.dz.bigdata.writer.BaseEnv;<br>    <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ServerLogHdfsWriter</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">BaseEnv</span> &#123;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-type">Logger</span> <span class="hljs-variable">LOG</span> <span class="hljs-operator">=</span> LoggerFactory.getLogger(ServerLogHdfsWriter.class);<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-variable">maxParallelism</span> <span class="hljs-operator">=</span> <span class="hljs-number">6</span>;<br>    <br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            Config.initArgs(args);<br>    <br>            <span class="hljs-type">String</span> <span class="hljs-variable">topic</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;topic&quot;</span>);<br>            <span class="hljs-type">String</span> <span class="hljs-variable">groupId</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;groupId&quot;</span>);<br>            <span class="hljs-type">String</span> <span class="hljs-variable">checkpointInterval</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;checkpointInterval&quot;</span>);<br>            <span class="hljs-type">String</span> <span class="hljs-variable">location</span> <span class="hljs-operator">=</span> Config.getArgsRequiredValue(<span class="hljs-string">&quot;path&quot;</span>);<br>            <span class="hljs-type">int</span> <span class="hljs-variable">checkTime</span> <span class="hljs-operator">=</span> Integer.parseInt(checkpointInterval);<br>    <br>            <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> getStreamEnv(checkTime, <span class="hljs-string">&quot;/flink/checkpoints/flink_hdfs_writer_&quot;</span> + topic);<br>    <br>            <span class="hljs-type">Properties</span> <span class="hljs-variable">props</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Properties</span>();<br>            props.setProperty(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, Config.getPropValue(Constants.KAFKA_SERVER));<br>            props.setProperty(<span class="hljs-string">&quot;group.id&quot;</span>, groupId);<br>            env.setParallelism(maxParallelism);<br>    <br>            DataStreamSource&lt;String&gt; source =<br>                    env.addSource(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FlinkKafkaConsumer</span>&lt;&gt;(topic, <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleStringSchema</span>(), props));<br>    <br>            SingleOutputStreamOperator&lt;ServerStandardLog&gt; rowLog = source.map(line -&gt; &#123;<br>                <span class="hljs-keyword">try</span> &#123;<br>                    <span class="hljs-type">JSONObject</span> <span class="hljs-variable">jsonObject</span> <span class="hljs-operator">=</span> JSON.parseObject(line);<br>                    <span class="hljs-keyword">if</span> (jsonObject.get(<span class="hljs-string">&quot;data&quot;</span>) != <span class="hljs-literal">null</span>) &#123;<br>                        jsonObject.put(<span class="hljs-string">&quot;data&quot;</span>, jsonObject.getJSONObject(<span class="hljs-string">&quot;data&quot;</span>));<br>                    &#125;<br>                    <span class="hljs-type">ServerStandardLog</span> <span class="hljs-variable">serverStandardLog</span> <span class="hljs-operator">=</span><br>                            JSON.parseObject(jsonObject.toJSONString(), ServerStandardLog.class);<br>                    <span class="hljs-keyword">return</span> serverStandardLog;<br>    <br>                &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>                    LOG.error(<span class="hljs-string">&quot;get log msg exception  &quot;</span>, e);<br>                    e.printStackTrace();<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>                &#125;<br>            &#125;).filter(Objects::nonNull);<br>            <span class="hljs-type">OutputFileConfig</span> <span class="hljs-variable">config</span> <span class="hljs-operator">=</span><br>                    OutputFileConfig.builder().withPartSuffix(<span class="hljs-string">&quot;.&quot;</span> + topic.trim() + <span class="hljs-string">&quot;.snappy.parquet&quot;</span>).build();<br>    <br>            StreamingFileSink&lt;ServerStandardLog&gt; sink = StreamingFileSink<br>                                                         .forBulkFormat(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(<span class="hljs-string">&quot;hdfs://&quot;</span> + location),<br>                                                                 ParquetAvroWriters.forReflectRecord(ServerStandardLog.class,<br>                                                                         CompressionCodecName.SNAPPY))<br>                                                         .withBucketAssigner(<span class="hljs-keyword">new</span> <span class="hljs-title class_">CommonEventTimeBucketAssigner</span>&lt;&gt;(<span class="hljs-string">&quot;dt=0%s%s&quot;</span>,<br>                                                                 e-&gt; e.getReqTime()))<br>                                                         .withOutputFileConfig(config).build();<br>    <br>            <span class="hljs-keyword">if</span>(!<span class="hljs-string">&quot;dev&quot;</span>.equals(Config.getProfile()))&#123;<br>                rowLog.addSink(sink);<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                rowLog.print();<br>            &#125;<br>    <br>            env.execute(<span class="hljs-string">&quot;server_log_to_hdfs_dwd_&quot;</span>+topic);<br>        &#125;<br>    &#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseEnv</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> StreamExecutionEnvironment <span class="hljs-title function_">getStreamEnv</span><span class="hljs-params">(<span class="hljs-type">int</span> checkpointTime, String checkpointPath)</span> &#123;<br>        <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<br>        env.enableCheckpointing(checkpointTime * <span class="hljs-number">60</span> * <span class="hljs-number">1000</span>, CheckpointingMode.EXACTLY_ONCE);<br>        env.getCheckpointConfig().setMaxConcurrentCheckpoints(<span class="hljs-number">1</span>);<br>        env.getCheckpointConfig().setMinPauseBetweenCheckpoints(<span class="hljs-number">500</span>);<br>        env.getCheckpointConfig().setCheckpointTimeout(checkpointTime * <span class="hljs-number">2</span> * <span class="hljs-number">60</span> * <span class="hljs-number">1000</span>);<br><br>        <span class="hljs-keyword">if</span> (!<span class="hljs-string">&quot;dev&quot;</span>.equals(Config.getProfile())) &#123;<br>            <span class="hljs-type">FsStateBackend</span> <span class="hljs-variable">fsStateBackend</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">FsStateBackend</span>(<span class="hljs-string">&quot;hdfs://&quot;</span> + checkpointPath);<br>            <span class="hljs-type">StateBackend</span> <span class="hljs-variable">rocksDBBackend</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RocksDBStateBackend</span>(fsStateBackend, TernaryBoolean.TRUE);<br>            env.setStateBackend(rocksDBBackend);<br>            env.setRestartStrategy(RestartStrategies.fixedDelayRestart(<span class="hljs-number">2</span>, Time.minutes(<span class="hljs-number">3</span>)));<br><span class="hljs-comment">//            env.setRestartStrategy(RestartStrategies.noRestart());</span><br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-type">StateBackend</span> <span class="hljs-variable">fsStateBackend</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">FsStateBackend</span>(<span class="hljs-string">&quot;file://&quot;</span> + checkpointPath);<br>            env.setStateBackend(fsStateBackend);<br>            env.setRestartStrategy(RestartStrategies.noRestart());<br>        &#125;<br><br>        env.getCheckpointConfig()<br>                .enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);<br><br>        <span class="hljs-keyword">return</span> env;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure></li><li><p>JavaBean </p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-meta">@Data</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ServerStandardLog</span> &#123;<br>    <span class="hljs-keyword">private</span> String logId=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String bline=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String pline=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> Long reqTime;<br>    <span class="hljs-keyword">private</span> String ip=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String country=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String province=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String city=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String uid=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String ua=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String imei=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String imsi=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String idfa=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String idfv=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String key=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> String subKey=<span class="hljs-string">&quot;&quot;</span>;<br>    <span class="hljs-keyword">private</span> Map&lt;String,String&gt; data = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">ServerStandardLog</span><span class="hljs-params">()</span> &#123;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h1 id="总结和问题"><a href="#总结和问题" class="headerlink" title="总结和问题"></a>总结和问题</h1><ul><li>使用flink-Streaming写入时,对map类型支持.</li><li>sink并行度不为1时,且多个topic往同一个目录写入时,需将sink文件名命名为不同的,否则会造成冲突,目前以topic区分,最好的方式可设置为随机数或uuid.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink SQL 调研实践总结</title>
      <link href="/flink/2020-05-12-Flink%20SQL%20%E8%B0%83%E7%A0%94%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/"/>
      <url>/flink/2020-05-12-Flink%20SQL%20%E8%B0%83%E7%A0%94%E5%AE%9E%E8%B7%B5%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="Flink-SQL-调研实践总结"><a href="#Flink-SQL-调研实践总结" class="headerlink" title="Flink SQL 调研实践总结"></a>Flink SQL 调研实践总结</h2><p>使用Flink 版本为:1.10.0<br>此版本中Flink SQL 对DDL语句支持直接创建Table方式使用.</p><p>注意: 基本使用能够,如果想利用Table方式对Hbase进行类似table查询读取操作失败,所以如果想使用这种方式的话,建议等到后续版本升级可能会支持.</p><h3 id="本次调研实践的各个软件版本说明"><a href="#本次调研实践的各个软件版本说明" class="headerlink" title="本次调研实践的各个软件版本说明"></a>本次调研实践的各个软件版本说明</h3><p>Flink:1.10.0</p><p>Kafka:2.2.0</p><p>ES:7.2</p><p>HBase:2.1.0</p><p>Hadoop:3.0.0</p><p>JDK:1.8.0</p><p>scala:2.11.12 | pom中打包使用的是 2.12</p><h3 id="使用情景"><a href="#使用情景" class="headerlink" title="使用情景:"></a>使用情景:</h3><p>source: kafka</p><p>sink: elesticsearch7, hbase</p><ul><li><p>业务需求:</p><p>利用 FlinkSQL 将 kafka中用户日志数据和hbase中数据数据关联查询.得到结果集.然后再存入hbase和es中.</p></li></ul><h4 id="具体代码实现"><a href="#具体代码实现" class="headerlink" title="具体代码实现"></a>具体代码实现</h4><p>逻辑说明: source接入Kafka,中间经过统计,最后将数据写入到es中.</p><p>直接贴代码吧.</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br></pre></td><td class="code"><pre><code class="hljs scala"><br><span class="hljs-keyword">import</span> org.apache.flink.api.common.restartstrategy.<span class="hljs-type">RestartStrategies</span><br><span class="hljs-keyword">import</span> org.apache.flink.api.scala._<br><span class="hljs-keyword">import</span> org.apache.flink.runtime.state.filesystem.<span class="hljs-type">FsStateBackend</span><br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.<span class="hljs-type">CheckpointingMode</span><br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.environment.<span class="hljs-type">CheckpointConfig</span>.<span class="hljs-type">ExternalizedCheckpointCleanup</span><br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.scala.<span class="hljs-type">StreamExecutionEnvironment</span><br><span class="hljs-keyword">import</span> org.apache.flink.table.api.<span class="hljs-type">EnvironmentSettings</span><br><span class="hljs-keyword">import</span> org.apache.flink.table.api.scala.&#123;<span class="hljs-type">StreamTableEnvironment</span>, _&#125;<br><span class="hljs-keyword">import</span> org.apache.flink.types.<span class="hljs-type">Row</span><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 此程序没有做到实时更新当前小时.待优化.(此为FlinkSql的特性所致.虽然没有实时写入到结果集.但是中间计算是实时计算着走的.到窗口结束时会将结果直接写入到结果集中)</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">FlinkSqlMidKafkaSinkES</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ConfigBase</span> </span>&#123;<br><br>  <span class="hljs-keyword">var</span> sourSql =<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">      |create table shafa_mid_log_json (</span><br><span class="hljs-string">      | ext String,</span><br><span class="hljs-string">      | os String,</span><br><span class="hljs-string">      | agent_id String,</span><br><span class="hljs-string">      | openid String,</span><br><span class="hljs-string">      | ctx String,</span><br><span class="hljs-string">      | ip String,</span><br><span class="hljs-string">      | network String,</span><br><span class="hljs-string">      | uid String,</span><br><span class="hljs-string">      | admin_id String,</span><br><span class="hljs-string">      | host String,</span><br><span class="hljs-string">      | referral_id String,</span><br><span class="hljs-string">      | theme String,</span><br><span class="hljs-string">      | tag String,</span><br><span class="hljs-string">      | page String,</span><br><span class="hljs-string">      | track String,</span><br><span class="hljs-string">      | channel_id String,</span><br><span class="hljs-string">      | map_json String,</span><br><span class="hljs-string">      | vt String,</span><br><span class="hljs-string">      | ua String,</span><br><span class="hljs-string">      | domain String,</span><br><span class="hljs-string">      | reqtime BIGINT,</span><br><span class="hljs-string">      | ts AS TO_TIMESTAMP(FROM_UNIXTIME(reqtime/1000,&#x27;yyyy-MM-dd HH:mm:ss&#x27;)), -- flink 官方版本暂不支持 传入 bigint的类型.阿里云文档中可以.</span><br><span class="hljs-string">      | proctime as PROCTIME(),   -- 通过计算列产生一个处理时间列</span><br><span class="hljs-string">      | WATERMARK FOR ts as ts - INTERVAL &#x27;5&#x27; SECOND  -- 在et上定义watermark，et成为事件时间列</span><br><span class="hljs-string">      | )</span><br><span class="hljs-string">      | WITH (</span><br><span class="hljs-string">      |&#x27;connector.type&#x27; = &#x27;kafka&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.version&#x27; = &#x27;universal&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.topic&#x27; = &#x27;mid_shafa_json_log&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.startup-mode&#x27; = &#x27;latest-offset&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.properties.group.id&#x27; = &#x27;flink_sql_consume_mid_json&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.properties.zookeeper.connect&#x27; = &#x27;%s&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.properties.bootstrap.servers&#x27; = &#x27;%s&#x27;,</span><br><span class="hljs-string">      |&#x27;format.type&#x27; = &#x27;json&#x27;,</span><br><span class="hljs-string">      |&#x27;update-mode&#x27;=&#x27;append&#x27;</span><br><span class="hljs-string">      | )&quot;&quot;&quot;</span>.stripMargin<br><br>  <span class="hljs-keyword">var</span> sinkSql =<br>    <span class="hljs-string">s&quot;&quot;</span><span class="hljs-string">&quot;CREATE TABLE sink_es_shafa_pv_uv (</span><br><span class="hljs-string">       |ts  STRING,</span><br><span class="hljs-string">       |channel_id String,</span><br><span class="hljs-string">       |pv BIGINT,</span><br><span class="hljs-string">       |uv BIGINT</span><br><span class="hljs-string">       |) WITH (</span><br><span class="hljs-string">       |&#x27;connector.type&#x27; = &#x27;elasticsearch&#x27;,</span><br><span class="hljs-string">       |&#x27;connector.version&#x27; = &#x27;7&#x27;,</span><br><span class="hljs-string">       |&#x27;connector.hosts&#x27; = &#x27;%s&#x27;,</span><br><span class="hljs-string">       |&#x27;connector.index&#x27; = &#x27;shafa_pv_uv_dh&#x27;,</span><br><span class="hljs-string">       |&#x27;connector.document-type&#x27; = &#x27;shafa_pv_uv&#x27;,</span><br><span class="hljs-string">       |&#x27;connector.bulk-flush.max-actions&#x27; = &#x27;1&#x27;,</span><br><span class="hljs-string">       |&#x27;format.type&#x27; = &#x27;json&#x27;,</span><br><span class="hljs-string">       |&#x27;update-mode&#x27; = &#x27;upsert&#x27;</span><br><span class="hljs-string">       |)&quot;</span><span class="hljs-string">&quot;&quot;</span>.stripMargin<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span></span>(args: <span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> paramTool = getProperties(args)<br>    <span class="hljs-keyword">val</span> zookeeperQuorum = paramTool.get(<span class="hljs-string">&quot;zookeeper.quorum&quot;</span>)<br>    <span class="hljs-keyword">val</span> esHttpHost = paramTool.get(<span class="hljs-string">&quot;es.http.host&quot;</span>)<br>    <span class="hljs-keyword">val</span> brokerServers = paramTool.get(<span class="hljs-string">&quot;kafka.bootstrap.servers&quot;</span>)<br>    <span class="hljs-keyword">val</span> env: <span class="hljs-type">StreamExecutionEnvironment</span> = <span class="hljs-type">StreamExecutionEnvironment</span>.getExecutionEnvironment<br><br>    <span class="hljs-comment">//启用并设置checkpoint相关属性</span><br>    env.enableCheckpointing(<span class="hljs-number">1000</span>, <span class="hljs-type">CheckpointingMode</span>.<span class="hljs-type">EXACTLY_ONCE</span>)<br>    env.getCheckpointConfig.setMaxConcurrentCheckpoints(<span class="hljs-number">1</span>)<br>    env.getCheckpointConfig.setMinPauseBetweenCheckpoints(<span class="hljs-number">500</span>)<br>    env.getCheckpointConfig.setCheckpointTimeout(<span class="hljs-number">60000</span>)<br>    <span class="hljs-comment">//2049 9870</span><br>    <span class="hljs-comment">//    env.setStateBackend(new FsStateBackend(&quot;hdfs://hd-master-101:9000/flink/checkpoints/shafa_pv_uv/&quot;));</span><br>    env.setStateBackend(<span class="hljs-keyword">new</span> <span class="hljs-type">FsStateBackend</span>(<span class="hljs-string">&quot;hdfs:///flink/checkpoints/shafa_pv_uv/&quot;</span>));<br>    env.getCheckpointConfig.enableExternalizedCheckpoints(<span class="hljs-type">ExternalizedCheckpointCleanup</span>.<span class="hljs-type">RETAIN_ON_CANCELLATION</span>)<br>    <span class="hljs-comment">//重启策略</span><br>    env.setRestartStrategy(<span class="hljs-type">RestartStrategies</span>.noRestart())<br><br><br>    <span class="hljs-keyword">val</span> settings = <span class="hljs-type">EnvironmentSettings</span>.newInstance()<br>      .useBlinkPlanner()<br>      .inStreamingMode()<br>      .build()<br>    env.setParallelism(<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">val</span> tEnv = <span class="hljs-type">StreamTableEnvironment</span>.create(env, settings)<br>    <span class="hljs-comment">//origin_cps_shafa_logs</span><br>    tEnv.sqlUpdate(sourSql.format(zookeeperQuorum, brokerServers))<br>    <span class="hljs-comment">//    tEnv.sqlUpdate(sourConsumeSql)</span><br>    tEnv.sqlUpdate(sinkSql.format(esHttpHost))<br>    <span class="hljs-comment">//    tEnv.sqlQuery(&quot;&quot;&quot;select channel_id,uid,ts,proctime from shafa_mid_log_json &quot;&quot;&quot;).toAppendStream[Row].print()</span><br>    <span class="hljs-comment">//统计一分钟内的数据</span><br>    tEnv.sqlQuery(<br>      <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        |</span><br><span class="hljs-string">        |select</span><br><span class="hljs-string">        | DATE_FORMAT(TUMBLE_START(ts, interval &#x27;10&#x27; minute),&#x27;yyyyMMddHHmm&#x27;) as ts,</span><br><span class="hljs-string">        | &#x27;all&#x27; as channel_id,</span><br><span class="hljs-string">        | count(uid) as pv,</span><br><span class="hljs-string">        | count(distinct uid) as pv</span><br><span class="hljs-string">        | from shafa_mid_log_json</span><br><span class="hljs-string">        | group by tumble(ts,interval &#x27;10&#x27; minute )</span><br><span class="hljs-string">        |&quot;&quot;&quot;</span>.stripMargin)<br>      .toAppendStream[<span class="hljs-type">Row</span>].print()<br><br>    <span class="hljs-comment">//    //5分钟</span><br>    <span class="hljs-comment">//    tEnv.sqlUpdate(</span><br>    <span class="hljs-comment">//      &quot;&quot;&quot;</span><br>    <span class="hljs-comment">//        |insert into sink_es_shafa_pv_uv</span><br>    <span class="hljs-comment">//        |select</span><br>    <span class="hljs-comment">//        | DATE_FORMAT(TUMBLE_END(ts, interval &#x27;5&#x27; minute),&#x27;yyyyMMddHHmm&#x27;) as ts,</span><br>    <span class="hljs-comment">//        | &#x27;all&#x27; as channel_id,</span><br>    <span class="hljs-comment">//        | count(uid) as pv,</span><br>    <span class="hljs-comment">//        | count(distinct uid) as pv</span><br>    <span class="hljs-comment">//        | from shafa_mid_log_json</span><br>    <span class="hljs-comment">//        | group by tumble(ts,interval &#x27;5&#x27; minute )</span><br>    <span class="hljs-comment">//        |&quot;&quot;&quot;.stripMargin)</span><br><br>    <span class="hljs-comment">//统计一个小时内pv,uv</span><br>    tEnv.sqlUpdate(<br>      <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        |insert into sink_es_shafa_pv_uv</span><br><span class="hljs-string">        | select</span><br><span class="hljs-string">        | DATE_FORMAT(TUMBLE_START(ts, interval &#x27;1&#x27; hour),&#x27;yyyyMMddHH&#x27;) as ts,</span><br><span class="hljs-string">        | channel_id,</span><br><span class="hljs-string">        | count(uid) as pv,</span><br><span class="hljs-string">        | count(distinct uid) as pv</span><br><span class="hljs-string">        | from shafa_mid_log_json</span><br><span class="hljs-string">        | group by tumble(ts,interval &#x27;1&#x27; hour ) , channel_id</span><br><span class="hljs-string">        |&quot;&quot;&quot;</span>.stripMargin)<br><br>    <span class="hljs-comment">//统计当前小时总的pv,uv</span><br>    tEnv.sqlUpdate(<br>      <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        |insert into sink_es_shafa_pv_uv</span><br><span class="hljs-string">        | select</span><br><span class="hljs-string">        | DATE_FORMAT(TUMBLE_START(ts, interval &#x27;1&#x27; hour),&#x27;yyyyMMddHH&#x27;) as ts,</span><br><span class="hljs-string">        | &#x27;hour&#x27; as channel_id,</span><br><span class="hljs-string">        | count(uid) as pv,</span><br><span class="hljs-string">        | count(distinct uid) as pv</span><br><span class="hljs-string">        | from shafa_mid_log_json</span><br><span class="hljs-string">        | group by tumble(ts,interval &#x27;1&#x27; hour )</span><br><span class="hljs-string">        |&quot;&quot;&quot;</span>.stripMargin)<br><br>    <span class="hljs-comment">//统计当天每个渠道总的pv,uv</span><br>    tEnv.sqlUpdate(<br>      <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        |insert into sink_es_shafa_pv_uv</span><br><span class="hljs-string">        | select</span><br><span class="hljs-string">        | DATE_FORMAT(TUMBLE_START(ts, interval &#x27;1&#x27; day),&#x27;yyyyMMdd&#x27;) as ts,</span><br><span class="hljs-string">        | channel_id,</span><br><span class="hljs-string">        | count(uid) as pv,</span><br><span class="hljs-string">        | count(distinct uid) as pv</span><br><span class="hljs-string">        | from shafa_mid_log_json</span><br><span class="hljs-string">        | group by tumble(ts,interval &#x27;1&#x27; day ),channel_id</span><br><span class="hljs-string">        |&quot;&quot;&quot;</span>.stripMargin)<br><br>    <span class="hljs-comment">//统计当天总的pv,uv</span><br>    tEnv.sqlUpdate(<br>      <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        |insert into sink_es_shafa_pv_uv</span><br><span class="hljs-string">        | select</span><br><span class="hljs-string">        | DATE_FORMAT(TUMBLE_START(ts, interval &#x27;1&#x27; day),&#x27;yyyyMMdd&#x27;) as ts,</span><br><span class="hljs-string">        | &#x27;day&#x27; as channel_id,</span><br><span class="hljs-string">        | count(uid) as pv,</span><br><span class="hljs-string">        | count(distinct uid) as pv</span><br><span class="hljs-string">        | from shafa_mid_log_json</span><br><span class="hljs-string">        | group by tumble(ts,interval &#x27;1&#x27; day )</span><br><span class="hljs-string">        |&quot;&quot;&quot;</span>.stripMargin)<br><br>    env.execute(<span class="hljs-string">&quot;stat_shafa_pv_uv_es&quot;</span>)<br>  &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结:"></a>总结:</h3><ol><li><p>kafka接入时利用了计算列</p> <figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scala">| reqtime <span class="hljs-type">BIGINT</span>,<br>| ts <span class="hljs-type">AS</span> <span class="hljs-type">TO_TIMESTAMP</span>(<span class="hljs-type">FROM_UNIXTIME</span>(reqtime/<span class="hljs-number">1000</span>,&#x27;yyyy-<span class="hljs-type">MM</span>-dd <span class="hljs-type">HH</span>:mm:ss&#x27;)) <br></code></pre></td></tr></table></figure><p>flink sql1.10.0 中TO_TIMESTAMP函数还不支持时间戳(整型数据),支持符合时间格式的字符串形式.但是阿里云文档的支持.</p></li><li><p>写入结果集需等到窗口结束时一次性写入.</p></li><li><p>目前table 对hbase只能做写入操作.对读取操作不友好,测试发现暂时无法正常使用.不建议使用table方式读取Hbase,但是可以做写入.Flink SQL后续版本可能会升级.</p></li></ol><p>具体代码测试读取Hbase:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs scala"><br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.scala.&#123;<span class="hljs-type">StreamExecutionEnvironment</span>, _&#125;<br><span class="hljs-keyword">import</span> org.apache.flink.table.api.<span class="hljs-type">EnvironmentSettings</span><br><span class="hljs-keyword">import</span> org.apache.flink.table.api.scala.&#123;<span class="hljs-type">StreamTableEnvironment</span>, _&#125;<br><span class="hljs-keyword">import</span> org.apache.flink.types.<span class="hljs-type">Row</span><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * hbase join flink sql table test</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">object</span> <span class="hljs-title">HbaseJoinFlinkTableV2</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ConfigBase</span> </span>&#123;<br>  <span class="hljs-keyword">var</span> sourceSql =<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">      |create table cps_hive_to_hbase (</span><br><span class="hljs-string">      | id VARCHAR,</span><br><span class="hljs-string">      | cf1 ROW(</span><br><span class="hljs-string">      | user_id VARCHAR,</span><br><span class="hljs-string">      | channel_id VARCHAR,</span><br><span class="hljs-string">      | open_id VARCHAR,</span><br><span class="hljs-string">      | book_id VARCHAR,</span><br><span class="hljs-string">      | book_sex VARCHAR,</span><br><span class="hljs-string">      | book_category_id VARCHAR,</span><br><span class="hljs-string">      | read_chapter_num VARCHAR,</span><br><span class="hljs-string">      | all_read_chapter_num VARCHAR,</span><br><span class="hljs-string">      | utime VARCHAR,</span><br><span class="hljs-string">      | rgdt VARCHAR,</span><br><span class="hljs-string">      | sex VARCHAR,</span><br><span class="hljs-string">      | subscribe_time VARCHAR,</span><br><span class="hljs-string">      | vip_endtime VARCHAR,</span><br><span class="hljs-string">      | update_user_time VARCHAR,</span><br><span class="hljs-string">      | is_pay VARCHAR,</span><br><span class="hljs-string">      | cz_money VARCHAR,</span><br><span class="hljs-string">      | cz_count VARCHAR,</span><br><span class="hljs-string">      | all_xf_free_kandian VARCHAR,</span><br><span class="hljs-string">      | all_xf_money VARCHAR,</span><br><span class="hljs-string">      | all_remain_money VARCHAR,</span><br><span class="hljs-string">      | all_remain_free_money VARCHAR</span><br><span class="hljs-string">      | )</span><br><span class="hljs-string">      |</span><br><span class="hljs-string">      | )</span><br><span class="hljs-string">      | WITH (</span><br><span class="hljs-string">      |&#x27;connector.type&#x27; = &#x27;hbase&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.version&#x27; = &#x27;1.4.3&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.table-name&#x27; = &#x27;cps_hive_to_hbase&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.zookeeper.znode.parent&#x27; = &#x27;/hbase&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.zookeeper.quorum&#x27; = &#x27;%s&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.write.buffer-flush.max-size&#x27; = &#x27;10mb&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.write.buffer-flush.max-rows&#x27; = &#x27;1000&#x27;,</span><br><span class="hljs-string">      |&#x27;connector.write.buffer-flush.interval&#x27; = &#x27;2s&#x27;</span><br><span class="hljs-string">      | )&quot;&quot;&quot;</span>.stripMargin<br><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span></span>(args: <span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]): <span class="hljs-type">Unit</span> = &#123;<br>    <span class="hljs-keyword">val</span> paramTool = getProperties(args)<br>    <span class="hljs-keyword">val</span> zookeeper = paramTool.get(<span class="hljs-string">&quot;zookeeper.quorum&quot;</span>)<br>    <span class="hljs-keyword">val</span> env = <span class="hljs-type">StreamExecutionEnvironment</span>.getExecutionEnvironment<br>    <span class="hljs-keyword">val</span> settings = <span class="hljs-type">EnvironmentSettings</span>.newInstance()<br>      .useBlinkPlanner()<br>      .inStreamingMode()<br>      .build()<br>    <span class="hljs-comment">//    env.setParallelism(1)</span><br>    <span class="hljs-keyword">val</span> tEnv = <span class="hljs-type">StreamTableEnvironment</span>.create(env, settings)<br>    sourceSql = <span class="hljs-type">String</span>.format(sourceSql, zookeeper)<br><br>    println(sourceSql)<br>    tEnv.sqlUpdate(sourceSql)<br><br>    <span class="hljs-keyword">val</span> query = tEnv.sqlQuery(<span class="hljs-string">&quot;select * from  cps_hive_to_hbase limit 10 &quot;</span>).toAppendStream[<span class="hljs-type">Row</span>].print()<br><br>    env.execute(<span class="hljs-string">&quot;test hbase&quot;</span>)<br><br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>会抛出异常:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs log">Exception in thread &quot;main&quot; java.lang.RuntimeException: java.util.concurrent.ExecutionException: akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://flink/user/dispatcher#-523925282]] after [10000 ms]. Message of type [org.apache.flink.runtime.rpc.messages.LocalFencedMessage]. A typical reason for `AskTimeoutException` is that the recipient actor didn&#x27;t send a reply.<br><br><br></code></pre></td></tr></table></figure><p>查看官方论坛<a href="https://issues.apache.org/jira/browse/FLINK-11143">issues</a>中有人提及,未找到解决方案.</p><h3 id="附录一-代码"><a href="#附录一-代码" class="headerlink" title="附录一 代码"></a>附录一 代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs scala"><br><span class="hljs-keyword">import</span> org.apache.flink.api.java.utils.<span class="hljs-type">ParameterTool</span><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ConfigBase</span> </span>&#123;<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getProperties</span></span>(args: <span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]): <span class="hljs-type">ParameterTool</span> = &#123;<br>    <span class="hljs-type">ParameterTool</span>.fromPropertiesFile(<span class="hljs-keyword">this</span>.getClass.getClassLoader.getResourceAsStream(<span class="hljs-string">&quot;application.yml&quot;</span>))<br>  &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="附录二-POM-xml"><a href="#附录二-POM-xml" class="headerlink" title="附录二 POM.xml"></a>附录二 POM.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span>?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">project</span> <span class="hljs-attr">xmlns</span>=<span class="hljs-string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span><br><span class="hljs-tag">         <span class="hljs-attr">xmlns:xsi</span>=<span class="hljs-string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span><br><span class="hljs-tag">         <span class="hljs-attr">xsi:schemaLocation</span>=<span class="hljs-string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">parent</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>dz-rt<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.dz.rt<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">parent</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">modelVersion</span>&gt;</span>4.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">modelVersion</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-sql<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">flink.version</span>&gt;</span>1.10.0<span class="hljs-tag">&lt;/<span class="hljs-name">flink.version</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">scala.library.verison</span>&gt;</span>2.12<span class="hljs-tag">&lt;/<span class="hljs-name">scala.library.verison</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">scala.version</span>&gt;</span>2.12.11<span class="hljs-tag">&lt;/<span class="hljs-name">scala.version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.scala-lang<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>scala-library<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;scala.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-core<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-scala_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-comment">&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-streaming-scala_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-comment">&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-elasticsearch7_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-api-java-bridge_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-api-scala-bridge_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-planner_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-planner-blink_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-streaming-scala_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-comment">&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-table<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">type</span>&gt;</span>pom<span class="hljs-tag">&lt;/<span class="hljs-name">type</span>&gt;</span><br>            <span class="hljs-comment">&lt;!--            &lt;scope&gt;provided&lt;/scope&gt;--&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-connector-kafka_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.alibaba<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>fastjson<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.68<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-scala_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-json<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-csv<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-hbase --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.flink<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>flink-hbase_$&#123;scala.library.verison&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.0.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>        <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-client --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hbase<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hbase-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.1.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-comment">&lt;!--            &lt;version&gt;1.4.3&lt;/version&gt;--&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">resources</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">resource</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/scala/<span class="hljs-tag">&lt;/<span class="hljs-name">directory</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">targetPath</span>&gt;</span>target/classes/<span class="hljs-tag">&lt;/<span class="hljs-name">targetPath</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">includes</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">include</span>&gt;</span>*.*<span class="hljs-tag">&lt;/<span class="hljs-name">include</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">includes</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">resource</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">resource</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/resources/<span class="hljs-tag">&lt;/<span class="hljs-name">directory</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">includes</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">include</span>&gt;</span>*.*<span class="hljs-tag">&lt;/<span class="hljs-name">include</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">includes</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">resource</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">resources</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>            <span class="hljs-comment">&lt;!-- Scala Compiler --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>net.alchim31.maven<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>scala-maven-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.2.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>testCompile<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">args</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">arg</span>&gt;</span>-nobootcp<span class="hljs-tag">&lt;/<span class="hljs-name">arg</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">args</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br><br>            <span class="hljs-comment">&lt;!-- 编译插件 --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.7.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br><br>            <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-dependency-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>copy-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>prepare-package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">goals</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">goal</span>&gt;</span>copy-dependencies<span class="hljs-tag">&lt;/<span class="hljs-name">goal</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">goals</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">outputDirectory</span>&gt;</span>$&#123;project.build.directory&#125;/lib<span class="hljs-tag">&lt;/<span class="hljs-name">outputDirectory</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">overWriteReleases</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">overWriteReleases</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">overWriteSnapshots</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">overWriteSnapshots</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">overWriteIfNewer</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">overWriteIfNewer</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br><br><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">project</span>&gt;</span><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
          <category> FlinkSQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink 提交任务及问题排查</title>
      <link href="/flink/2020-05-08-Flink%20%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%8F%8A%E6%80%BB%E7%BB%93/"/>
      <url>/flink/2020-05-08-Flink%20%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E9%97%AE%E9%A2%98%E5%8F%8A%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="Flink-提交任务相关使用"><a href="#Flink-提交任务相关使用" class="headerlink" title="Flink 提交任务相关使用"></a>Flink 提交任务相关使用</h2><h3 id="Flink提交任务问题描述"><a href="#Flink提交任务问题描述" class="headerlink" title="Flink提交任务问题描述"></a>Flink提交任务问题描述</h3><ul><li>环境说明:</li></ul><ol><li>运行方式环境: Flink on yarn</li><li>提交方式 bin&#x2F;flink run -m yarn-cluster -d ….args</li></ol><ul><li>问题来源描述:</li></ul><ol><li>线上测试时,提交任务时,想指定任务到具体到那个yarn queue,和自定义application name</li></ol><ul><li>过程:</li></ul><ol><li><p>不指定appname,和yarnqueue前提交任务方式:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/flink run -s hdfs:///flink/checkpoints/59f0497711acd5f6f7b7eba0b536e1a9/chk-12699/_metadata -m yarn-cluster -d \<br>-ynm KafkaETLToKafka -yqu root.flink -yjm 1024 -ytm 1024 -ys 1 --class com.dz.rt.fql.KafkaETLToKafka apps/flink-sql-1.0.0.jar <br><br></code></pre></td></tr></table></figure></li><li><p>尝试指定 queue和app name 方式,未成功.</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#此方式提交时,-yqu root.flink  -ynm &quot;KafkaETLToKafka&quot;不生效</span><br>./bin/flink run -s hdfs:///flink/checkpoints/ab8ddc38cd161f23ab2e1c9f334639f1/chk-6884/_metadata -m yarn-cluster -d \<br>--class com.dz.rt.fql.KafkaETLToKafka apps/flink-sql-1.0.0.jar \<br>-yjm 1024 -ytm 1024 -yqu root.flink  -ynm <span class="hljs-string">&quot;KafkaETLToKafka&quot;</span><br><br></code></pre></td></tr></table></figure></li><li><p>成功的方式:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/flink run -s hdfs:///flink/checkpoints/shafa_pv_uv/de857b69ca392a9b62ecf21a74cabb7c/chk-68146/_metadata -m yarn-cluster -d \<br>-yjm 1024 -ytm 1024 -yqu root.flink -ynm <span class="hljs-string">&quot;KafkaETLToKafka&quot;</span> \<br>--class com.dz.rt.fql.KafkaETLToKafka -j apps/flink-sql-1.0.0.jar <br></code></pre></td></tr></table></figure></li><li><p>cancel Job:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">./bin/flink cancel -s [savepoint-path] jobId -yid yarnId  <br><span class="hljs-comment">#eg:</span><br>./bin/flink cancel -s hdfs:///flink/savepoints/KafkaETLToKafka b901b38229a9376ab910dc905fd985a7 -yid application_1625118766753_0013<br></code></pre></td></tr></table></figure></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在flink on yarn 使用flink方式提交任务中:</p><ol><li>使用-jy 参数无效.需使用 -j,或不使用-j参数 将jar跟在 -c|–class 类名后面.</li><li>需将flink run参数尽量写到-c前面,保证参数有效优先</li><li>使用checpoints 是 记得加参数 -s hdfs:&#x2F;&#x2F;nameservice1&#x2F;chk_meta_path. 后记得加上 -m yarn-cluster</li></ol><p>其他提交方式和参数使用及具体说明,参看 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/cli.html">Flink官方文档</a>{:target&#x3D;”_blank”}</p><h2 id="Flink-日志问题排查"><a href="#Flink-日志问题排查" class="headerlink" title="Flink 日志问题排查"></a>Flink 日志问题排查</h2><h3 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h3><ol><li>方式一</li></ol><p>直接通过web页面访问.</p><ol start="2"><li>方式二</li></ol><p>通过yarn logs -applicationId xxxx 方式</p><p>yarn logs命令使用参看 yarn logs –help</p><p>此方式使用时:需启用yarn日志收集</p><p>yarn.log-aggregation-enable&#x3D;true</p><p>更多相关问题排查可参看 <a href="https://developer.aliyun.com/article/719703">阿里Flink on Yarn问题排查文档</a></p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hive 自定义函数处理非法字符</title>
      <link href="/hive/2019-11-08-hive-udf-%E5%A4%84%E7%90%86%E9%9D%9E%E6%B3%95%E5%AD%97%E6%AE%B5/"/>
      <url>/hive/2019-11-08-hive-udf-%E5%A4%84%E7%90%86%E9%9D%9E%E6%B3%95%E5%AD%97%E6%AE%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="hive-自定义函数-解析非法字符串"><a href="#hive-自定义函数-解析非法字符串" class="headerlink" title="hive 自定义函数 解析非法字符串"></a>hive 自定义函数 解析非法字符串</h1><h2 id="现象"><a href="#现象" class="headerlink" title="现象:"></a>现象:</h2><pre><code class="hljs">线上业务因解析某个字段,将最终结果导入到mysql出现非法字符不能插入的情况.mysql的编码为utf8</code></pre><p>现象部分日志</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs log"><br>org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) at org.apache.sqoop.mapreduce.TextExportMapper.map(TextExportMapper.java:90) ... 10 more Caused by: java.sql.BatchUpdateException: Incorrect string value: &#x27;\xF0\x9F\x90\x89&#x27; for column &#x27;column_name&#x27; at row 24 at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at<br><br></code></pre></td></tr></table></figure><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ol><li><p>修改mysql的编码,将其设置为utf8mb4,并配置mysql.conf.重启mysql</p><p> 优点:一劳永逸. </p><p> 缺点:线上数据库为业务数据库,重启成本太大</p></li><li><p>自定义函数,过滤不合理的字符串,将其替换.</p><p>  优点:不用重启数据库. </p><p> 缺点: 每次遇到非法字符需要使用自定义函数去解析.</p></li></ol><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>现选择了方案2.<br>实现方式,直接上代码:<br>添加maven依赖 (选择和线上hive相对应的version依赖)</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-exec<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.1.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 处理hive中utf8字符串中的特殊表情符号,mysql导入数据时,提示非法字符,</span><br><span class="hljs-comment"> * 解决方案:</span><br><span class="hljs-comment"> * 1.可通过修改 mysql的编码集为: utf8mb4,缺点:需要重启数据库,线上环境不友好</span><br><span class="hljs-comment"> * 2.通过自定义函数将 非法字段过滤,替换为空或其他自定义字符串,缺点: 需要编码,将jar上传.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SpecialStringProcess</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">UDF</span> &#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * 替换非法字符的数据</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">String</span> <span class="hljs-variable">replaceStr</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">evaluate</span><span class="hljs-params">(String originValue)</span> &#123;<br>        <span class="hljs-keyword">if</span> (originValue == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (originValue.trim().isEmpty()) &#123;<br>            <span class="hljs-keyword">return</span> originValue;<br>        &#125;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">pattern</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;[\\ud83c\\udc00-\\ud83c\\udfff]|[\\ud83d\\udc00-\\ud83d\\udfff]|[\\u2600-\\u27ff]&quot;</span>;<br>        <span class="hljs-type">Pattern</span> <span class="hljs-variable">emoji</span> <span class="hljs-operator">=</span> Pattern.compile(pattern);<br>        <span class="hljs-type">Matcher</span> <span class="hljs-variable">matcher</span> <span class="hljs-operator">=</span> emoji.matcher(originValue);<br>        <span class="hljs-comment">//去除表情符</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> matcher.replaceAll(replaceStr);<br>        <span class="hljs-comment">//去除非UTF8编码的字符</span><br>        result = filterOffUtf8Mb4V2(result);<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br><br>    <span class="hljs-comment">//过滤 非utf8编码的字符</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">filterOffUtf8Mb4</span><span class="hljs-params">(String text)</span> &#123;<br>        <span class="hljs-type">byte</span>[] bytes = <span class="hljs-keyword">new</span> <span class="hljs-title class_">byte</span>[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">try</span> &#123;<br>            bytes = text.getBytes(<span class="hljs-string">&quot;UTF-8&quot;</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (UnsupportedEncodingException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>        <span class="hljs-type">ByteBuffer</span> <span class="hljs-variable">buffer</span> <span class="hljs-operator">=</span> ByteBuffer.allocate(bytes.length);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (i &lt; bytes.length) &#123;<br>            <span class="hljs-type">short</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> bytes[i];<br>            <span class="hljs-keyword">if</span> (b &gt; <span class="hljs-number">0</span>) &#123;<br>                buffer.put(bytes[i++]);<br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br>            b += <span class="hljs-number">256</span>;<br>            <span class="hljs-keyword">if</span> ((b ^ <span class="hljs-number">0xC0</span>) &gt;&gt; <span class="hljs-number">4</span> == <span class="hljs-number">0</span>) &#123;<br>                buffer.put(bytes, i, <span class="hljs-number">2</span>);<br>                i += <span class="hljs-number">2</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((b ^ <span class="hljs-number">0xE0</span>) &gt;&gt; <span class="hljs-number">4</span> == <span class="hljs-number">0</span>) &#123;<br>                buffer.put(bytes, i, <span class="hljs-number">3</span>);<br>                i += <span class="hljs-number">3</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((b ^ <span class="hljs-number">0xF0</span>) &gt;&gt; <span class="hljs-number">4</span> == <span class="hljs-number">0</span>) &#123;<br>                i += <span class="hljs-number">4</span>;<br>            &#125;<br>        &#125;<br>        buffer.flip();<br>        <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(buffer.array(), <span class="hljs-string">&quot;utf-8&quot;</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (UnsupportedEncodingException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br>        <span class="hljs-keyword">return</span> text;<br>    &#125;<br><br><br>    <span class="hljs-comment">// 过滤非汉字的utf8的字符</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title function_">filterOffUtf8Mb4V2</span><span class="hljs-params">(String text)</span> &#123;<br>        <span class="hljs-type">byte</span>[] bytes = <span class="hljs-string">&quot;&quot;</span>.getBytes();<br>        <span class="hljs-keyword">try</span> &#123;<br>            bytes = text.getBytes(<span class="hljs-string">&quot;utf-8&quot;</span>);<br><br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br><br>        &#125;<br>        <span class="hljs-type">ByteBuffer</span> <span class="hljs-variable">buffer</span> <span class="hljs-operator">=</span> ByteBuffer.allocate(bytes.length);<br>        <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (i &lt; bytes.length) &#123;<br>            <span class="hljs-type">short</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> bytes[i];<br>            <span class="hljs-keyword">if</span> (b &gt; <span class="hljs-number">0</span>) &#123;<br>                buffer.put(bytes[i++]);<br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br><br>            b += <span class="hljs-number">256</span>; <span class="hljs-comment">// 去掉符号位</span><br><br>            <span class="hljs-keyword">if</span> (((b &gt;&gt; <span class="hljs-number">5</span>) ^ <span class="hljs-number">0x6</span>) == <span class="hljs-number">0</span>) &#123;<br>                buffer.put(bytes, i, <span class="hljs-number">2</span>);<br>                i += <span class="hljs-number">2</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (((b &gt;&gt; <span class="hljs-number">4</span>) ^ <span class="hljs-number">0xE</span>) == <span class="hljs-number">0</span>) &#123;<br>                buffer.put(bytes, i, <span class="hljs-number">3</span>);<br>                i += <span class="hljs-number">3</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (((b &gt;&gt; <span class="hljs-number">3</span>) ^ <span class="hljs-number">0x1E</span>) == <span class="hljs-number">0</span>) &#123;<br>                i += <span class="hljs-number">4</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (((b &gt;&gt; <span class="hljs-number">2</span>) ^ <span class="hljs-number">0x3E</span>) == <span class="hljs-number">0</span>) &#123;<br>                i += <span class="hljs-number">5</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (((b &gt;&gt; <span class="hljs-number">1</span>) ^ <span class="hljs-number">0x7E</span>) == <span class="hljs-number">0</span>) &#123;<br>                i += <span class="hljs-number">6</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                buffer.put(bytes[i++]);<br>            &#125;<br>        &#125;<br>        buffer.flip();<br>        <span class="hljs-type">String</span> <span class="hljs-variable">str</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            str = <span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>(buffer.array(), <span class="hljs-string">&quot;utf-8&quot;</span>);<br><br>        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br><br>        &#125;<br>        <span class="hljs-keyword">return</span> str;<br>    &#125;<br><br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>首先将打包好的jar上传的hdfs</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfs -put xxx.jar /hdfs/udf/<br></code></pre></td></tr></table></figure><p>使用方式有两种.</p><ol><li>在hive中添加全局的自定义function</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">进入到hive shell中 ,直接创建永久自定义函数</span><br><span class="hljs-meta prompt_">hive&gt;</span><span class="language-bash"></span><br><span class="language-bash">create <span class="hljs-keyword">function</span> replaceEmoji as <span class="hljs-string">&#x27;com.xx.hive.SpecialStringProcess&#x27;</span> using jar <span class="hljs-string">&#x27;hdfs:///hdfs/udf/xxx.jar&#x27;</span>;</span><br><br></code></pre></td></tr></table></figure><p>此法优点:一次添加后续直接使用</p><p>缺点: 对后期维护不友好</p><ol start="2"><li>在hive sql中使用临时的自义定function</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">在hive -e <span class="hljs-string">&quot;...&quot;</span> 或 hive -f file.. 中 创建临时的<span class="hljs-keyword">function</span></span><br><br>hive -e &quot;<br>create temporary function replaceEmoji as &#x27;com.xx.hive.SpecialStringProcess&#x27; using jar &#x27;hdfs:///hdfs/udf/xxx.jar&#x27;;<br>other conf.....<br>...<br>sql <br>....<br><br>&quot;<br><br></code></pre></td></tr></table></figure><p>此法优点: 明确使用来源,方便查看和定位.</p><p>缺点: 每次都需要创建</p>]]></content>
      
      
      <categories>
          
          <category> Hive </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>很久不用Tomcat，使用Tomcat的小结</title>
      <link href="/java/2019-11-08-Tomcat%E9%83%A8%E7%BD%B2%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"/>
      <url>/java/2019-11-08-Tomcat%E9%83%A8%E7%BD%B2%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="问题背景和现象"><a href="#问题背景和现象" class="headerlink" title="问题背景和现象"></a>问题背景和现象</h1><p>上上个月(九月底),刚到新公司第一天(早上11点领到电脑,下午让我做个功能),然后上线部署..我他瞄啥环境都不熟悉,连机器在哪都不知道,权限都是现找人开…待续,下班(已到凌晨1点半了).身体要紧.</p><hr><p>2019年11月11日17:28<br>继续上次没写完的.<br><br>之前公司的部署方式是 docker image + k8s集群 ,每次打包后得到 对应的docker image上传的镜像服务器.<br>在k8s中直接 kubectl set  image deploy&#x2F;app_name app_name&#x3D;docker_image<br>即可.</p><p>很久没用tomcat直接部署过了.<br>在此记录一下,以及对相应的一些配置熟悉.</p><p>以下操作,默认以tomcat跟目录为基础.</p><h1 id="启动脚本相关说明和配置"><a href="#启动脚本相关说明和配置" class="headerlink" title="启动脚本相关说明和配置"></a>启动脚本相关说明和配置</h1><p>查看bin下的startup.sh脚本.可以看到</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash">PRGDIR=`<span class="hljs-built_in">dirname</span> <span class="hljs-string">&quot;<span class="hljs-variable">$PRG</span>&quot;</span>`<br>EXECUTABLE=catalina.sh<br><br><span class="hljs-comment"># Check that target executable exists</span><br><span class="hljs-keyword">if</span> <span class="hljs-variable">$os400</span>; <span class="hljs-keyword">then</span><br>  <span class="hljs-comment"># -x will Only work on the os400 if the files are:</span><br>  <span class="hljs-comment"># 1. owned by the user</span><br>  <span class="hljs-comment"># 2. owned by the PRIMARY group of the user</span><br>  <span class="hljs-comment"># this will not work if the user belongs in secondary groups</span><br>  <span class="hljs-built_in">eval</span><br><span class="hljs-keyword">else</span><br>  <span class="hljs-keyword">if</span> [ ! -x <span class="hljs-string">&quot;<span class="hljs-variable">$PRGDIR</span>&quot;</span>/<span class="hljs-string">&quot;<span class="hljs-variable">$EXECUTABLE</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Cannot find <span class="hljs-variable">$PRGDIR</span>/<span class="hljs-variable">$EXECUTABLE</span>&quot;</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;The file is absent or does not have execute permission&quot;</span><br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;This file is needed to run this program&quot;</span><br>    <span class="hljs-built_in">exit</span> 1<br>  <span class="hljs-keyword">fi</span><br><span class="hljs-keyword">fi</span><br><br><span class="hljs-built_in">exec</span> <span class="hljs-string">&quot;<span class="hljs-variable">$PRGDIR</span>&quot;</span>/<span class="hljs-string">&quot;<span class="hljs-variable">$EXECUTABLE</span>&quot;</span> start <span class="hljs-string">&quot;<span class="hljs-variable">$@</span>&quot;</span><br><br></code></pre></td></tr></table></figure><h2 id="实际启动脚本参数配置"><a href="#实际启动脚本参数配置" class="headerlink" title="实际启动脚本参数配置"></a>实际启动脚本参数配置</h2><p>可以看到实际去执行的脚本是:<br>bin目录下的catalina.sh脚本.<br>进入 catalina.sh 脚本中,可查看到启动时,对jvm的参数设置和classpath相关进行设置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 设置 jvm相关参数</span><br>JAVA_OPTS=<span class="hljs-string">&quot; -Djava.util.Arrays.useLegacyMergeSort=true -Dprofile=onl -Djava.security.egd=file:/dev/./urandom -Xms16396m -Xmx16396m  -DDZServerLocation=NEW -XX:MaxNewSize=4096m -XX:MaxPermSize=4096m &quot;</span><br><br><span class="hljs-comment"># 设置 class path,将依赖的jar导入.</span><br>CLASSPTH=<span class="hljs-variable">$CLASSPATH</span>:<span class="hljs-variable">$CATALINA_BASE</span>/applib/*.jar<br><br>CLASSPATH=<br><br><span class="hljs-keyword">if</span> [ -r <span class="hljs-string">&quot;<span class="hljs-variable">$CATALINA_BASE</span>/bin/setenv.sh&quot;</span> ]; <span class="hljs-keyword">then</span><br>  . <span class="hljs-string">&quot;<span class="hljs-variable">$CATALINA_BASE</span>/bin/setenv.sh&quot;</span><br><span class="hljs-keyword">elif</span> [ -r <span class="hljs-string">&quot;<span class="hljs-variable">$CATALINA_HOME</span>/bin/setenv.sh&quot;</span> ]; <span class="hljs-keyword">then</span><br>  . <span class="hljs-string">&quot;<span class="hljs-variable">$CATALINA_HOME</span>/bin/setenv.sh&quot;</span><br><span class="hljs-keyword">fi</span><br><br><br></code></pre></td></tr></table></figure><h2 id="依赖相关配置"><a href="#依赖相关配置" class="headerlink" title="依赖相关配置"></a>依赖相关配置</h2><p>当我们的项目依赖很多jar包时,上传war到服务器时,不用每次都带着对应的jar包,将依赖的jar放到一个指定的目录,这是打包war时,就不用每次都把依赖的jar包打上,减少了 war的大小.</p><p>缺点: 可能更新jar包版本时,容易忘记将新的jar忘记上传更新.</p><p>打全包的有点就是不用考虑是否有jar忘记上传依赖.</p><p>配置依赖jar包目录(也可将依赖的jar直接放到tomcat根目录下lib目录中,但不建议这样做.)</p><p>新建一个目录存放依赖的jar包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> applib<br><br></code></pre></td></tr></table></figure><p>编辑 catalina.properties </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><br>common.loader=&quot;$&#123;catalina.base&#125;/lib&quot;,&quot;$&#123;catalina.base&#125;/lib/*.jar&quot;,&quot;$&#123;catalina.home&#125;/lib&quot;,&quot;$&#123;catalina.home&#125;/lib/*.jar&quot;,&quot;$&#123;catalina.home&#125;/applib&quot;,&quot;$&#123;catalina.home&#125;/applib/*.jar&quot;<br><br><br></code></pre></td></tr></table></figure><p>将新增的applib目录和jar包,添加到common.loader,tomcat启动时读取 catalina.properties 配置,会将这里设置的依赖加入到环境变量中.</p><h1 id="关于自动部署和热部署"><a href="#关于自动部署和热部署" class="headerlink" title="关于自动部署和热部署."></a>关于自动部署和热部署.</h1><p>相关配置:<br>见server.xml中的autodeploy 属性</p><p>自动部署: 当将新的war放到到wabapp目录下,tomcat有配置项可以使新放入的war进行自动部署,但是,当自动部署后,系统中的用户需要重新登陆,没有保存session信息.</p><p>重启部署:重启部署方式中.将tomcat bin&#x2F;shutdown.sh后,如果已登录的用户,在此期间不进行操作,session不会丢失,当再次启动tomcat后,用户session依然得以保留(用户在部署期间不访问服务器,session会被保存,如果服务器重启中,访问了,session会丢失.)</p><p>以上两点,具体内部实现还不太清楚,不过实际中遇到的情况就是这样的.后续可再搞清.</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>kubernetes浅入(一)</title>
      <link href="/docker/2018-05-09-kubernetes%E6%B5%85%E5%85%A5/"/>
      <url>/docker/2018-05-09-kubernetes%E6%B5%85%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<hr><p>公司需要搭建一个k8s集群用于爬虫快捷部署,临时看了mritd<a href="https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/"></a>的搭建教程,基本算是可以使用了.</p><p>本文仅做个人笔记使用,搭建过程参考自:<a href="https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/">mritd的博文</a>{:target&#x3D;”_blank”}</p><p>为了快速搭建,本次搭建使用了mritd的脚本</p><hr><h2 id="系统和软件"><a href="#系统和软件" class="headerlink" title="系统和软件"></a>系统和软件</h2><ol><li>Ubuntu16.04 server</li><li>Kubernetes1.10.1</li><li>Docker 18.03.1-ce</li></ol><h2 id="软件和背景"><a href="#软件和背景" class="headerlink" title="软件和背景"></a>软件和背景</h2><ol><li>需要提前安装docker和docker-compose</li><li>etcd <a href="https://yq.aliyun.com/articles/11035">etcd简介参考文档</a> ETCD是用于共享配置和服务发现的分布式，一致性的KV存储系统。</li><li>cfssl 用于生成ectd证书<a href="https://github.com/cloudflare/cfssl/releases">GitHub官网下载</a></li><li>hyperkube <a href="https://github.com/kubernetes/kubernetes/blob/master/cluster/images/hyperkube/README.md">官方介绍</a>(用于安装kubelet)</li><li>本文使用4台机子搭建(ip地址根据自己需要修改)</li></ol><p>| IP   | TYPE  |<br>| ****** | ****** |<br>| 192.168.1.30  | master node etcd  |<br>| 192.168.1.31  | node etcd  |<br>| 192.168.1.32  | node etcd  |<br>| 192.168.1.33  | node   | </p><h2 id="开始搭建"><a href="#开始搭建" class="headerlink" title="开始搭建"></a>开始搭建</h2><p>切换到root用户,在root家目录新建个文件夹用户存放后续需要用到的文件和配置,</p><p>记得对从节点配置ssh免登陆</p><p>我新建的目录为 k8s,后续安装不特别说明都基于 &#x2F;root&#x2F;k8s 此目录</p><p>先查看安装目录结构<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180509130102.png!700x999"><br><br></p><h3 id="一-安装cfssl"><a href="#一-安装cfssl" class="headerlink" title="一 安装cfssl"></a>一 安装cfssl</h3><p>使用mritd的cnd下载二进制安装包,如果不能用,可到<a href="https://github.com/cloudflare/cfssl/releases">GitHub下载</a></p><h4 id="1-1-安装"><a href="#1-1-安装" class="headerlink" title="1.1 安装"></a>1.1 安装</h4><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget https:<span class="hljs-regexp">//m</span>ritdftp.b0.upaiyun.com<span class="hljs-regexp">/cfssl/</span>cfssl.tar.gz<br>tar -zxvf cfssl.tar.gz<br>mv cfssl cfssljson <span class="hljs-regexp">/usr/</span>local/bin<br>chmod +x <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/bin/</span>cfssl <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/bin/</span>cfssljson<br>rm -f cfssl.tar.gz<br></code></pre></td></tr></table></figure><h4 id="1-2-生成etcd证书"><a href="#1-2-生成etcd证书" class="headerlink" title="1.2 生成etcd证书"></a>1.2 生成etcd证书</h4><p>mkdir ssl<br>cd ssl</p><h5 id="etcd-csr-json"><a href="#etcd-csr-json" class="headerlink" title="etcd-csr.json"></a>etcd-csr.json</h5><p>修改hosts相关配置为自己的ip</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>  <span class="hljs-string">&quot;key&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;algo&quot;</span>: <span class="hljs-string">&quot;rsa&quot;</span>,<br>    <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">2048</span><br>  &#125;,<br>  <span class="hljs-string">&quot;names&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-string">&quot;etcd&quot;</span>,<br>      <span class="hljs-string">&quot;OU&quot;</span>: <span class="hljs-string">&quot;etcd Security&quot;</span>,<br>      <span class="hljs-string">&quot;L&quot;</span>: <span class="hljs-string">&quot;Beijing&quot;</span>,<br>      <span class="hljs-string">&quot;ST&quot;</span>: <span class="hljs-string">&quot;Beijing&quot;</span>,<br>      <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-string">&quot;CN&quot;</span><br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;CN&quot;</span>: <span class="hljs-string">&quot;etcd&quot;</span>,<br>  <span class="hljs-string">&quot;hosts&quot;</span>: [<br>    <span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>    <span class="hljs-string">&quot;localhost&quot;</span>,<br>    <span class="hljs-string">&quot;192.168.1.61&quot;</span>,<br>    <span class="hljs-string">&quot;192.168.1.62&quot;</span>,<br>    <span class="hljs-string">&quot;192.168.1.63&quot;</span><br>  ]<br>&#125;<br><br></code></pre></td></tr></table></figure><h5 id="etcd-gencert-json"><a href="#etcd-gencert-json" class="headerlink" title="etcd-gencert.json"></a>etcd-gencert.json</h5><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>  <span class="hljs-string">&quot;signing&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;default&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;usages&quot;</span>: [<br>          <span class="hljs-string">&quot;signing&quot;</span>,<br>          <span class="hljs-string">&quot;key encipherment&quot;</span>,<br>          <span class="hljs-string">&quot;server auth&quot;</span>,<br>          <span class="hljs-string">&quot;client auth&quot;</span><br>        ],<br>        <span class="hljs-string">&quot;expiry&quot;</span>: <span class="hljs-string">&quot;87600h&quot;</span><br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="etcd-root-ca-csr-json"><a href="#etcd-root-ca-csr-json" class="headerlink" title="etcd-root-ca-csr.json"></a>etcd-root-ca-csr.json</h5><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>  <span class="hljs-string">&quot;key&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;algo&quot;</span>: <span class="hljs-string">&quot;rsa&quot;</span>,<br>    <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">4096</span><br>  &#125;,<br>  <span class="hljs-string">&quot;names&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-string">&quot;etcd&quot;</span>,<br>      <span class="hljs-string">&quot;OU&quot;</span>: <span class="hljs-string">&quot;etcd Security&quot;</span>,<br>      <span class="hljs-string">&quot;L&quot;</span>: <span class="hljs-string">&quot;Beijing&quot;</span>,<br>      <span class="hljs-string">&quot;ST&quot;</span>: <span class="hljs-string">&quot;Beijing&quot;</span>,<br>      <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-string">&quot;CN&quot;</span><br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;CN&quot;</span>: <span class="hljs-string">&quot;etcd-root-ca&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure><h5 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h5><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">cfssl gencert</span> <span class="hljs-literal">--</span><span class="hljs-comment">initca=true etcd</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-literal">-</span><span class="hljs-comment">csr</span><span class="hljs-string">.</span><span class="hljs-comment">json | cfssljson</span> <span class="hljs-literal">--</span><span class="hljs-comment">bare etcd</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><br><span class="hljs-comment">cfssl gencert</span> <span class="hljs-literal">--</span><span class="hljs-comment">ca etcd</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-string">.</span><span class="hljs-comment">pem</span> <span class="hljs-literal">--</span><span class="hljs-comment">ca</span><span class="hljs-literal">-</span><span class="hljs-comment">key etcd</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-literal">-</span><span class="hljs-comment">key</span><span class="hljs-string">.</span><span class="hljs-comment">pem</span> <span class="hljs-literal">--</span><span class="hljs-comment">config etcd</span><span class="hljs-literal">-</span><span class="hljs-comment">gencert</span><span class="hljs-string">.</span><span class="hljs-comment">json etcd</span><span class="hljs-literal">-</span><span class="hljs-comment">csr</span><span class="hljs-string">.</span><span class="hljs-comment">json | cfssljson</span> <span class="hljs-literal">--</span><span class="hljs-comment">bare etcd</span><br></code></pre></td></tr></table></figure><p>生成后结果如下<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180509144247.png!700x999"><br><br></p><h3 id="二-安装etcd"><a href="#二-安装etcd" class="headerlink" title="二 安装etcd"></a>二 安装etcd</h3><p>Etcd 这里采用最新的 3.2.18 版本，安装方式直接复制二进制文件、systemd service 配置<br>cd ~&#x2F;k8s&#x2F;<br>mkdir systemd &amp;&amp; cd systemd<br>touch etcd.service</p><h4 id="etcd-service"><a href="#etcd-service" class="headerlink" title="etcd.service"></a>etcd.service</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-section">[Unit]</span><br><span class="hljs-attr">Description</span>=Etcd Server<br><span class="hljs-attr">After</span>=network.target<br><span class="hljs-attr">After</span>=network-<span class="hljs-literal">on</span>line.target<br><span class="hljs-attr">Wants</span>=network-<span class="hljs-literal">on</span>line.target<br><br><span class="hljs-section">[Service]</span><br><span class="hljs-attr">Type</span>=notify<br><span class="hljs-attr">WorkingDirectory</span>=/var/lib/etcd/<br><span class="hljs-attr">EnvironmentFile</span>=-/etc/etcd/etcd.conf<br><span class="hljs-attr">User</span>=etcd<br><span class="hljs-comment">## set GOMAXPROCS to number of processors</span><br><span class="hljs-attr">ExecStart</span>=/bin/bash -c <span class="hljs-string">&quot;GOMAXPROCS=$(nproc) /usr/local/bin/etcd --name=\&quot;$&#123;ETCD_NAME&#125;\&quot; --data-dir=\&quot;$&#123;ETCD_DATA_DIR&#125;\&quot; --listen-client-urls=\&quot;$&#123;ETCD_LISTEN_CLIENT_URLS&#125;\&quot;&quot;</span><br><span class="hljs-attr">Restart</span>=<span class="hljs-literal">on</span>-failure<br><span class="hljs-attr">LimitNOFILE</span>=<span class="hljs-number">65536</span><br><br><span class="hljs-section">[Install]</span><br><span class="hljs-attr">WantedBy</span>=multi-user.target<br><br></code></pre></td></tr></table></figure><p>touch etcd.conf</p><h4 id="etcd-conf"><a href="#etcd-conf" class="headerlink" title="etcd.conf"></a>etcd.conf</h4><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment">## [member]</span><br><span class="hljs-attr">ETCD_NAME</span>=etcd1<br><span class="hljs-attr">ETCD_DATA_DIR</span>=<span class="hljs-string">&quot;/var/lib/etcd/etcd1.etcd&quot;</span><br><span class="hljs-attr">ETCD_WAL_DIR</span>=<span class="hljs-string">&quot;/var/lib/etcd/wal&quot;</span><br><span class="hljs-attr">ETCD_SNAPSHOT_COUNT</span>=<span class="hljs-string">&quot;100&quot;</span><br><span class="hljs-attr">ETCD_HEARTBEAT_INTERVAL</span>=<span class="hljs-string">&quot;100&quot;</span><br><span class="hljs-attr">ETCD_ELECTION_TIMEOUT</span>=<span class="hljs-string">&quot;1000&quot;</span><br><span class="hljs-attr">ETCD_LISTEN_PEER_URLS</span>=<span class="hljs-string">&quot;https://192.168.1.61:2380&quot;</span><br><span class="hljs-attr">ETCD_LISTEN_CLIENT_URLS</span>=<span class="hljs-string">&quot;https://192.168.1.61:2379,http://127.0.0.1:2379&quot;</span><br><span class="hljs-attr">ETCD_MAX_SNAPSHOTS</span>=<span class="hljs-string">&quot;5&quot;</span><br><span class="hljs-attr">ETCD_MAX_WALS</span>=<span class="hljs-string">&quot;5&quot;</span><br><span class="hljs-comment">#ETCD_CORS=&quot;&quot;</span><br><br><span class="hljs-comment">## [cluster]</span><br><span class="hljs-attr">ETCD_INITIAL_ADVERTISE_PEER_URLS</span>=<span class="hljs-string">&quot;https://192.168.1.61:2380&quot;</span><br><span class="hljs-comment">## if you use different ETCD_NAME (e.g. test), set ETCD_INITIAL_CLUSTER value for this name, i.e. &quot;test=http://...&quot;</span><br><span class="hljs-attr">ETCD_INITIAL_CLUSTER</span>=<span class="hljs-string">&quot;etcd1=https://192.168.1.61:2380,etcd2=https://192.168.1.62:2380,etcd3=https://192.168.1.63:2380&quot;</span><br><span class="hljs-attr">ETCD_INITIAL_CLUSTER_STATE</span>=<span class="hljs-string">&quot;new&quot;</span><br><span class="hljs-attr">ETCD_INITIAL_CLUSTER_TOKEN</span>=<span class="hljs-string">&quot;etcd-cluster&quot;</span><br><span class="hljs-attr">ETCD_ADVERTISE_CLIENT_URLS</span>=<span class="hljs-string">&quot;https://192.168.1.61:2379&quot;</span><br><span class="hljs-comment">#ETCD_DISCOVERY=&quot;&quot;</span><br><span class="hljs-comment">#ETCD_DISCOVERY_SRV=&quot;&quot;</span><br><span class="hljs-comment">#ETCD_DISCOVERY_FALLBACK=&quot;proxy&quot;</span><br><span class="hljs-comment">#ETCD_DISCOVERY_PROXY=&quot;&quot;</span><br><span class="hljs-comment">#ETCD_STRICT_RECONFIG_CHECK=&quot;false&quot;</span><br><span class="hljs-comment">#ETCD_AUTO_COMPACTION_RETENTION=&quot;0&quot;</span><br><br><span class="hljs-comment">## [proxy]</span><br><span class="hljs-comment">#ETCD_PROXY=&quot;off&quot;</span><br><span class="hljs-comment">#ETCD_PROXY_FAILURE_WAIT=&quot;5000&quot;</span><br><span class="hljs-comment">#ETCD_PROXY_REFRESH_INTERVAL=&quot;30000&quot;</span><br><span class="hljs-comment">#ETCD_PROXY_DIAL_TIMEOUT=&quot;1000&quot;</span><br><span class="hljs-comment">#ETCD_PROXY_WRITE_TIMEOUT=&quot;5000&quot;</span><br><span class="hljs-comment">#ETCD_PROXY_READ_TIMEOUT=&quot;0&quot;</span><br><br><span class="hljs-comment">## [security]</span><br><span class="hljs-attr">ETCD_CERT_FILE</span>=<span class="hljs-string">&quot;/etc/etcd/ssl/etcd.pem&quot;</span><br><span class="hljs-attr">ETCD_KEY_FILE</span>=<span class="hljs-string">&quot;/etc/etcd/ssl/etcd-key.pem&quot;</span><br><span class="hljs-attr">ETCD_CLIENT_CERT_AUTH</span>=<span class="hljs-string">&quot;true&quot;</span><br><span class="hljs-attr">ETCD_TRUSTED_CA_FILE</span>=<span class="hljs-string">&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;</span><br><span class="hljs-attr">ETCD_AUTO_TLS</span>=<span class="hljs-string">&quot;true&quot;</span><br><span class="hljs-attr">ETCD_PEER_CERT_FILE</span>=<span class="hljs-string">&quot;/etc/etcd/ssl/etcd.pem&quot;</span><br><span class="hljs-attr">ETCD_PEER_KEY_FILE</span>=<span class="hljs-string">&quot;/etc/etcd/ssl/etcd-key.pem&quot;</span><br><span class="hljs-attr">ETCD_PEER_CLIENT_CERT_AUTH</span>=<span class="hljs-string">&quot;true&quot;</span><br><span class="hljs-attr">ETCD_PEER_TRUSTED_CA_FILE</span>=<span class="hljs-string">&quot;/etc/etcd/ssl/etcd-root-ca.pem&quot;</span><br><span class="hljs-attr">ETCD_PEER_AUTO_TLS</span>=<span class="hljs-string">&quot;true&quot;</span><br><br><span class="hljs-comment">## [logging]</span><br><span class="hljs-comment">#ETCD_DEBUG=&quot;false&quot;</span><br><span class="hljs-comment">## examples for -log-package-levels etcdserver=WARNING,security=DEBUG</span><br><span class="hljs-comment">#ETCD_LOG_PACKAGE_LEVELS=&quot;&quot;</span><br></code></pre></td></tr></table></figure><p>touch install.sh</p><h4 id="install-sh"><a href="#install-sh" class="headerlink" title="install .sh"></a>install .sh</h4><p>这里解释下,此处下载etcd安装包,为系统添加etcd用户,并赋值etcd用户权限,安装下载来的安装包,拷贝相关证书到&#x2F;etc&#x2F;etcd&#x2F;目录中给etcd使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-built_in">set</span> -e<br><br>ETCD_VERSION=<span class="hljs-string">&quot;3.2.18&quot;</span><br><span class="hljs-comment">#下载etcd安装包</span><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">download</span></span>()&#123;<br>    <span class="hljs-keyword">if</span> [ ! -f <span class="hljs-string">&quot;etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz&quot;</span> ]; <span class="hljs-keyword">then</span><br>        wget https://github.com/coreos/etcd/releases/download/v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>/etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz<br>        tar -zxvf etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz<br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br><span class="hljs-comment">## 添加ectd相关用户和权限</span><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">preinstall</span></span>()&#123;<br>    getent group etcd &gt;/dev/null || groupadd -r etcd<br>    getent passwd etcd &gt;/dev/null || useradd -r -g etcd -d /var/lib/etcd -s /sbin/nologin -c <span class="hljs-string">&quot;etcd user&quot;</span> etcd<br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">install</span></span>()&#123;<br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Copy etcd...\033[0m&quot;</span><br>    tar -zxvf etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64.tar.gz<br>    <span class="hljs-built_in">cp</span> etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64/etcd* /usr/local/bin<br>    <span class="hljs-built_in">rm</span> -rf etcd-v<span class="hljs-variable">$&#123;ETCD_VERSION&#125;</span>-linux-amd64<br><br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Copy etcd config...\033[0m&quot;</span><br>    <span class="hljs-built_in">cp</span> -r conf /etc/etcd<br>    <span class="hljs-built_in">chown</span> -R etcd:etcd /etc/etcd<br>    <span class="hljs-built_in">chmod</span> -R 755 /etc/etcd/ssl<br><br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Copy etcd systemd config...\033[0m&quot;</span><br>    <span class="hljs-built_in">cp</span> systemd/*.service /lib/systemd/system<br>    systemctl daemon-reload<br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">postinstall</span></span>()&#123;<br>    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">&quot;/var/lib/etcd&quot;</span> ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">mkdir</span> /var/lib/etcd<br>        <span class="hljs-built_in">chown</span> -R etcd:etcd /var/lib/etcd<br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br><br>download<br>preinstall<br>install<br>postinstall<br></code></pre></td></tr></table></figure><ul><li>download : 从GitHub官网下载二进制文件并解压</li><li>preinstall : 创建etcd用户,并制定家目录登录shell,为Etcd做准备</li><li>install :  将下载来的二进制压缩包解压并复制到&#x2F;usr&#x2F;local&#x2F;bin,后到conf中的文件复制到 &#x2F;etc&#x2F;etcd</li><li>postinstall : 安装后收尾工作，比如检测 &#x2F;var&#x2F;lib&#x2F;etcd 是否存在，纠正权限等</li></ul><p>执行 .&#x2F;install.sh,得到如下结果:<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180510110948.png!700x999"></p><p><font color='red'>注意:完后install后,将etcd目录scp到每台需要安装etcd的节点,修改etcd.conf 中的相关配置(ETCD_NAME,IP等),在每个etcd再执行install.sh </font></p><h3 id="三-安装kubernetes"><a href="#三-安装kubernetes" class="headerlink" title="三 安装kubernetes"></a>三 安装kubernetes</h3><p>由于 kubelet 和 kube-proxy 用到的 kubeconfig 配置文件需要借助 kubectl 来生成，所以需要先安装一下 kubect</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget https:<span class="hljs-regexp">//</span>storage.googleapis.com<span class="hljs-regexp">/kubernetes-release/</span>release<span class="hljs-regexp">/v1.10.1/</span>bin<span class="hljs-regexp">/linux/</span>amd64/hyperkube -O hyperkube_1.<span class="hljs-number">10.1</span><br>chmod +x hyperkube_1.<span class="hljs-number">10.1</span><br>cp hyperkube_1.<span class="hljs-number">10.1</span> <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/bin/</span>hyperkube<br>ln -s <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/bin/</span>hyperkube <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/bin/</span>kubectl<br></code></pre></td></tr></table></figure><h4 id="3-1生成k8s证书"><a href="#3-1生成k8s证书" class="headerlink" title="3.1生成k8s证书"></a>3.1生成k8s证书</h4><h5 id="admin-csr-json"><a href="#admin-csr-json" class="headerlink" title="admin-csr.json"></a>admin-csr.json</h5><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>  <span class="hljs-string">&quot;CN&quot;</span>: <span class="hljs-string">&quot;admin&quot;</span>,<br>  <span class="hljs-string">&quot;hosts&quot;</span>: [],<br>  <span class="hljs-string">&quot;key&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;algo&quot;</span>: <span class="hljs-string">&quot;rsa&quot;</span>,<br>    <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">2048</span><br>  &#125;,<br>  <span class="hljs-string">&quot;names&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-string">&quot;CN&quot;</span>,<br>      <span class="hljs-string">&quot;ST&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>      <span class="hljs-string">&quot;L&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>      <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-string">&quot;system:masters&quot;</span>,<br>      <span class="hljs-string">&quot;OU&quot;</span>: <span class="hljs-string">&quot;System&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="k8s-gencert-json"><a href="#k8s-gencert-json" class="headerlink" title="k8s-gencert.json"></a>k8s-gencert.json</h5><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>  <span class="hljs-string">&quot;CN&quot;</span>: <span class="hljs-string">&quot;kubernetes&quot;</span>,<br>  <span class="hljs-string">&quot;key&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;algo&quot;</span>: <span class="hljs-string">&quot;rsa&quot;</span>,<br>    <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">4096</span><br>  &#125;,<br>  <span class="hljs-string">&quot;names&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-string">&quot;CN&quot;</span>,<br>      <span class="hljs-string">&quot;ST&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>      <span class="hljs-string">&quot;L&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>      <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-string">&quot;k8s&quot;</span>,<br>      <span class="hljs-string">&quot;OU&quot;</span>: <span class="hljs-string">&quot;System&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="kube-apiserver-csr-json"><a href="#kube-apiserver-csr-json" class="headerlink" title="kube-apiserver-csr.json"></a>kube-apiserver-csr.json</h5><p>注意修改为自己的ip,10.254.0.1这个ip我暂时不听清楚具体是啥,貌似是k8s集群里类似路由地址的东西</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>    <span class="hljs-string">&quot;CN&quot;</span>: <span class="hljs-string">&quot;kubernetes&quot;</span>,<br>    <span class="hljs-string">&quot;hosts&quot;</span>: [<br>        <span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>        <span class="hljs-string">&quot;10.254.0.1&quot;</span>,<br>        <span class="hljs-string">&quot;192.168.1.30&quot;</span>,<br>        <span class="hljs-string">&quot;192.168.1.31&quot;</span>,<br>        <span class="hljs-string">&quot;192.168.1.32&quot;</span>,<br>        <span class="hljs-string">&quot;192.168.1.33&quot;</span>,<br>        <span class="hljs-string">&quot;*.kubernetes.master&quot;</span>,<br>        <span class="hljs-string">&quot;localhost&quot;</span>,<br>        <span class="hljs-string">&quot;kubernetes&quot;</span>,<br>        <span class="hljs-string">&quot;kubernetes.default&quot;</span>,<br>        <span class="hljs-string">&quot;kubernetes.default.svc&quot;</span>,<br>        <span class="hljs-string">&quot;kubernetes.default.svc.cluster&quot;</span>,<br>        <span class="hljs-string">&quot;kubernetes.default.svc.cluster.local&quot;</span><br>    ],<br>    <span class="hljs-string">&quot;key&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;algo&quot;</span>: <span class="hljs-string">&quot;rsa&quot;</span>,<br>        <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">2048</span><br>    &#125;,<br>    <span class="hljs-string">&quot;names&quot;</span>: [<br>        &#123;<br>            <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-string">&quot;CN&quot;</span>,<br>            <span class="hljs-string">&quot;ST&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>            <span class="hljs-string">&quot;L&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>            <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-string">&quot;k8s&quot;</span>,<br>            <span class="hljs-string">&quot;OU&quot;</span>: <span class="hljs-string">&quot;System&quot;</span><br>        &#125;<br>    ]<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="kube-proxy-csr-json"><a href="#kube-proxy-csr-json" class="headerlink" title="kube-proxy-csr.json"></a>kube-proxy-csr.json</h5><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs prolog">&#123;<br>  <span class="hljs-string">&quot;CN&quot;</span>: <span class="hljs-string">&quot;system:kube-proxy&quot;</span>,<br>  <span class="hljs-string">&quot;hosts&quot;</span>: [],<br>  <span class="hljs-string">&quot;key&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;algo&quot;</span>: <span class="hljs-string">&quot;rsa&quot;</span>,<br>    <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">2048</span><br>  &#125;,<br>  <span class="hljs-string">&quot;names&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;C&quot;</span>: <span class="hljs-string">&quot;CN&quot;</span>,<br>      <span class="hljs-string">&quot;ST&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>      <span class="hljs-string">&quot;L&quot;</span>: <span class="hljs-string">&quot;BeiJing&quot;</span>,<br>      <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-string">&quot;k8s&quot;</span>,<br>      <span class="hljs-string">&quot;OU&quot;</span>: <span class="hljs-string">&quot;System&quot;</span><br>    &#125;<br>  ]<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="生成证书操作"><a href="#生成证书操作" class="headerlink" title="生成证书操作:"></a>生成证书操作:</h5><p>可将此脚本写到一个 sh中,然后执行</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-comment">## 生成 CA</span><br><span class="hljs-string">cfssl</span> <span class="hljs-string">gencert</span> <span class="hljs-built_in">--initca=true</span> <span class="hljs-string">k8s-root-ca-csr</span>.<span class="hljs-string">json</span> | <span class="hljs-string">cfssljson</span> <span class="hljs-built_in">--bare</span> <span class="hljs-string">k8s-root-ca</span><br><br><span class="hljs-comment">## 依次生成其他组件证书</span><br><span class="hljs-string">for</span> <span class="hljs-string">targetName</span> <span class="hljs-string">in</span> <span class="hljs-string">kube-apiserver</span> <span class="hljs-string">admin</span> <span class="hljs-string">kube-proxy</span>; <span class="hljs-string">do</span><br>    <span class="hljs-string">cfssl</span> <span class="hljs-string">gencert</span> <span class="hljs-built_in">--ca</span> <span class="hljs-string">k8s-root-ca</span>.<span class="hljs-string">pem</span> <span class="hljs-built_in">--ca-key</span> <span class="hljs-string">k8s-root-ca-key</span>.<span class="hljs-string">pem</span> <span class="hljs-built_in">--config</span> <span class="hljs-string">k8s-gencert</span>.<span class="hljs-string">json</span> <span class="hljs-built_in">--profile</span> <span class="hljs-string">kubernetes</span> $<span class="hljs-string">targetName-csr</span>.<span class="hljs-string">json</span> | <span class="hljs-string">cfssljson</span> <span class="hljs-built_in">--bare</span> $<span class="hljs-string">targetName</span><br><span class="hljs-string">done</span><br><br><span class="hljs-comment">## 地址默认为 127.0.0.1:6443</span><br><span class="hljs-comment">## 如果在 master 上启用 kubelet 请在生成后的 kubeconfig 中</span><br><span class="hljs-comment">## 修改该地址为 当前MASTER_IP:6443</span><br><span class="hljs-string">KUBE_APISERVER</span>=<span class="hljs-string">&quot;https://127.0.0.1:6443&quot;</span><br><span class="hljs-string">BOOTSTRAP_TOKEN</span>=$(<span class="hljs-string">head</span> -<span class="hljs-string">c</span> <span class="hljs-string">16</span> /<span class="hljs-string">dev</span>/<span class="hljs-string">urandom</span> | <span class="hljs-string">od</span> -<span class="hljs-string">An</span> -<span class="hljs-string">t</span> <span class="hljs-string">x</span> | <span class="hljs-string">tr</span> -<span class="hljs-string">d</span> <span class="hljs-string">&#x27; &#x27;</span>)<br><span class="hljs-string">echo</span> <span class="hljs-string">&quot;Tokne: $&#123;BOOTSTRAP_TOKEN&#125;&quot;</span><br><br><span class="hljs-comment">## 不要质疑 system:bootstrappers 用户组是否写错了，有疑问请参考官方文档</span><br><span class="hljs-comment">## https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/</span><br><span class="hljs-string">cat</span> &gt; <span class="hljs-string">token</span>.<span class="hljs-string">csv</span> &lt;&lt;<span class="hljs-string">EOF</span><br>$&#123;<span class="hljs-string">BOOTSTRAP_TOKEN</span>&#125;,<span class="hljs-string">kubelet-bootstrap</span>,<span class="hljs-string">10001</span>,<span class="hljs-string">&quot;system:bootstrappers&quot;</span><br><span class="hljs-string">EOF</span><br><br><span class="hljs-string">echo</span> <span class="hljs-string">&quot;Create kubelet bootstrapping kubeconfig...&quot;</span><br><span class="hljs-comment">## 设置集群参数</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-built_in">set-cluster</span> <span class="hljs-string">kubernetes</span> \<br>  <span class="hljs-built_in">--certificate-authority=k8s-root-ca.pem</span> \<br>  <span class="hljs-built_in">--embed-certs=true</span> \<br>  <span class="hljs-built_in">--server=$&#123;KUBE_APISERVER&#125;</span> \<br>  <span class="hljs-built_in">--kubeconfig=bootstrap.kubeconfig</span><br><span class="hljs-comment">## 设置客户端认证参数</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-built_in">set-credentials</span> <span class="hljs-string">kubelet-bootstrap</span> \<br>  <span class="hljs-built_in">--token=$&#123;BOOTSTRAP_TOKEN&#125;</span> \<br>  <span class="hljs-built_in">--kubeconfig=bootstrap.kubeconfig</span><br><span class="hljs-comment">## 设置上下文参数</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-built_in">set-context</span> <span class="hljs-string">default</span> \<br>  <span class="hljs-built_in">--cluster=kubernetes</span> \<br>  <span class="hljs-built_in">--user=kubelet-bootstrap</span> \<br>  <span class="hljs-built_in">--kubeconfig=bootstrap.kubeconfig</span><br><span class="hljs-comment">## 设置默认上下文</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-string">use-context</span> <span class="hljs-string">default</span> <span class="hljs-built_in">--kubeconfig=bootstrap.kubeconfig</span><br><br><span class="hljs-string">echo</span> <span class="hljs-string">&quot;Create kube-proxy kubeconfig...&quot;</span><br><span class="hljs-comment">## 设置集群参数</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-built_in">set-cluster</span> <span class="hljs-string">kubernetes</span> \<br>  <span class="hljs-built_in">--certificate-authority=k8s-root-ca.pem</span> \<br>  <span class="hljs-built_in">--embed-certs=true</span> \<br>  <span class="hljs-built_in">--server=$&#123;KUBE_APISERVER&#125;</span> \<br>  <span class="hljs-built_in">--kubeconfig=kube-proxy.kubeconfig</span><br><span class="hljs-comment">## 设置客户端认证参数</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-built_in">set-credentials</span> <span class="hljs-string">kube-proxy</span> \<br>  <span class="hljs-built_in">--client-certificate=kube-proxy.pem</span> \<br>  <span class="hljs-built_in">--client-key=kube-proxy-key.pem</span> \<br>  <span class="hljs-built_in">--embed-certs=true</span> \<br>  <span class="hljs-built_in">--kubeconfig=kube-proxy.kubeconfig</span><br><span class="hljs-comment">## 设置上下文参数</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-built_in">set-context</span> <span class="hljs-string">default</span> \<br>  <span class="hljs-built_in">--cluster=kubernetes</span> \<br>  <span class="hljs-built_in">--user=kube-proxy</span> \<br>  <span class="hljs-built_in">--kubeconfig=kube-proxy.kubeconfig</span><br><span class="hljs-comment">## 设置默认上下文</span><br><span class="hljs-string">kubectl</span> <span class="hljs-string">config</span> <span class="hljs-string">use-context</span> <span class="hljs-string">default</span> <span class="hljs-built_in">--kubeconfig=kube-proxy.kubeconfig</span><br><br><span class="hljs-comment">## 创建高级审计配置</span><br><span class="hljs-string">cat</span> &gt;&gt; <span class="hljs-string">audit-policy</span>.<span class="hljs-string">yaml</span> &lt;&lt;<span class="hljs-string">EOF</span><br><span class="hljs-comment">## Log all requests at the Metadata level.</span><br><span class="hljs-string">apiVersion</span>: <span class="hljs-string">audit</span>.<span class="hljs-string">k8s</span>.<span class="hljs-string">io</span>/<span class="hljs-string">v1beta1</span><br><span class="hljs-string">kind</span>: <span class="hljs-string">Policy</span><br><span class="hljs-string">rules</span>:<br>- <span class="hljs-string">level</span>: <span class="hljs-string">Metadata</span><br><span class="hljs-string">EOF</span><br></code></pre></td></tr></table></figure><p>生成完成后如下截图:<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180510112658.png!700x999"></p><h4 id="3-2配置systemd"><a href="#3-2配置systemd" class="headerlink" title="3.2配置systemd"></a>3.2配置systemd</h4><p>安装k8s都是用二进制文件的,所以需要手动创建systemd</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> k8s &amp;&amp; <span class="hljs-built_in">mkdir</span> systemd  &amp;&amp; <span class="hljs-built_in">cd</span> systemd<br></code></pre></td></tr></table></figure><p>如果已经创建了这个目录就不需要了</p><h5 id="vim-kube-apiserver-service"><a href="#vim-kube-apiserver-service" class="headerlink" title="vim kube-apiserver.service"></a>vim kube-apiserver.service</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[Unit]<br><span class="hljs-attribute">Description</span>=Kubernetes API<span class="hljs-built_in"> Server</span><br><span class="hljs-built_in"></span><span class="hljs-attribute">Documentation</span>=https://github.com/GoogleCloudPlatform/kubernetes<br><span class="hljs-attribute">After</span>=network.target<br><span class="hljs-attribute">After</span>=etcd.service<br><br>[Service]<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/config<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/apiserver<br><span class="hljs-attribute">User</span>=kube<br><span class="hljs-attribute">ExecStart</span>=/usr/local/bin/hyperkube apiserver \<br>            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \<br>            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \<br>            <span class="hljs-variable">$KUBE_ETCD_SERVERS</span> \<br>            <span class="hljs-variable">$KUBE_API_ADDRESS</span> \<br>            <span class="hljs-variable">$KUBE_API_PORT</span> \<br>            <span class="hljs-variable">$KUBELET_PORT</span> \<br>            <span class="hljs-variable">$KUBE_ALLOW_PRIV</span> \<br>            <span class="hljs-variable">$KUBE_SERVICE_ADDRESSES</span> \<br>            <span class="hljs-variable">$KUBE_ADMISSION_CONTROL</span> \<br>            <span class="hljs-variable">$KUBE_API_ARGS</span><br><span class="hljs-attribute">Restart</span>=on-failure<br><span class="hljs-attribute">Type</span>=notify<br><span class="hljs-attribute">LimitNOFILE</span>=65536<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br></code></pre></td></tr></table></figure><h5 id="vim-kube-controller-manager-service"><a href="#vim-kube-controller-manager-service" class="headerlink" title="vim kube-controller-manager.service"></a>vim kube-controller-manager.service</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[Unit]<br><span class="hljs-attribute">Description</span>=Kubernetes Controller Manager<br><span class="hljs-attribute">Documentation</span>=https://github.com/GoogleCloudPlatform/kubernetes<br><br>[Service]<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/config<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/controller-manager<br><span class="hljs-attribute">User</span>=kube<br><span class="hljs-attribute">ExecStart</span>=/usr/local/bin/hyperkube controller-manager \<br>            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \<br>            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \<br>            <span class="hljs-variable">$KUBE_MASTER</span> \<br>            <span class="hljs-variable">$KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="hljs-attribute">Restart</span>=on-failure<br><span class="hljs-attribute">LimitNOFILE</span>=65536<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br></code></pre></td></tr></table></figure><h5 id="vim-kubelet-service"><a href="#vim-kubelet-service" class="headerlink" title="vim kubelet.service"></a>vim kubelet.service</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[Unit]<br><span class="hljs-attribute">Description</span>=Kubernetes Kubelet<span class="hljs-built_in"> Server</span><br><span class="hljs-built_in"></span><span class="hljs-attribute">Documentation</span>=https://github.com/GoogleCloudPlatform/kubernetes<br><span class="hljs-attribute">After</span>=docker.service<br><span class="hljs-attribute">Requires</span>=docker.service<br><br>[Service]<br><span class="hljs-attribute">WorkingDirectory</span>=/var/lib/kubelet<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/config<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/kubelet<br><span class="hljs-attribute">ExecStart</span>=/usr/local/bin/hyperkube kubelet \<br>            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \<br>            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \<br>            <span class="hljs-variable">$KUBELET_API_SERVER</span> \<br>            <span class="hljs-variable">$KUBELET_ADDRESS</span> \<br>            <span class="hljs-variable">$KUBELET_PORT</span> \<br>            <span class="hljs-variable">$KUBELET_HOSTNAME</span> \<br>            <span class="hljs-variable">$KUBE_ALLOW_PRIV</span> \<br>            <span class="hljs-variable">$KUBELET_ARGS</span><br><span class="hljs-attribute">Restart</span>=on-failure<br><span class="hljs-attribute">KillMode</span>=process<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br><br></code></pre></td></tr></table></figure><h5 id="vim-kube-proxy-service"><a href="#vim-kube-proxy-service" class="headerlink" title="vim kube-proxy.service"></a>vim kube-proxy.service</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[Unit]<br><span class="hljs-attribute">Description</span>=Kubernetes Kube-Proxy<span class="hljs-built_in"> Server</span><br><span class="hljs-built_in"></span><span class="hljs-attribute">Documentation</span>=https://github.com/GoogleCloudPlatform/kubernetes<br><span class="hljs-attribute">After</span>=network.target<br><br>[Service]<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/config<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/proxy<br><span class="hljs-attribute">ExecStart</span>=/usr/local/bin/hyperkube<span class="hljs-built_in"> proxy </span>\<br>            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \<br>            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \<br>            <span class="hljs-variable">$KUBE_MASTER</span> \<br>            <span class="hljs-variable">$KUBE_PROXY_ARGS</span><br><span class="hljs-attribute">Restart</span>=on-failure<br><span class="hljs-attribute">LimitNOFILE</span>=65536<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br></code></pre></td></tr></table></figure><h5 id="vim-kube-scheduler-service"><a href="#vim-kube-scheduler-service" class="headerlink" title="vim kube-scheduler.service"></a>vim kube-scheduler.service</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[Unit]<br><span class="hljs-attribute">Description</span>=Kubernetes<span class="hljs-built_in"> Scheduler </span>Plugin<br><span class="hljs-attribute">Documentation</span>=https://github.com/GoogleCloudPlatform/kubernetes<br><br>[Service]<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/config<br><span class="hljs-attribute">EnvironmentFile</span>=-/etc/kubernetes/scheduler<br><span class="hljs-attribute">User</span>=kube<br><span class="hljs-attribute">ExecStart</span>=/usr/local/bin/hyperkube<span class="hljs-built_in"> scheduler </span>\<br>            <span class="hljs-variable">$KUBE_LOGTOSTDERR</span> \<br>            <span class="hljs-variable">$KUBE_LOG_LEVEL</span> \<br>            <span class="hljs-variable">$KUBE_MASTER</span> \<br>            <span class="hljs-variable">$KUBE_SCHEDULER_ARGS</span><br><span class="hljs-attribute">Restart</span>=on-failure<br><span class="hljs-attribute">LimitNOFILE</span>=65536<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br></code></pre></td></tr></table></figure><p>至此 systemd创建完成,后续通过脚本会将此此目录中是的文件 copy到系统的systemd目录中的<br><br>返回上层目录,回到k8s目录,继续创建相关配置</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">## cd .. &amp;&amp; pwd</span><br><span class="hljs-regexp">/root/</span>k8s<br></code></pre></td></tr></table></figure><h4 id="3-3k8s-配置master节点"><a href="#3-3k8s-配置master节点" class="headerlink" title="3.3k8s-配置master节点"></a>3.3k8s-配置master节点</h4><p>&#x2F;root&#x2F;k8s目录下进行<br><br>Master 节点主要会运行 3 各组件: kube-apiserver、kube-controller-manager、kube-scheduler，其中用到的配置文件如下</p><h5 id="config"><a href="#config" class="headerlink" title="config"></a>config</h5><p>config 是一个通用配置文件，值得注意的是由于安装时对于 Node、Master 节点都会包含该文件，在 Node 节点上请注释掉 KUBE_MASTER 变量，因为 Node 节点需要做 HA，要连接本地的 6443 加密端口；而这个变量将会覆盖 kubeconfig 中指定的 127.0.0.1:6443 地址</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs clean">###<br>## kubernetes <span class="hljs-keyword">system</span> config<br>#<br>## The following values are used to configure various aspects <span class="hljs-keyword">of</span> all<br>## kubernetes services, including<br>#<br>##   kube-apiserver.service<br>##   kube-controller-manager.service<br>##   kube-scheduler.service<br>##   kubelet.service<br>##   kube-proxy.service<br>## logging to stderr means we get it <span class="hljs-keyword">in</span> the systemd journal<br>KUBE_LOGTOSTDERR=<span class="hljs-string">&quot;--logtostderr=true&quot;</span><br><br>## journal message level, <span class="hljs-number">0</span> is debug<br>KUBE_LOG_LEVEL=<span class="hljs-string">&quot;--v=2&quot;</span><br><br>## Should this cluster be allowed to run privileged docker containers<br>KUBE_ALLOW_PRIV=<span class="hljs-string">&quot;--allow-privileged=true&quot;</span><br><br>## How the controller-manager, scheduler, and proxy find the apiserver<br>KUBE_MASTER=<span class="hljs-string">&quot;--master=http://127.0.0.1:8080&quot;</span><br><br></code></pre></td></tr></table></figure><h5 id="apiserver"><a href="#apiserver" class="headerlink" title="apiserver"></a>apiserver</h5><p>apiserver 配置相对于 1.8 略有变动，其中准入控制器(admission control)选项名称变为了 –enable-admission-plugins，控制器列表也有相应变化，这里采用官方推荐配置，具体请参考 <a href="https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use">官方文档</a><br><br>注意,此处直接复制了mritd的文档.其中ip需要改为自己的</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment">###</span><br><span class="hljs-comment">## kubernetes system config</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">## The following values are used to configure the kube-apiserver</span><br><span class="hljs-comment">#</span><br><br><span class="hljs-comment">## The address on the local server to listen to.</span><br><span class="hljs-attr">KUBE_API_ADDRESS</span>=<span class="hljs-string">&quot;--advertise-address=192.168.1.61 --bind-address=192.168.1.61&quot;</span><br><br><span class="hljs-comment">## The port on the local server to listen on.</span><br><span class="hljs-attr">KUBE_API_PORT</span>=<span class="hljs-string">&quot;--secure-port=6443&quot;</span><br><br><span class="hljs-comment">## Port minions listen on</span><br><span class="hljs-comment">## KUBELET_PORT=&quot;--kubelet-port=10250&quot;</span><br><br><span class="hljs-comment">## Comma separated list of nodes in the etcd cluster</span><br><span class="hljs-attr">KUBE_ETCD_SERVERS</span>=<span class="hljs-string">&quot;--etcd-servers=https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379&quot;</span><br><br><span class="hljs-comment">## Address range to use for services</span><br><span class="hljs-attr">KUBE_SERVICE_ADDRESSES</span>=<span class="hljs-string">&quot;--service-cluster-ip-range=10.254.0.0/16&quot;</span><br><br><span class="hljs-comment">## default admission control policies</span><br><span class="hljs-attr">KUBE_ADMISSION_CONTROL</span>=<span class="hljs-string">&quot;--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction&quot;</span><br><br><span class="hljs-comment">## Add your own!</span><br><span class="hljs-attr">KUBE_API_ARGS</span>=<span class="hljs-string">&quot; --anonymous-auth=false \</span><br><span class="hljs-string">                --apiserver-count=3 \</span><br><span class="hljs-string">                --audit-log-maxage=30 \</span><br><span class="hljs-string">                --audit-log-maxbackup=3 \</span><br><span class="hljs-string">                --audit-log-maxsize=100 \</span><br><span class="hljs-string">                --audit-log-path=/var/log/kube-audit/audit.log \</span><br><span class="hljs-string">                --audit-policy-file=/etc/kubernetes/audit-policy.yaml \</span><br><span class="hljs-string">                --authorization-mode=Node,RBAC \</span><br><span class="hljs-string">                --client-ca-file=/etc/kubernetes/ssl/k8s-root-ca.pem \</span><br><span class="hljs-string">                --enable-bootstrap-token-auth \</span><br><span class="hljs-string">                --enable-garbage-collector \</span><br><span class="hljs-string">                --enable-logs-handler \</span><br><span class="hljs-string">                --enable-swagger-ui \</span><br><span class="hljs-string">                --etcd-cafile=/etc/etcd/ssl/etcd-root-ca.pem \</span><br><span class="hljs-string">                --etcd-certfile=/etc/etcd/ssl/etcd.pem \</span><br><span class="hljs-string">                --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem \</span><br><span class="hljs-string">                --etcd-compaction-interval=5m0s \</span><br><span class="hljs-string">                --etcd-count-metric-poll-period=1m0s \</span><br><span class="hljs-string">                --event-ttl=48h0m0s \</span><br><span class="hljs-string">                --kubelet-https=true \</span><br><span class="hljs-string">                --kubelet-timeout=3s \</span><br><span class="hljs-string">                --log-flush-frequency=5s \</span><br><span class="hljs-string">                --token-auth-file=/etc/kubernetes/token.csv \</span><br><span class="hljs-string">                --tls-cert-file=/etc/kubernetes/ssl/kube-apiserver.pem \</span><br><span class="hljs-string">                --tls-private-key-file=/etc/kubernetes/ssl/kube-apiserver-key.pem \</span><br><span class="hljs-string">                --service-node-port-range=30000-50000 \</span><br><span class="hljs-string">                --service-account-key-file=/etc/kubernetes/ssl/k8s-root-ca.pem \</span><br><span class="hljs-string">                --storage-backend=etcd3 \</span><br><span class="hljs-string">                --enable-swagger-ui=true&quot;</span><br></code></pre></td></tr></table></figure><h5 id="controller-manager"><a href="#controller-manager" class="headerlink" title="controller-manager"></a>controller-manager</h5><p>controller manager 配置默认开启了证书轮换能力用于自动签署 kueblet 证书，并且证书时间也设置了 10 年，可自行调整；增加了 –controllers 选项以指定开启全部控制器</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">###</span><br><span class="hljs-comment">## The following values are used to configure the kubernetes controller</span><span class="hljs-literal">-</span><span class="hljs-comment">manager</span><br><br><span class="hljs-comment">## defaults from config and apiserver should be adequate</span><br><br><span class="hljs-comment">## Add your own!</span><br><span class="hljs-comment">KUBE_CONTROLLER_MANAGER_ARGS=&quot;</span>  <span class="hljs-literal">--</span><span class="hljs-comment">bind</span><span class="hljs-literal">-</span><span class="hljs-comment">address=0</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">0 \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">cluster</span><span class="hljs-literal">-</span><span class="hljs-comment">name=kubernetes \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">cluster</span><span class="hljs-literal">-</span><span class="hljs-comment">signing</span><span class="hljs-literal">-</span><span class="hljs-comment">cert</span><span class="hljs-literal">-</span><span class="hljs-comment">file=/etc/kubernetes/ssl/k8s</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-string">.</span><span class="hljs-comment">pem \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">cluster</span><span class="hljs-literal">-</span><span class="hljs-comment">signing</span><span class="hljs-literal">-</span><span class="hljs-comment">key</span><span class="hljs-literal">-</span><span class="hljs-comment">file=/etc/kubernetes/ssl/k8s</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-literal">-</span><span class="hljs-comment">key</span><span class="hljs-string">.</span><span class="hljs-comment">pem \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">controllers=*</span><span class="hljs-string">,</span><span class="hljs-comment">bootstrapsigner</span><span class="hljs-string">,</span><span class="hljs-comment">tokencleaner \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">deployment</span><span class="hljs-literal">-</span><span class="hljs-comment">controller</span><span class="hljs-literal">-</span><span class="hljs-comment">sync</span><span class="hljs-literal">-</span><span class="hljs-comment">period=10s \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">experimental</span><span class="hljs-literal">-</span><span class="hljs-comment">cluster</span><span class="hljs-literal">-</span><span class="hljs-comment">signing</span><span class="hljs-literal">-</span><span class="hljs-comment">duration=86700h0m0s \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">leader</span><span class="hljs-literal">-</span><span class="hljs-comment">elect=true \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">node</span><span class="hljs-literal">-</span><span class="hljs-comment">monitor</span><span class="hljs-literal">-</span><span class="hljs-comment">grace</span><span class="hljs-literal">-</span><span class="hljs-comment">period=40s \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">node</span><span class="hljs-literal">-</span><span class="hljs-comment">monitor</span><span class="hljs-literal">-</span><span class="hljs-comment">period=5s \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">pod</span><span class="hljs-literal">-</span><span class="hljs-comment">eviction</span><span class="hljs-literal">-</span><span class="hljs-comment">timeout=5m0s \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">terminated</span><span class="hljs-literal">-</span><span class="hljs-comment">pod</span><span class="hljs-literal">-</span><span class="hljs-comment">gc</span><span class="hljs-literal">-</span><span class="hljs-comment">threshold=50 \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-literal">-</span><span class="hljs-comment">file=/etc/kubernetes/ssl/k8s</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-string">.</span><span class="hljs-comment">pem \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">service</span><span class="hljs-literal">-</span><span class="hljs-comment">account</span><span class="hljs-literal">-</span><span class="hljs-comment">private</span><span class="hljs-literal">-</span><span class="hljs-comment">key</span><span class="hljs-literal">-</span><span class="hljs-comment">file=/etc/kubernetes/ssl/k8s</span><span class="hljs-literal">-</span><span class="hljs-comment">root</span><span class="hljs-literal">-</span><span class="hljs-comment">ca</span><span class="hljs-literal">-</span><span class="hljs-comment">key</span><span class="hljs-string">.</span><span class="hljs-comment">pem \</span><br>                                <span class="hljs-literal">--</span><span class="hljs-comment">feature</span><span class="hljs-literal">-</span><span class="hljs-comment">gates=RotateKubeletServerCertificate=true&quot;</span><br></code></pre></td></tr></table></figure><h5 id="scheduler"><a href="#scheduler" class="headerlink" title="scheduler"></a>scheduler</h5><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs clean">###<br>## kubernetes scheduler config<br><br>## default config should be adequate<br><br>## Add your own!<br>KUBE_SCHEDULER_ARGS=<span class="hljs-string">&quot;   --address=0.0.0.0 \</span><br><span class="hljs-string">                        --leader-elect=true \</span><br><span class="hljs-string">                        --algorithm-provider=DefaultProvider&quot;</span><br></code></pre></td></tr></table></figure><h4 id="3-4k8s-配置node节点"><a href="#3-4k8s-配置node节点" class="headerlink" title="3.4k8s-配置node节点"></a>3.4k8s-配置node节点</h4><p>Node 节点上主要有 kubelet、kube-proxy 组件，用到的配置如下</p><h5 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h5><p>kubeket 默认也开启了证书轮换能力以保证自动续签相关证书，同时增加了 –node-labels 选项为 node 打一个标签，关于这个标签最后部分会有讨论，如果在 master 上启动 kubelet，请将 node-role.kubernetes.io&#x2F;k8s-node&#x3D;true 修改为 node-role.kubernetes.io&#x2F;k8s-master&#x3D;true</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs clean">###<br>## kubernetes kubelet (minion) config<br><br>## The address for the info server to serve on (set to <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> or <span class="hljs-string">&quot;&quot;</span> for all interfaces)<br>KUBELET_ADDRESS=<span class="hljs-string">&quot;--node-ip=192.168.1.61&quot;</span><br><br>## The port for the info server to serve on<br>## KUBELET_PORT=<span class="hljs-string">&quot;--port=10250&quot;</span><br><br>## You may leave this blank to use the actual hostname<br>KUBELET_HOSTNAME=<span class="hljs-string">&quot;--hostname-override=k1.node&quot;</span><br><br>## location <span class="hljs-keyword">of</span> the api-server<br>## KUBELET_API_SERVER=<span class="hljs-string">&quot;&quot;</span><br><br>## Add your own!<br>KUBELET_ARGS=<span class="hljs-string">&quot;  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \</span><br><span class="hljs-string">                --cert-dir=/etc/kubernetes/ssl \</span><br><span class="hljs-string">                --cgroup-driver=cgroupfs \</span><br><span class="hljs-string">                --cluster-dns=10.254.0.2 \</span><br><span class="hljs-string">                --cluster-domain=cluster.local. \</span><br><span class="hljs-string">                --fail-swap-on=false \</span><br><span class="hljs-string">                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \</span><br><span class="hljs-string">                --node-labels=node-role.kubernetes.io/k8s-node=true \</span><br><span class="hljs-string">                --image-gc-high-threshold=70 \</span><br><span class="hljs-string">                --image-gc-low-threshold=50 \</span><br><span class="hljs-string">                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \</span><br><span class="hljs-string">                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="hljs-string">                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \</span><br><span class="hljs-string">                --serialize-image-pulls=false \</span><br><span class="hljs-string">                --sync-frequency=30s \</span><br><span class="hljs-string">                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \</span><br><span class="hljs-string">                --resolv-conf=/etc/resolv.conf \</span><br><span class="hljs-string">                --rotate-certificates&quot;</span><br></code></pre></td></tr></table></figure><h5 id="proxy"><a href="#proxy" class="headerlink" title="proxy"></a>proxy</h5><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs clean">###<br>## kubernetes proxy config<br>## default config should be adequate<br>## Add your own!<br>KUBE_PROXY_ARGS=<span class="hljs-string">&quot;--bind-address=0.0.0.0 \</span><br><span class="hljs-string">                 --hostname-override=k1.node \</span><br><span class="hljs-string">                 --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \</span><br><span class="hljs-string">                 --cluster-cidr=10.254.0.0/16&quot;</span><br><br></code></pre></td></tr></table></figure><h5 id="安装集群组件"><a href="#安装集群组件" class="headerlink" title="安装集群组件"></a>安装集群组件</h5><p>完成上述后,会得到如下一个目录结构(需要保证这个目录结构,才能使用接下来的安装脚本)</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs stylus">k8s<br>├── conf<br>│   ├── apiserver<br>│   ├── audit-policy<span class="hljs-selector-class">.yaml</span><br>│   ├── bootstrap<span class="hljs-selector-class">.kubeconfig</span><br>│   ├── config<br>│   ├── controller-manager<br>│   ├── kubelet<br>│   ├── kube-proxy<span class="hljs-selector-class">.kubeconfig</span><br>│   ├── proxy<br>│   ├── scheduler<br>│   ├── ssl<br>│   │   ├── admin<span class="hljs-selector-class">.csr</span><br>│   │   ├── admin-csr<span class="hljs-selector-class">.json</span><br>│   │   ├── admin-key<span class="hljs-selector-class">.pem</span><br>│   │   ├── admin<span class="hljs-selector-class">.pem</span><br>│   │   ├── k8s-gencert<span class="hljs-selector-class">.json</span><br>│   │   ├── k8s-root-ca<span class="hljs-selector-class">.csr</span><br>│   │   ├── k8s-root-ca-csr<span class="hljs-selector-class">.json</span><br>│   │   ├── k8s-root-ca-key<span class="hljs-selector-class">.pem</span><br>│   │   ├── k8s-root-ca<span class="hljs-selector-class">.pem</span><br>│   │   ├── kube-apiserver<span class="hljs-selector-class">.csr</span><br>│   │   ├── kube-apiserver-csr<span class="hljs-selector-class">.json</span><br>│   │   ├── kube-apiserver-key<span class="hljs-selector-class">.pem</span><br>│   │   ├── kube-apiserver<span class="hljs-selector-class">.pem</span><br>│   │   ├── kube-proxy<span class="hljs-selector-class">.csr</span><br>│   │   ├── kube-proxy-csr<span class="hljs-selector-class">.json</span><br>│   │   ├── kube-proxy-key<span class="hljs-selector-class">.pem</span><br>│   │   └── kube-proxy<span class="hljs-selector-class">.pem</span><br>│   └── token<span class="hljs-selector-class">.csv</span><br>├── hyperkube_1.<span class="hljs-number">10.1</span><br>├── install<span class="hljs-selector-class">.sh</span><br>└── systemd<br>    ├── kube-apiserver<span class="hljs-selector-class">.service</span><br>    ├── kube-controller-manager<span class="hljs-selector-class">.service</span><br>    ├── kubelet<span class="hljs-selector-class">.service</span><br>    ├── kube-proxy<span class="hljs-selector-class">.service</span><br>    └── kube-scheduler<span class="hljs-selector-class">.service</span><br><br></code></pre></td></tr></table></figure><h5 id="install-sh-1"><a href="#install-sh-1" class="headerlink" title="install.sh"></a>install.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-built_in">set</span> -e<br><br>KUBE_VERSION=<span class="hljs-string">&quot;1.10.1&quot;</span><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">download_k8s</span></span>()&#123;<br>    <span class="hljs-keyword">if</span> [ ! -f <span class="hljs-string">&quot;hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span>&quot;</span> ]; <span class="hljs-keyword">then</span><br>        wget https://storage.googleapis.com/kubernetes-release/release/v<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span>/bin/linux/amd64/hyperkube -O hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span><br>        <span class="hljs-built_in">chmod</span> +x hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span><br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">preinstall</span></span>()&#123;<br>    getent group kube &gt;/dev/null || groupadd -r kube<br>    getent passwd kube &gt;/dev/null || useradd -r -g kube -d / -s /sbin/nologin -c <span class="hljs-string">&quot;Kubernetes user&quot;</span> kube<br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">install_k8s</span></span>()&#123;<br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Copy hyperkube...\033[0m&quot;</span><br>    <span class="hljs-built_in">cp</span> hyperkube_<span class="hljs-variable">$&#123;KUBE_VERSION&#125;</span> /usr/local/bin/hyperkube<br><br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Create symbolic link...\033[0m&quot;</span><br>    <span class="hljs-built_in">ln</span> -sf /usr/local/bin/hyperkube /usr/local/bin/kubectl<br><br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Copy kubernetes config...\033[0m&quot;</span><br>    <span class="hljs-built_in">cp</span> -r conf /etc/kubernetes<br>    <span class="hljs-keyword">if</span> [ -d <span class="hljs-string">&quot;/etc/kubernetes/ssl&quot;</span> ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">chown</span> -R kube:kube /etc/kubernetes/ssl<br>    <span class="hljs-keyword">fi</span><br><br>    <span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\033[32mINFO: Copy kubernetes systemd config...\033[0m&quot;</span><br>    <span class="hljs-built_in">cp</span> systemd/*.service /lib/systemd/system<br>    systemctl daemon-reload<br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">postinstall</span></span>()&#123;<br>    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">&quot;/var/log/kube-audit&quot;</span> ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">mkdir</span> /var/log/kube-audit<br>    <span class="hljs-keyword">fi</span><br><br>    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">&quot;/var/lib/kubelet&quot;</span> ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">mkdir</span> /var/lib/kubelet<br>    <span class="hljs-keyword">fi</span><br><br>    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-string">&quot;/usr/libexec&quot;</span> ]; <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">mkdir</span> /usr/libexec<br>    <span class="hljs-keyword">fi</span><br>    <span class="hljs-built_in">chown</span> -R kube:kube /var/log/kube-audit /var/lib/kubelet /usr/libexec<br>&#125;<br><br><br>download_k8s<br>preinstall<br>install_k8s<br>postinstall<br></code></pre></td></tr></table></figure><ul><li>脚本解释如下:<blockquote><p>download_k8s: 下载 hyperkube 二进制文件<br>preinstall: 安装前处理，同 etcd 一样创建 kube 普通用户指定家目录、shell 等<br>install_k8s: 复制 hyperkube 到安装目录，为 kubectl 创建软连接(为啥创建软连接就能执行请自行阅读 源码)，复制相关配置到对应目录，并处理权限<br>postinstall: 收尾工作，创建日志目录等，并处理权限</p></blockquote></li></ul><p><font color='red'> <h5>最后执行此脚本安装即可，将k8s目录scp到每个节点 执行install.sh 此外，应确保每个节点安装了 ipset、conntrack 两个包，因为 kube-proxy 组件会使用其处理 iptables 规则等</h5></font></p><h3 id="四-启动集群"><a href="#四-启动集群" class="headerlink" title="四 启动集群"></a>四 启动集群</h3><h4 id="4-1-启动master"><a href="#4-1-启动master" class="headerlink" title="4.1 启动master"></a>4.1 启动master</h4><p>对于 master 节点启动无需做过多处理，多个 master 只要保证 apiserver 等配置中的 ip 地址监听没问题后直接启动即可</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nsis"><span class="hljs-params">system</span>ctl daemon-reload<br><span class="hljs-params">system</span>ctl start kube-apiserver<br><span class="hljs-params">system</span>ctl start kube-controller-manager<br><span class="hljs-params">system</span>ctl start kube-scheduler<br><span class="hljs-params">system</span>ctl enable kube-apiserver<br><span class="hljs-params">system</span>ctl enable kube-controller-manager<br><span class="hljs-params">system</span>ctl enable kube-scheduler<br></code></pre></td></tr></table></figure><h4 id="4-2-启动node"><a href="#4-2-启动node" class="headerlink" title="4.2 启动node"></a>4.2 启动node</h4><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nsis"><span class="hljs-params">system</span>ctl daemon-reload<br><span class="hljs-params">system</span>ctl start kubelet<br><span class="hljs-params">system</span>ctl start kube-proxy<br><span class="hljs-params">system</span>ctl enable kubelet<br><span class="hljs-params">system</span>ctl enable kube-proxy<br></code></pre></td></tr></table></figure><p>其中,如果master也需要跑任务的话, kubelet 和 kube-proxy 也需要在master节点启动<br></p><p>启动完后如图<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180510114912.png!700x999"></p><h3 id="五-配置集群网络相关"><a href="#五-配置集群网络相关" class="headerlink" title="五 配置集群网络相关"></a>五 配置集群网络相关</h3><p>由于 HA 等功能需要，对于 Node 需要做一些处理才能启动，主要有以下两个地方需要处理</p><h4 id="5-1-nginx-proxy"><a href="#5-1-nginx-proxy" class="headerlink" title="5.1 nginx-proxy"></a>5.1 nginx-proxy</h4><p>在启动 kubelet、kube-proxy 服务之前，需要在本地启动 nginx 来 tcp 负载均衡 apiserver 6443 端口，nginx-proxy 使用 docker + systemd 启动，配置如下<br><br>注意: 对于在 master 节点启动 kubelet 来说，不需要 nginx 做负载均衡；可以跳过此步骤，并修改 kubelet.kubeconfig、kube-proxy.kubeconfig 中的 apiserver 地址为当前 master ip 6443 端口即可</p><h5 id="nginx-proxy-service"><a href="#nginx-proxy-service" class="headerlink" title="nginx-proxy.service"></a>nginx-proxy.service</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[Unit]<br><span class="hljs-attribute">Description</span>=kubernetes apiserver docker wrapper<br><span class="hljs-attribute">Wants</span>=docker.socket<br><span class="hljs-attribute">After</span>=docker.service<br><br>[Service]<br><span class="hljs-attribute">User</span>=root<br><span class="hljs-attribute">PermissionsStartOnly</span>=<span class="hljs-literal">true</span><br><span class="hljs-attribute">ExecStart</span>=/usr/bin/docker <span class="hljs-built_in">run</span> -p 127.0.0.1:6443:6443 \<br>                              -v /etc/nginx:/etc/nginx \<br>                              --name nginx-proxy \<br>                              <span class="hljs-attribute">--net</span>=host \<br>                              <span class="hljs-attribute">--restart</span>=on-failure:5 \<br>                              <span class="hljs-attribute">--memory</span>=512M \<br>                              nginx:1.13.12-alpine<br><span class="hljs-attribute">ExecStartPre</span>=-/usr/bin/docker rm -f nginx-proxy<br><span class="hljs-attribute">ExecStop</span>=/usr/bin/docker stop nginx-proxy<br><span class="hljs-attribute">Restart</span>=always<br><span class="hljs-attribute">RestartSec</span>=15s<br><span class="hljs-attribute">TimeoutStartSec</span>=30s<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br><br></code></pre></td></tr></table></figure><h5 id="nginx-conf"><a href="#nginx-conf" class="headerlink" title="nginx.conf"></a>nginx.conf</h5><p>注意修改ip</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">error_log stderr <span class="hljs-keyword">notice</span>;<br><br>worker_processes auto;<br>events &#123;<br>        multi_accept <span class="hljs-keyword">on</span>;<br>        use epoll;<br>        worker_connections <span class="hljs-number">1024</span>;<br>&#125;<br><br>stream &#123;<br>    upstream kube_apiserver &#123;<br>        least_conn;<br>        <span class="hljs-keyword">server</span> <span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.30</span>:<span class="hljs-number">6443</span>;<br>        <span class="hljs-keyword">server</span> <span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.31</span>:<span class="hljs-number">6443</span>;<br>        <span class="hljs-keyword">server</span> <span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.32</span>:<span class="hljs-number">6443</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">server</span> &#123;<br>        <span class="hljs-keyword">listen</span>        <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>:<span class="hljs-number">6443</span>;<br>        proxy_pass    kube_apiserver;<br>        proxy_timeout <span class="hljs-number">10</span>m;<br>        proxy_connect_timeout <span class="hljs-number">1</span>s;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h5 id="启动-apiserver-的本地负载均衡"><a href="#启动-apiserver-的本地负载均衡" class="headerlink" title="启动 apiserver 的本地负载均衡"></a>启动 apiserver 的本地负载均衡</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> /etc/nginx<br><span class="hljs-built_in">cp</span> nginx.conf /etc/nginx<br><span class="hljs-built_in">cp</span> nginx-proxy.service /lib/systemd/system<br><br>systemctl daemon-reload<br>systemctl start nginx-proxy<br>systemctl <span class="hljs-built_in">enable</span> nginx-proxy<br></code></pre></td></tr></table></figure><h5 id="TLS-bootstrapping"><a href="#TLS-bootstrapping" class="headerlink" title="TLS bootstrapping"></a>TLS bootstrapping</h5><p>创建好 nginx-proxy 后不要忘记为 TLS Bootstrap 创建相应的 RBAC 规则，这些规则能实现证自动签署 TLS Bootstrap 发出的 CSR 请求，从而实现证书轮换(创建一次即可)；详情请参考 <a href="https://mritd.me/2018/01/07/kubernetes-tls-bootstrapping-note/">Kubernetes TLS bootstrapping 那点事</a></p><h6 id="tls-bootstrapping-clusterrole-yaml"><a href="#tls-bootstrapping-clusterrole-yaml" class="headerlink" title="tls-bootstrapping-clusterrole.yaml"></a>tls-bootstrapping-clusterrole.yaml</h6><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment">## A ClusterRole which instructs the CSR approver to approve a node requesting a</span><br><span class="hljs-comment">## serving cert matching its client cert.</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span><br><span class="hljs-attr">rules:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">apiGroups:</span> [<span class="hljs-string">&quot;certificates.k8s.io&quot;</span>]<br>  <span class="hljs-attr">resources:</span> [<span class="hljs-string">&quot;certificatesigningrequests/selfnodeserver&quot;</span>]<br>  <span class="hljs-attr">verbs:</span> [<span class="hljs-string">&quot;create&quot;</span>]<br></code></pre></td></tr></table></figure><p>上述yaml需要再master节点执行创建</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">## 给与 kubelet-bootstrap 用户进行 node-bootstrapper 的权限</span><br>kubectl create clusterrolebinding kubelet-bootstrap \<br>    <span class="hljs-attribute">--clusterrole</span>=system:node-bootstrapper \<br>    <span class="hljs-attribute">--user</span>=kubelet-bootstrap<br><br>kubectl create -f tls-bootstrapping-clusterrole.yaml<br><br><span class="hljs-comment">## 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求</span><br>kubectl create clusterrolebinding node-client-auto-approve-csr \<br>        <span class="hljs-attribute">--clusterrole</span>=system:certificates.k8s.io:certificatesigningrequests:nodeclient \<br>        <span class="hljs-attribute">--group</span>=system:bootstrappers<br><br><span class="hljs-comment">## 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求</span><br>kubectl create clusterrolebinding node-client-auto-renew-crt \<br>        <span class="hljs-attribute">--clusterrole</span>=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient \<br>        <span class="hljs-attribute">--group</span>=system:nodes<br><br><span class="hljs-comment">## 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求</span><br>kubectl create clusterrolebinding node-server-auto-renew-crt \<br>        <span class="hljs-attribute">--clusterrole</span>=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver \<br>        <span class="hljs-attribute">--group</span>=system:nodes<br></code></pre></td></tr></table></figure><h5 id="执行启动"><a href="#执行启动" class="headerlink" title="执行启动"></a>执行启动</h5><p>多节点部署时先启动好 nginx-proxy，然后修改好相应配置的 ip 地址等配置，最终直接启动即可(master 上启动 kubelet 不要忘了修改 kubeconfig 中的 apiserver 地址，还有对应的 kubelet 的 node label)</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs nsis"><span class="hljs-params">system</span>ctl daemon-reload<br><span class="hljs-params">system</span>ctl restart kubelet<br><span class="hljs-params">system</span>ctl restart kube-proxy<br><span class="hljs-params">system</span>ctl enable kubelet<br><span class="hljs-params">system</span>ctl enable kube-proxy<br><br></code></pre></td></tr></table></figure><p>启动成功后得到如下图<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180510115842.png!700x999"><br><br><br>截图来自mritd,由于是公司机器,不能直接暴露,后续个人搭建时,再来替换为自己的</p><h4 id="5-2-Calico"><a href="#5-2-Calico" class="headerlink" title="5.2 Calico"></a>5.2 Calico</h4><p>Calico 安装仍然延续以前的方案，使用 Daemonset 安装 cni 组件，使用 systemd 控制 calico-node 以确保 calico-node 能正确的拿到主机名等</p><h5 id="修改calico配置"><a href="#修改calico配置" class="headerlink" title="修改calico配置"></a>修改calico配置</h5><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs awk">wget https:<span class="hljs-regexp">//</span>docs.projectcalico.org<span class="hljs-regexp">/v3.1/g</span>etting-started<span class="hljs-regexp">/kubernetes/i</span>nstallation<span class="hljs-regexp">/hosted/</span>calico.yaml -O calico.example.yaml<br><br>ETCD_CERT=`cat <span class="hljs-regexp">/etc/</span>etcd<span class="hljs-regexp">/ssl/</span>etcd.pem | base64 | tr -d <span class="hljs-string">&#x27;\n&#x27;</span>`<br>ETCD_KEY=`cat <span class="hljs-regexp">/etc/</span>etcd<span class="hljs-regexp">/ssl/</span>etcd-key.pem | base64 | tr -d <span class="hljs-string">&#x27;\n&#x27;</span>`<br>ETCD_CA=`cat <span class="hljs-regexp">/etc/</span>etcd<span class="hljs-regexp">/ssl/</span>etcd-root-ca.pem | base64 | tr -d <span class="hljs-string">&#x27;\n&#x27;</span>`<br>ETCD_ENDPOINTS=<span class="hljs-string">&quot;https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379&quot;</span><br><br>cp calico.example.yaml calico.yaml<br><br>sed -i <span class="hljs-string">&quot;s@.*etcd_endpoints:.*@\ \ etcd_endpoints:\ \&quot;$&#123;ETCD_ENDPOINTS&#125;\&quot;@gi&quot;</span> calico.yaml<br><br>sed -i <span class="hljs-string">&quot;s@.*etcd-cert:.*@\ \ etcd-cert:\ $&#123;ETCD_CERT&#125;@gi&quot;</span> calico.yaml<br>sed -i <span class="hljs-string">&quot;s@.*etcd-key:.*@\ \ etcd-key:\ $&#123;ETCD_KEY&#125;@gi&quot;</span> calico.yaml<br>sed -i <span class="hljs-string">&quot;s@.*etcd-ca:.*@\ \ etcd-ca:\ $&#123;ETCD_CA&#125;@gi&quot;</span> calico.yaml<br><br>sed -i <span class="hljs-string">&#x27;s@.*etcd_ca:.*@\ \ etcd_ca:\ &quot;/calico-secrets/etcd-ca&quot;@gi&#x27;</span> calico.yaml<br>sed -i <span class="hljs-string">&#x27;s@.*etcd_cert:.*@\ \ etcd_cert:\ &quot;/calico-secrets/etcd-cert&quot;@gi&#x27;</span> calico.yaml<br>sed -i <span class="hljs-string">&#x27;s@.*etcd_key:.*@\ \ etcd_key:\ &quot;/calico-secrets/etcd-key&quot;@gi&#x27;</span> calico.yaml<br><br><span class="hljs-comment">## 注释掉 calico-node 部分(由 Systemd 接管)</span><br>sed -i <span class="hljs-string">&#x27;123,219s@.*@#&amp;@gi&#x27;</span> calico.yaml<br></code></pre></td></tr></table></figure><h5 id="创建systemd"><a href="#创建systemd" class="headerlink" title="创建systemd"></a>创建systemd</h5><h5>注意: 创建 systemd service 配置文件要在每个节点上都执行</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">K8S_MASTER_IP</span>=<span class="hljs-string">&quot;192.168.1.61&quot;</span><br><span class="hljs-attribute">HOSTNAME</span>=`cat /etc/hostname`<br><span class="hljs-attribute">ETCD_ENDPOINTS</span>=<span class="hljs-string">&quot;https://192.168.1.61:2379,https://192.168.1.62:2379,https://192.168.1.63:2379&quot;</span><br><br>cat &gt; /lib/systemd/system/calico-node.service &lt;&lt;EOF<br>[Unit]<br><span class="hljs-attribute">Description</span>=calico node<br><span class="hljs-attribute">After</span>=docker.service<br><span class="hljs-attribute">Requires</span>=docker.service<br><br>[Service]<br><span class="hljs-attribute">User</span>=root<br><span class="hljs-attribute">Environment</span>=ETCD_ENDPOINTS=$&#123;ETCD_ENDPOINTS&#125;<br><span class="hljs-attribute">PermissionsStartOnly</span>=<span class="hljs-literal">true</span><br><span class="hljs-attribute">ExecStart</span>=/usr/bin/docker <span class="hljs-built_in">run</span>   <span class="hljs-attribute">--net</span>=host --privileged <span class="hljs-attribute">--name</span>=calico-node \\<br>                                -e <span class="hljs-attribute">ETCD_ENDPOINTS</span>=\$&#123;ETCD_ENDPOINTS&#125; \\<br>                                -e <span class="hljs-attribute">ETCD_CA_CERT_FILE</span>=/etc/etcd/ssl/etcd-root-ca.pem \\<br>                                -e <span class="hljs-attribute">ETCD_CERT_FILE</span>=/etc/etcd/ssl/etcd.pem \\<br>                                -e <span class="hljs-attribute">ETCD_KEY_FILE</span>=/etc/etcd/ssl/etcd-key.pem \\<br>                                -e <span class="hljs-attribute">NODENAME</span>=<span class="hljs-variable">$&#123;HOSTNAME&#125;</span> \\<br>                                -e IP= \\<br>                                -e <span class="hljs-attribute">IP_AUTODETECTION_METHOD</span>=can-reach=$&#123;K8S_MASTER_IP&#125; \\<br>                                -e <span class="hljs-attribute">AS</span>=64512 \\<br>                                -e <span class="hljs-attribute">CLUSTER_TYPE</span>=k8s,bgp \\<br>                                -e <span class="hljs-attribute">CALICO_IPV4POOL_CIDR</span>=10.20.0.0/16 \\<br>                                -e <span class="hljs-attribute">CALICO_IPV4POOL_IPIP</span>=always \\<br>                                -e <span class="hljs-attribute">CALICO_LIBNETWORK_ENABLED</span>=<span class="hljs-literal">true</span> \\<br>                                -e <span class="hljs-attribute">CALICO_NETWORKING_BACKEND</span>=bird \\<br>                                -e <span class="hljs-attribute">CALICO_DISABLE_FILE_LOGGING</span>=<span class="hljs-literal">true</span> \\<br>                                -e <span class="hljs-attribute">FELIX_IPV6SUPPORT</span>=<span class="hljs-literal">false</span> \\<br>                                -e <span class="hljs-attribute">FELIX_DEFAULTENDPOINTTOHOSTACTION</span>=ACCEPT \\<br>                                -e <span class="hljs-attribute">FELIX_LOGSEVERITYSCREEN</span>=info \\<br>                                -e <span class="hljs-attribute">FELIX_IPINIPMTU</span>=1440 \\<br>                                -e <span class="hljs-attribute">FELIX_HEALTHENABLED</span>=<span class="hljs-literal">true</span> \\<br>                                -e <span class="hljs-attribute">CALICO_K8S_NODE_REF</span>=<span class="hljs-variable">$&#123;HOSTNAME&#125;</span> \\<br>                                -v /etc/calico/etcd-root-ca.pem:/etc/etcd/ssl/etcd-root-ca.pem \\<br>                                -v /etc/calico/etcd.pem:/etc/etcd/ssl/etcd.pem \\<br>                                -v /etc/calico/etcd-key.pem:/etc/etcd/ssl/etcd-key.pem \\<br>                                -v /lib/modules:/lib/modules \\<br>                                -v /var/lib/calico:/var/lib/calico \\<br>                                -v /var/run/calico:/var/run/calico \\<br>                                quay.io/calico/node:v3.1.0<br><span class="hljs-attribute">ExecStop</span>=/usr/bin/docker rm -f calico-node<br><span class="hljs-attribute">Restart</span>=always<br><span class="hljs-attribute">RestartSec</span>=10<br><br>[Install]<br><span class="hljs-attribute">WantedBy</span>=multi-user.target<br>EOF<br></code></pre></td></tr></table></figure><font color='red'> 对于以上脚本中的 K8S_MASTER_IP 变量，只需要填写一个 master ip 即可，这个变量用于 calico 自动选择 IP 使用；在宿主机有多张网卡的情况下，calcio node 会自动获取一个 IP，获取原则就是尝试是否能够联通这个 master ip 由于 calico 需要使用 etcd 存储数据，所以需要复制 etcd 证书到相关目录，/etc/calico 需要在每个节点都有</font><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cp -r <span class="hljs-regexp">/etc/</span>etcd<span class="hljs-regexp">/ssl /</span>etc/calico<br></code></pre></td></tr></table></figure><h5 id="修改kubelet配置"><a href="#修改kubelet配置" class="headerlink" title="修改kubelet配置"></a>修改kubelet配置</h5><p>使用 Calico 后需要修改 kubelet 配置增加 CNI 设置(–network-plugin&#x3D;cni)，修改后配置如下 <br><br>增加了 –network-plugin&#x3D;cni \    这个配置</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs clean">###<br>## kubernetes kubelet (minion) config<br><br>## The address for the info server to serve on (set to <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span> or <span class="hljs-string">&quot;&quot;</span> for all interfaces)<br>KUBELET_ADDRESS=<span class="hljs-string">&quot;--node-ip=192.168.1.30&quot;</span><br><br>## The port for the info server to serve on<br>## KUBELET_PORT=<span class="hljs-string">&quot;--port=10250&quot;</span><br><br>## You may leave this blank to use the actual hostname<br>KUBELET_HOSTNAME=<span class="hljs-string">&quot;--hostname-override=k1.node&quot;</span><br><br>## location <span class="hljs-keyword">of</span> the api-server<br>## KUBELET_API_SERVER=<span class="hljs-string">&quot;&quot;</span><br><br>## Add your own!<br>KUBELET_ARGS=<span class="hljs-string">&quot;  --bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \</span><br><span class="hljs-string">                --cert-dir=/etc/kubernetes/ssl \</span><br><span class="hljs-string">                --cgroup-driver=cgroupfs \</span><br><span class="hljs-string">                --network-plugin=cni \</span><br><span class="hljs-string">                --cluster-dns=10.254.0.2 \</span><br><span class="hljs-string">                --cluster-domain=cluster.local. \</span><br><span class="hljs-string">                --fail-swap-on=false \</span><br><span class="hljs-string">                --feature-gates=RotateKubeletClientCertificate=true,RotateKubeletServerCertificate=true \</span><br><span class="hljs-string">                --node-labels=node-role.kubernetes.io/k8s-master=true \</span><br><span class="hljs-string">                --image-gc-high-threshold=70 \</span><br><span class="hljs-string">                --image-gc-low-threshold=50 \</span><br><span class="hljs-string">                --kube-reserved=cpu=500m,memory=512Mi,ephemeral-storage=1Gi \</span><br><span class="hljs-string">                --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \</span><br><span class="hljs-string">                --system-reserved=cpu=1000m,memory=1024Mi,ephemeral-storage=1Gi \</span><br><span class="hljs-string">                --serialize-image-pulls=false \</span><br><span class="hljs-string">                --sync-frequency=30s \</span><br><span class="hljs-string">                --pod-infra-container-image=k8s.gcr.io/pause-amd64:3.0 \</span><br><span class="hljs-string">                --resolv-conf=/etc/resolv.conf \</span><br><span class="hljs-string">                --rotate-certificates&quot;</span><br></code></pre></td></tr></table></figure><h5 id="创建-Calico-Daemonset"><a href="#创建-Calico-Daemonset" class="headerlink" title="创建 Calico Daemonset"></a>创建 Calico Daemonset</h5><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">## 先创建 RBAC</span><br>kubectl apply -f \<br>https:<span class="hljs-regexp">//</span>docs.projectcalico.org<span class="hljs-regexp">/v3.1/g</span>etting-started<span class="hljs-regexp">/kubernetes/i</span>nstallation/rbac.yaml<br><br><span class="hljs-comment">## 再创建 Calico Daemonset</span><br>kubectl create -f calico.yaml<br></code></pre></td></tr></table></figure><h5 id="启动-Calico-Node"><a href="#启动-Calico-Node" class="headerlink" title="启动 Calico Node"></a>启动 Calico Node</h5><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">systemctl daemon-reload<br>systemctl restart calico-<span class="hljs-keyword">node</span><br><span class="hljs-title">systemctl</span> enable calico-<span class="hljs-keyword">node</span><br><br><span class="hljs-title">## 等待 20s</span> 拉取镜像<br>sleep <span class="hljs-number">20</span><br>systemctl restart kubelet<br></code></pre></td></tr></table></figure><h5 id="测试网络"><a href="#测试网络" class="headerlink" title="测试网络"></a>测试网络</h5><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-comment">## 创建 deployment</span><br><span class="hljs-attribute">cat &lt;&lt; EOF &gt;&gt; demo.deploy.yml</span><br><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">demo-deployment</span><br><span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">replicas</span><span class="hljs-punctuation">:</span> <span class="hljs-string">5</span><br>  <span class="hljs-attribute">selector</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">matchLabels</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">demo</span><br>  <span class="hljs-attribute">template</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">demo</span><br>    <span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">containers</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">name: demo</span><br>        <span class="hljs-attribute">image</span><span class="hljs-punctuation">:</span> <span class="hljs-string">mritd/demo</span><br>        <span class="hljs-attribute">imagePullPolicy</span><span class="hljs-punctuation">:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attribute">ports</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">containerPort: 80</span><br>EOF<br>kubectl create -f demo.deploy.yml<br></code></pre></td></tr></table></figure><p>截图引用自mritd<br><br><img src="https://stone-upyun.b0.aicdn.com/blog20180510120356.png!700x999"><br><br></p><h4 id="5-3-coreDNS"><a href="#5-3-coreDNS" class="headerlink" title="5.3 coreDNS"></a>5.3 coreDNS</h4><p>此处使用的mritd的脚本自动安装的<br></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd ~ <br>git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/mritd/</span>ktool<br>cd <span class="hljs-regexp">/root/</span>ktool<span class="hljs-regexp">/k8s/</span>addons/coredns<br><br><span class="hljs-comment">## 执行上面的替换脚本</span><br>./deploy.sh<br><br><span class="hljs-comment">## 创建 CoreDNS</span><br>kubectl create -f coredns.yaml<br></code></pre></td></tr></table></figure><p>替换脚本内容为:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-comment">## Deploys CoreDNS to a cluster currently running Kube-DNS.</span><br><br>SERVICE_CIDR=<span class="hljs-variable">$&#123;1:-10.254.0.0/16&#125;</span><br>POD_CIDR=<span class="hljs-variable">$&#123;2:-10.20.0.0/16&#125;</span><br>CLUSTER_DNS_IP=<span class="hljs-variable">$&#123;3:-10.254.0.2&#125;</span><br>CLUSTER_DOMAIN=<span class="hljs-variable">$&#123;4:-cluster.local&#125;</span><br>YAML_TEMPLATE=<span class="hljs-variable">$&#123;5:-`pwd`/coredns.yaml.sed&#125;</span><br><br>sed -e s/CLUSTER_DNS_IP/<span class="hljs-variable">$CLUSTER_DNS_IP</span>/g -e s/CLUSTER_DOMAIN/<span class="hljs-variable">$CLUSTER_DOMAIN</span>/g -e s?SERVICE_CIDR?<span class="hljs-variable">$SERVICE_CIDR</span>?g -e s?POD_CIDR?<span class="hljs-variable">$POD_CIDR</span>?g <span class="hljs-variable">$YAML_TEMPLATE</span> &gt; coredns.yaml<br></code></pre></td></tr></table></figure><h5 id="部署DNS自动扩容"><a href="#部署DNS自动扩容" class="headerlink" title="部署DNS自动扩容"></a>部署DNS自动扩容</h5><p>vim dns-horizontal-autoscaler.yaml</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-comment">## Copyright 2016 The Kubernetes Authors.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">## Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">## you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">## You may obtain a copy of the License at</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">##     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">## Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">## distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">## See the License for the specific language governing permissions and</span><br><span class="hljs-comment">## limitations under the License.</span><br><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">ServiceAccount</span><br><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">v1</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br>  <span class="hljs-attribute">namespace</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-system</span><br>  <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">addonmanager.kubernetes.io/mode</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Reconcile</span><br><span class="hljs-attribute">***</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">ClusterRole</span><br><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">system:kube-dns-autoscaler</span><br>  <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">addonmanager.kubernetes.io/mode</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Reconcile</span><br><span class="hljs-attribute">rules</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">apiGroups: [&quot;&quot;]</span><br>    <span class="hljs-attribute">resources</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;nodes&quot;]</span><br>    <span class="hljs-attribute">verbs</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;list&quot;]</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">apiGroups: [&quot;&quot;]</span><br>    <span class="hljs-attribute">resources</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;replicationcontrollers/scale&quot;]</span><br>    <span class="hljs-attribute">verbs</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;get&quot;, &quot;update&quot;]</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">apiGroups: [&quot;extensions&quot;]</span><br>    <span class="hljs-attribute">resources</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;deployments/scale&quot;, &quot;replicasets/scale&quot;]</span><br>    <span class="hljs-attribute">verbs</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;get&quot;, &quot;update&quot;]</span><br><span class="hljs-comment">## Remove the configmaps rule once below issue is fixed:</span><br><span class="hljs-comment">## kubernetes-incubator/cluster-proportional-autoscaler#16</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">apiGroups: [&quot;&quot;]</span><br>    <span class="hljs-attribute">resources</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;configmaps&quot;]</span><br>    <span class="hljs-attribute">verbs</span><span class="hljs-punctuation">:</span> <span class="hljs-string">[&quot;get&quot;, &quot;create&quot;]</span><br><span class="hljs-attribute">***</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">ClusterRoleBinding</span><br><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">system:kube-dns-autoscaler</span><br>  <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">addonmanager.kubernetes.io/mode</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Reconcile</span><br><span class="hljs-attribute">subjects</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">kind: ServiceAccount</span><br>    <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br>    <span class="hljs-attribute">namespace</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-system</span><br><span class="hljs-attribute">roleRef</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">ClusterRole</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">system:kube-dns-autoscaler</span><br>  <span class="hljs-attribute">apiGroup</span><span class="hljs-punctuation">:</span> <span class="hljs-string">rbac.authorization.k8s.io</span><br><br><span class="hljs-attribute">***</span><br><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br>  <span class="hljs-attribute">namespace</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-system</span><br>  <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">k8s-app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br>    <span class="hljs-attribute">kubernetes.io/cluster-service</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;true&quot;</span><br>    <span class="hljs-attribute">addonmanager.kubernetes.io/mode</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Reconcile</span><br><span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">selector</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">matchLabels</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">k8s-app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br>  <span class="hljs-attribute">template</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">k8s-app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br>      <span class="hljs-attribute">annotations</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">scheduler.alpha.kubernetes.io/critical-pod</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&#x27;&#x27;</span><br>    <span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">priorityClassName</span><span class="hljs-punctuation">:</span> <span class="hljs-string">system-cluster-critical</span><br>      <span class="hljs-attribute">containers</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">name: autoscaler</span><br>        <span class="hljs-attribute">image</span><span class="hljs-punctuation">:</span> <span class="hljs-string">k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2-r2</span><br>        <span class="hljs-attribute">resources</span><span class="hljs-punctuation">:</span><br>            <span class="hljs-attribute">requests</span><span class="hljs-punctuation">:</span><br>                <span class="hljs-attribute">cpu</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;20m&quot;</span><br>                <span class="hljs-attribute">memory</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;10Mi&quot;</span><br>        <span class="hljs-attribute">command</span><span class="hljs-punctuation">:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">/cluster-proportional-autoscaler</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">--namespace=kube-system</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">--configmap=kube-dns-autoscaler</span><br>          <span class="hljs-comment">## Should keep target in sync with cluster/addons/dns/kube-dns.yaml.base</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">--target=Deployment/kube-dns</span><br>          <span class="hljs-comment">## When cluster is using large nodes(with more cores), &quot;coresPerReplica&quot; should dominate.</span><br>          <span class="hljs-comment">## If using small nodes, &quot;nodesPerReplica&quot; should dominate.</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">--default-params=&#123;&quot;linear&quot;:&#123;&quot;coresPerReplica&quot;:256,&quot;nodesPerReplica&quot;:16,&quot;preventSinglePointFailure&quot;:true&#125;&#125;</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">--logtostderr=true</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">--v=2</span><br>      <span class="hljs-attribute">tolerations</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">key: &quot;CriticalAddonsOnly&quot;</span><br>        <span class="hljs-attribute">operator</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Exists&quot;</span><br>      <span class="hljs-attribute">serviceAccountName</span><span class="hljs-punctuation">:</span> <span class="hljs-string">kube-dns-autoscaler</span><br></code></pre></td></tr></table></figure><p>执行yaml创建即可完成DNS的自动扩容</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">kubectl create -f dns-horizontal-<span class="hljs-built_in">auto</span>scaler.yaml <br></code></pre></td></tr></table></figure><h3 id="六-k8s-监控heapster"><a href="#六-k8s-监控heapster" class="headerlink" title="六 k8s-监控heapster"></a>六 k8s-监控heapster</h3><p>直接yaml创建即可</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk">kubectl create -f https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/kubernetes/</span>heapster<span class="hljs-regexp">/master/</span>deploy<span class="hljs-regexp">/kube-config/i</span>nfluxdb/grafana.yaml<br>kubectl create -f https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/kubernetes/</span>heapster<span class="hljs-regexp">/master/</span>deploy<span class="hljs-regexp">/kube-config/i</span>nfluxdb/heapster.yaml<br>kubectl create -f https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/kubernetes/</span>heapster<span class="hljs-regexp">/master/</span>deploy<span class="hljs-regexp">/kube-config/i</span>nfluxdb/influxdb.yaml<br>kubectl create -f https:<span class="hljs-regexp">//</span>raw.githubusercontent.com<span class="hljs-regexp">/kubernetes/</span>heapster<span class="hljs-regexp">/master/</span>deploy<span class="hljs-regexp">/kube-config/</span>rbac/heapster-rbac.yaml<br></code></pre></td></tr></table></figure><p>至此,搭建完成 ,集群已可以正常使用.如需要管理页面的可翻看下面的内容,不需要就不用了</p><h3 id="七-k8s-图形管理页面-Dashboard"><a href="#七-k8s-图形管理页面-Dashboard" class="headerlink" title="七 k8s-图形管理页面 Dashboard"></a>七 k8s-图形管理页面 Dashboard</h3><p>因为本次搭建没有部署Dashboard,具体搭建可看mritd的 <a href="https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/#%E5%85%AB%E9%83%A8%E7%BD%B2-dashboard">部署 Dashboard</a><br><br><br><br></p><p><strong>本文参考来自mritd的<a href="https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube">Kubernetes 1.10.1 集群搭建</a> ,其中大量脚本使用mritd提供</strong></p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>flume的搭建和简单使用</title>
      <link href="/hadoop/2018-05-02-flume%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
      <url>/hadoop/2018-05-02-flume%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h3 id="flume-简介"><a href="#flume-简介" class="headerlink" title="flume 简介:"></a>flume 简介:</h3><ul><li>百度百科:<br><br>  Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。<br>  当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。</li><li>简介2<br><ol><li>Flume 提供一个分布式的，可靠的，对大数据量的日志进行高效收集、聚集、移动的服务， Flume 只能在 Unix 环境下运行。<br></li><li>Flume 基于流式架构，容错性强，也很灵活简单。<br></li><li>Flume、Kafka 用来实时进行数据收集，Spark、Storm 用来实时处理数据，impala 用来实 时查询。<br></li></ol></li></ul><hr><h3 id="模式"><a href="#模式" class="headerlink" title="模式"></a>模式</h3><p>参考<a href="http://flume.apache.org/FlumeUserGuide.html">官文文档</a><br><br>模式一:单输入单输出 <br><br>    <img src="https://stone-upyun.b0.aicdn.com/blog20180502120225.png!700x999"></p><p>模式二:多flume连接<br>    <img src="https://stone-upyun.b0.aicdn.com/blog20180502120550.png!700x999"></p><p>模式三:多输入汇总<br>    <img src="https://stone-upyun.b0.aicdn.com/blog20180502120652.png!700x999"></p><p>模式四:多输出分发<br>    <img src="https://stone-upyun.b0.aicdn.com/blog20180502120712.png!700x999"></p><hr><h3 id="Flume-角色"><a href="#Flume-角色" class="headerlink" title="Flume 角色"></a>Flume 角色<br></h3><ul><li>1、Source <br><br>  用于采集数据，Source 是产生数据流的地方，同时 Source 会将产生的数据流传输到 Channel，<br>  这个有点类似于 Java IO 部分的 Channel。<br></li><li>2、Channel<br><br>  用于桥接 Sources 和 Sinks，类似于一个队列。<br></li><li>3、Sink<br><br>  从 Channel 收集数据，将数据写到目标源(可以是下一个 Source，也可以是 HDFS 或者 HBase)。</li><li>4、Event<br><br>  传输单元，Flume 数据传输的基本单元，以事件的形式将数据从源头送至目的地</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>下载官方对应的安装包,解压<br><br>修改 conf&#x2F;flume-env.sh 文件中JAVA_HOME即可使用<br><br>本文使用的版本:1.7.0 下载地址: <a href="http://archive.apache.org/dist/flume/">官方下载地址</a></p><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题:"></a>遇到的问题:</h3><p>在flume中配置两个sink输出到指定两端口,然后用两个soureces去接受这两个sink传递过来的值,,最终将之前其中一个sink的发送的数据放到hdfs,另一个数据放到本地磁盘.但是放到本地磁盘的那份数据,只有目录和文件,数据没有,放到hdfs上的有数据<br><br>第一个flume的配置</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 讲一个source 分发给多个chanel-对应多个sink，给下一个相应的flume</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.channels</span> = c1 c2<br><span class="hljs-attr">a1.sinks</span> = k1 k2<br><br><span class="hljs-comment"># 将数据复制给多个channel</span><br><span class="hljs-attr">a1.sources.r1.selector.type</span> = replicating<br><br><span class="hljs-comment"># sources 设置</span><br><span class="hljs-attr">a1.sources.r1.type</span> = exec<br><span class="hljs-attr">a1.sources.r1.command</span> = tail -F /home/admin/module/hive-<span class="hljs-number">1.2</span>.<span class="hljs-number">2</span>/logs/hive.log<br><span class="hljs-attr">a1.sources.r1.shell</span> = /bin/bash -c<br><br><span class="hljs-comment">#channels 设置</span><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-attr">a1.channels.c2.type</span> = memory<br><span class="hljs-attr">a1.channels.c2.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c2.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># sinks 设置</span><br><span class="hljs-attr">a1.sinks.k2.type</span> = avro<br><span class="hljs-attr">a1.sinks.k2.hostname</span> = hd001<br><span class="hljs-attr">a1.sinks.k2.port</span> = <span class="hljs-number">8088</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = avro<br><span class="hljs-attr">a1.sinks.k1.hostname</span> = hd001<br><span class="hljs-attr">a1.sinks.k1.port</span> = <span class="hljs-number">8089</span>  <br></code></pre></td></tr></table></figure><p>第二个flume的配置</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment">#接受上一个flume 的sink的结果# 定义服务</span><br><span class="hljs-attr">a2.sources</span> = r1<br><span class="hljs-attr">a2.channels</span> = c1<br><span class="hljs-attr">a2.sinks</span> = k1<br><br><span class="hljs-comment"># source 设置</span><br><span class="hljs-attr">a2.sources.r1.type</span> = avro<br><span class="hljs-attr">a2.sources.r1.bind</span> = hd001<br><span class="hljs-attr">a2.sources.r1.port</span> = <span class="hljs-number">8089</span><br><br><span class="hljs-comment"># sink 设置</span><br><span class="hljs-attr">a2.sinks.k1.type</span> = hdfs<br><span class="hljs-attr">a2.sinks.k1.hdfs.path</span> = hdfs://<span class="hljs-number">192.168</span>.<span class="hljs-number">1.20</span>:<span class="hljs-number">9000</span>/flume4/manysinks/%Y%m%d/%H<br><span class="hljs-comment">#上传文件的前缀</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.filePrefix</span> = upload2-<br><span class="hljs-comment">#是否按照时间滚动文件夹</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.round</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment">#多少时间单位创建一个新的文件夹</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.roundValue</span> = <span class="hljs-number">1</span><br><span class="hljs-comment">#重新定义时间单位</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.roundUnit</span> = hour<br><span class="hljs-comment">#是否使用本地时间戳</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="hljs-literal">true</span><br><span class="hljs-comment">#积攒多少个Event才flush到HDFS一次</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.batchSize</span> = <span class="hljs-number">1000</span><br><span class="hljs-comment">#设置文件类型，可支持压缩</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.fileType</span> = DataStream<br><span class="hljs-comment">#多久生成一个新的文件</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.rollInterval</span> = <span class="hljs-number">600</span><br><span class="hljs-comment">#设置每个文件的滚动大小</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.rollSize</span> = <span class="hljs-number">134217700</span><br><span class="hljs-comment">#文件的滚动与Event数量无关</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.rollCount</span> = <span class="hljs-number">0</span><br><span class="hljs-comment">#最小冗余数</span><br><span class="hljs-attr">a2.sinks.k1.hdfs.minBlockReplicas</span> = <span class="hljs-number">1</span><br><br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a2.channels.c1.type</span> = memory<br><span class="hljs-attr">a2.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a2.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-attr">a2.sources.r1.channels</span> = c1<br><span class="hljs-attr">a2.sinks.k1.channel</span> = c1<br><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1 c2<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br><span class="hljs-attr">a1.sinks.k2.channel</span> = c2 <br></code></pre></td></tr></table></figure><p>第三个flume的配置  </p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment">#接受上一个flume 的sink的结果# 定义服务</span><br><span class="hljs-attr">a3.sources</span> = r1<br><span class="hljs-attr">a3.channels</span> = c1<br><span class="hljs-attr">a3.sinks</span> = k1<br><span class="hljs-comment"># source 设置</span><br><span class="hljs-attr">a3.sources.r1.type</span> = avro<br><span class="hljs-attr">a3.sources.r1.bind</span> = hd001<br><span class="hljs-attr">a3.sources.r1.port</span> = <span class="hljs-number">8088</span><br><span class="hljs-comment"># sink 设置</span><br><span class="hljs-attr">a3.sinks.k1.type</span> = file_roll<br><span class="hljs-attr">a3.sinks.k1.sink.directory</span> = /home/admin/tmp/flume4<br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a3.channels.c1.type</span> = memory<br><span class="hljs-attr">a3.channels.c1.capacity</span> = <span class="hljs-number">100</span><br><span class="hljs-attr">a3.channels.c1.transactionCapacity</span> = <span class="hljs-number">50</span><br><br><span class="hljs-attr">a3.sources.r1.cahnnels</span> = c1<br><span class="hljs-attr">a3.sinks.k1.channel</span> = c1  <br></code></pre></td></tr></table></figure><p>查看第三个flume配置中对应结果目录数据</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs tap">[admin@hd001 ~]$ ll tmp/flum4/<br>总用量 0<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:32 1525231977673-1<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:37 1525231977673-10<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:37 1525231977673-11<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:38 1525231977673-12<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:39 1525231977673-13<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:39 1525231977673-14<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:39 1525231977673-15<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:40 1525231977673-16<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:41 1525231977673-17<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:41 1525231977673-18<br>-rw-rw-r--.<span class="hljs-number"> 1 </span>admin admin<span class="hljs-number"> 0 </span>5月  <span class="hljs-number"> 2 </span>11:41 1525231977673-19<br>里面的数据为0,cat * 出来也是空的,但是在第二个flume中到hdfs上的数据是有对应的hive.log日志<br><br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Flume </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>博客图床上传工具推荐</title>
      <link href="/blog/2018-04-16-%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E4%B8%8A%E4%BC%A0%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/"/>
      <url>/blog/2018-04-16-%E5%8D%9A%E5%AE%A2%E5%9B%BE%E5%BA%8A%E4%B8%8A%E4%BC%A0%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<h4 id="推荐的图床"><a href="#推荐的图床" class="headerlink" title="推荐的图床"></a>推荐的图床</h4><p>最近在怼博客,然后需要一些图片来辅助完成记录,网上口碑较好的又拍(upyun),七牛等.<br>同事个人在用upyun,公司也用的是这个.所以选择了upyun,然后发现没有一些上传图床的工具都是收费.<br>找到一个开源的,共享之.</p><h4 id="开源图床picGo"><a href="#开源图床picGo" class="headerlink" title="开源图床picGo"></a>开源图床picGo</h4><p>picGo支持的图床如下图</p><ul><li>截图<br><img src="https://stone-upyun.b0.aicdn.com/blog20180416174254.png!700x999"></li><li>下载地址 <br><br>工具<a href="https://github.com/Molunerfinn/PicGo/releases">github下载地址</a>{:target&#x3D;”_blank”}</li></ul>]]></content>
      
      
      <categories>
          
          <category> Blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hadoop-HA(高可用)集群搭建</title>
      <link href="/hadoop/2018-04-16-hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>/hadoop/2018-04-16-hadoop-HA(%E9%AB%98%E5%8F%AF%E7%94%A8)%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><ul><li>静态IP<br></li><li>映射主机名与ip<br></li><li>jdk环境<br></li><li>防火墙关闭<br></li><li>ssh免密<br></li></ul><h4 id="高可用原理介绍"><a href="#高可用原理介绍" class="headerlink" title="高可用原理介绍"></a>高可用原理介绍</h4><ul><li><h5 id="为何使用HA"><a href="#为何使用HA" class="headerlink" title="为何使用HA"></a>为何使用HA<br></h5><p>因为在非HA集群模式下namenode是单节点工作,故存在namenode的单节点故障.<br><br>为防止故障发生,需要使用多个namenode节点.<br><br>其中,hadoop2.x版本只能支持2个namenode节点 ,hadoop3.x可以支持更多个<br><br>本文以hadoop2.7.2版本为基础</p><br></li><li><h5 id="HA实现原理"><a href="#HA实现原理" class="headerlink" title="HA实现原理"></a>HA实现原理</h5><p>两个namenode的数据是一致的.<br><br>两个namenode通过hadoop中的journalnode集群服务来同步两个namenode的元数据<br><br>两个namenode工作时,其中一台处于active状态,另外一台处于standy状态,否则会出现(split-brain)脑裂,集群无法工作.<br><br>在故障自动转移中, 通过 zookeeper 中的ZKFC(zookeeper failover controller,zookeeper 故障转移控制)进程来控制namenode节点的工作状态切换<br><br>其中ZKFC会在两个namenode节点只监听namenode的状态信息,不会对元数据进行操作,<br><br>当处于active的namenode宕机或死掉,zookeeper会通过ZKFC通知另外一台namenode启用(active)</p></li></ul><h4 id="namenode的高可用配置"><a href="#namenode的高可用配置" class="headerlink" title="namenode的高可用配置"></a>namenode的高可用配置</h4><ul><li><h5 id="1-解压或复制原来hadoop集群相关文件"><a href="#1-解压或复制原来hadoop集群相关文件" class="headerlink" title="1.解压或复制原来hadoop集群相关文件"></a>1.解压或复制原来hadoop集群相关文件<br></h5>  <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tar</span> -zxf hadoop-<span class="hljs-number">2</span>.<span class="hljs-number">7</span>.<span class="hljs-number">2</span>.tar.gz -C ~/module/HA/<br></code></pre></td></tr></table></figure></li><li><h5 id="2-配置hadoop相关文件"><a href="#2-配置hadoop相关文件" class="headerlink" title="2.配置hadoop相关文件"></a>2.配置hadoop相关文件</h5>  <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd <span class="hljs-regexp">/home/</span>admin<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/hadoop-2.7.2/</span>etc/hadoop    <br></code></pre></td></tr></table></figure></li><li><h6 id="编辑core-site-xml-此时为非自动故障转移"><a href="#编辑core-site-xml-此时为非自动故障转移" class="headerlink" title="编辑core-site.xml(此时为非自动故障转移)"></a>编辑core-site.xml(此时为非自动故障转移)</h6>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 把两个NameNode）的地址组装成一个集群haCluster(haCluster为集群名称,后续需要跟此保持一致) --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://haCluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- # dfs 系统存取数据的目录 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/admin/module/HA/hadoop-2.7.2/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- journalnode 数据存储目录 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.journalnode.edit.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/admin/module/HA/hadoop-2.7.2/jn/haCluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- zookeeper通信客户端地址  --&gt;</span><br>  <span class="hljs-comment">&lt;!-- &lt;property&gt;</span><br><span class="hljs-comment">      &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="hljs-comment">      &lt;value&gt;hd001:2181,hd002:2181,hd003:2181&lt;/value&gt;</span><br><span class="hljs-comment">  &lt;/property&gt;  --&gt;</span><br><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h6 id="编辑hdfs-site-xml"><a href="#编辑hdfs-site-xml" class="headerlink" title="编辑hdfs-site.xml"></a>编辑hdfs-site.xml</h6>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 完全分布式集群名称 haCluster 此处的haCluster与core-site.xmlvs中的集群名称需要一致,此xml种的haCluster都是集群对应的名称 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.nameservices<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>haCluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.namenodes.haCluster<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>nn1,nn2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- nn1的RPC通信地址 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.rpc-address.haCluster.nn1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>   <span class="hljs-comment">&lt;!-- nn2的RPC通信地址 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.rpc-address.haCluster.nn2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- nn1的http通信地址 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.http-address.haCluster.nn1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002:50070<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- nn2的http通信地址 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.http-address.haCluster.nn2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd003:50070<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>qjournal://hd001:8485;hd002:8485;hd003:8485/haCluster<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br> <span class="hljs-comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>sshfence<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/admin/.ssh/id_rsa<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 声明journalnode服务器存储目录--&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/admin/module/HA/hadoop-2.7.2/jn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 关闭权限检查--&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.permissions.enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.client.failover.proxy.provider.haCluster<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- # hdfs文件系统中的文件副本数量 为1(一般情况,完全分布式都是3分以上基数份) --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- # hdfs文件系统中的文件副本数量 为1(一般情况,完全分布式都是3分以上基数份) --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- # 节点检测频率,用户namenode 检测datanode是否存活 120s --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>120<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 启用web查看hdfs系统 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 启用自动故障转移 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- # 指定 dfs 相关的机器地址,用户上下线新的机器 --&gt;</span><br>  <span class="hljs-comment">&lt;!-- &lt;property&gt;</span><br><span class="hljs-comment">          &lt;name&gt;dfs.hosts&lt;/name&gt;</span><br><span class="hljs-comment">          &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts&lt;/value&gt;</span><br><span class="hljs-comment">  &lt;/property&gt;</span><br><span class="hljs-comment">  # 指定退役的节点</span><br><span class="hljs-comment">  &lt;property&gt;</span><br><span class="hljs-comment">          &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;</span><br><span class="hljs-comment">          &lt;value&gt;/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude&lt;/value&gt;</span><br><span class="hljs-comment">  &lt;/property&gt; --&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h6 id="编辑mapred-site-xml"><a href="#编辑mapred-site-xml" class="headerlink" title="编辑mapred-site.xml"></a>编辑mapred-site.xml</h6>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 指定mr运行在yarn上 --&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>      <span class="hljs-comment">&lt;!--配置历史服务器 --&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure><p>  将hadoop目录分发至集群每台机器</p>  <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">scp -r <span class="hljs-regexp">/home/</span>admin<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/hadoop-2.7.2 hd002:~/m</span>odule<span class="hljs-regexp">/HA/</span><br>scp -r <span class="hljs-regexp">/home/</span>admin<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/hadoop-2.7.2 hd003:~/m</span>odule<span class="hljs-regexp">/HA/</span><br></code></pre></td></tr></table></figure><p>  至此 namenode高可用搭建完成,但是不是自动故障转移,切换namenode的active状态需要手动</p></li><li><h6 id="编辑yarn-site-xml-此处为非自动故障转移的配置"><a href="#编辑yarn-site-xml-此处为非自动故障转移的配置" class="headerlink" title="编辑yarn-site.xml(此处为非自动故障转移的配置)"></a>编辑yarn-site.xml(此处为非自动故障转移的配置)</h6>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 日志聚集功能使能 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-comment">&lt;!-- 日志保留时间设置7天 7*24*60*60 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>  <span class="hljs-comment">&lt;!-- 日志储存地址 --&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log.server.url<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>http://hd001:19888/jobhistory/logs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h6 id="编辑-slaves"><a href="#编辑-slaves" class="headerlink" title="编辑 slaves"></a>编辑 slaves</h6>  <figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">hd001</span><br>hd002<br>hd003<br></code></pre></td></tr></table></figure></li><li><h5 id="namenode高可用测试"><a href="#namenode高可用测试" class="headerlink" title="namenode高可用测试"></a>namenode高可用测试</h5><ul><li><h6 id="首先启动集群journalnode集群服务"><a href="#首先启动集群journalnode集群服务" class="headerlink" title="首先启动集群journalnode集群服务"></a>首先启动集群journalnode集群服务</h6>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">需要启动每个节点的 journalnode</span> <br><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cd</span> /home/admin/module/HA/hadoop-2.7.2</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sbin/hadoop-daemon.sh start journalnode</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">jps</span><br>    7684 Jps<br>    7609 JournalNode<br></code></pre></td></tr></table></figure></li><li><h6 id="格式化namenode"><a href="#格式化namenode" class="headerlink" title="格式化namenode"></a>格式化namenode</h6><p>  <font color='red'>注意: 为了使journalnode服务记录namenode初始信息,在格式化namenode前,需要先将journalnode集群服务启动,否则会失败</font></p>  <figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gradle">$ bin/hdfs namenode -format<br>#  Storage directory <span class="hljs-regexp">/home/</span>admin<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/hadoop-2.7.2/</span>data<span class="hljs-regexp">/tmp/</span>dfs/name has been successfully formatted.<br>#  出现这句话时,表示format成功<br></code></pre></td></tr></table></figure></li><li><h6 id="启动nn1的namenode"><a href="#启动nn1的namenode" class="headerlink" title="启动nn1的namenode"></a>启动nn1的namenode</h6>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sbin/hadoop-daemon.sh start namenode<br></code></pre></td></tr></table></figure></li><li><h6 id="nn2同步nn1-的元数据信息"><a href="#nn2同步nn1-的元数据信息" class="headerlink" title="nn2同步nn1 的元数据信息"></a>nn2同步nn1 的元数据信息</h6>  <figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">bin/hdfs </span>namenode -<span class="hljs-keyword">bootstrapStandby</span><br><span class="hljs-keyword"></span><br></code></pre></td></tr></table></figure></li><li><h6 id="启动nn2的namenode"><a href="#启动nn2的namenode" class="headerlink" title="启动nn2的namenode"></a>启动nn2的namenode</h6>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sbin/hadoop-daemon.sh start namenode<br><br></code></pre></td></tr></table></figure></li><li><h6 id="启动各个节点的datanode"><a href="#启动各个节点的datanode" class="headerlink" title="启动各个节点的datanode"></a>启动各个节点的datanode</h6>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">每隔节点都需要启动 hd001 hd002 hd003</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sbin/hadoop-daemon.sh start datanode</span> <br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sh ~/jpsutil.sh</span><br>=========== admin@hd001 ============<br>11010 DataNode<br>11400 Jps<br>10286 JournalNode<br>=========== admin@hd002 ============<br>9744 Jps<br>9473 DataNode<br>9317 NameNode<br>8959 JournalNode<br>=========== admin@hd003 ============<br>8881 DataNode<br>8388 JournalNode<br>9161 Jps<br>8746 NameNode<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">hd002,hd003中的namenode启动成功</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">此时 访问 http://hd002:50070/  和 http://hd003:50070/  均发现两个节点处于 standy状态</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">访问http://hd002:50070/explorer.html<span class="hljs-comment">#/ 文件目录会提示时:</span></span> <br>Operation category READ is not supported in state standby<br>因为没有active的name造成的<br><br></code></pre></td></tr></table></figure></li><li><h6 id="手动激活nn1中的namenode到active"><a href="#手动激活nn1中的namenode到active" class="headerlink" title="手动激活nn1中的namenode到active"></a>手动激活nn1中的namenode到active</h6>  <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">bin/hdfs haadmin -transitionToActive nn1<br><span class="hljs-comment">#此时再访问 http://hd002:50070/dfshealth.html#tab-overview 显示节点处于active</span><br>访问 http:<span class="hljs-regexp">//</span>hd002:<span class="hljs-number">50070</span><span class="hljs-regexp">/explorer.html#/</span> 可以正常访问<br></code></pre></td></tr></table></figure></li><li><h6 id="手动激活nn2中的namenode到active"><a href="#手动激活nn2中的namenode到active" class="headerlink" title="手动激活nn2中的namenode到active"></a>手动激活nn2中的namenode到active</h6>  <figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs pf">bin/hdfs haadmin -transitionToActive nn2<br>Automatic failover is enabled <span class="hljs-keyword">for</span> NameNode at hd002/<span class="hljs-number">192.168</span>.<span class="hljs-number">1.21</span>:<span class="hljs-number">9000</span><br>Refusing <span class="hljs-keyword">to</span> manually manage HA <span class="hljs-keyword">state</span>, since it may cause<br>a split-brain scenario or other incorrect <span class="hljs-keyword">state</span>.<br>If you are very sure you know what you are doing, please<br>specify the --forcemanual flag.<br><br>如果使用<br>bin/hdfs haadmin -transitionToActive nn2  --forcemanual<br>会提示 nn1已经处于active 不会被切换,切换失败<br><span class="hljs-number">18</span>/<span class="hljs-number">04</span>/<span class="hljs-number">16</span> <span class="hljs-number">18</span>:<span class="hljs-number">56</span>:<span class="hljs-number">57</span> WARN ha.HAAdmin: Proceeding with manual HA <span class="hljs-keyword">state</span> management even though<br>automatic failover is enabled <span class="hljs-keyword">for</span> NameNode at hd002/<span class="hljs-number">192.168</span>.<span class="hljs-number">1.21</span>:<span class="hljs-number">9000</span><br>transitionToActive: Node nn1 is already active<br>Usage: haadmin [-transitionToActive [--forceactive] <span class="hljs-variable">&lt;serviceId&gt;</span>]<br>    <br></code></pre></td></tr></table></figure></li><li><h6 id="手动激活nn1中的namenode到standby"><a href="#手动激活nn1中的namenode到standby" class="headerlink" title="手动激活nn1中的namenode到standby"></a>手动激活nn1中的namenode到standby</h6>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">bin/dfs haadmin -transitionToStandby nn1<br><span class="hljs-comment"># 切换完后后,再切换nn2到active可成功切换</span><br></code></pre></td></tr></table></figure></li></ul></li></ul><h4 id="HA的自动故障转移"><a href="#HA的自动故障转移" class="headerlink" title="HA的自动故障转移"></a>HA的自动故障转移</h4><pre><code class="hljs">    以上测试了手动故障转移的方式,下面配置自动故障转移&lt;br&gt;    HA的自动故障转移依赖于zookeeper</code></pre><ul><li><h5 id="配置zookeeper"><a href="#配置zookeeper" class="headerlink" title="配置zookeeper"></a>配置zookeeper</h5>  <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs awk">tar -zxvf zookeeper-<span class="hljs-number">3.4</span>.<span class="hljs-number">10</span>.tar.gz ~<span class="hljs-regexp">/module/</span>HA/<br>cd ~<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/zookeeper-3.4.10/</span><br>mkdir zkData<br>cd zkData<br>echo <span class="hljs-number">1</span> &gt; myid<br>cd ..<span class="hljs-regexp">/conf/</span><br>mv zoo_simple.cfg zoo.cfg<br>vim zoo.cfg<br><span class="hljs-comment"># 修改dataDir </span><br>dataDir=<span class="hljs-regexp">/home/</span>admin<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/zookeeper-3.4.10/</span>zkData<br><span class="hljs-comment">#末尾增加</span><br>server.<span class="hljs-number">1</span>=hd001:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span><br>server.<span class="hljs-number">2</span>=hd002:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span><br>server.<span class="hljs-number">3</span>=hd003:<span class="hljs-number">2888</span>:<span class="hljs-number">3888</span><br><br><span class="hljs-comment">#保存退出</span><br><span class="hljs-comment">#将 zookeeper分发到各个节点,修改zkData下myid文件中的值,于主机名称对应</span><br>scp -r ~<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/zookeeper-3.4.10  hd002:~/m</span>odule<span class="hljs-regexp">/HA/</span><br>scp -r ~<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/zookeeper-3.4.10  hd003:~/m</span>odule<span class="hljs-regexp">/HA/</span><br><br></code></pre></td></tr></table></figure><p>至此,zookeeper配置完成</p></li><li><h5 id="zookeeper启动测试"><a href="#zookeeper启动测试" class="headerlink" title="zookeeper启动测试"></a>zookeeper启动测试</h5>  <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment">#每台节点启动zookeeper服务</span><br>cd <span class="hljs-regexp">/home/</span>admin<span class="hljs-regexp">/module/</span>HA<span class="hljs-regexp">/zookeeper-3.4.10/</span><br>bin/zkServer.sh start<br><span class="hljs-comment">#查看进程</span><br>[admin@hd001 zookeeper-<span class="hljs-number">3.4</span>.<span class="hljs-number">10</span>]$ sh ~/jpsutil.sh<br>=========== admin@hd001 ============<br><span class="hljs-number">14452</span> Jps<br><span class="hljs-number">14390</span> QuorumPeerMain<br><span class="hljs-number">13033</span> DataNode<br><span class="hljs-number">10286</span> JournalNode<br>=========== admin@hd002 ============<br><span class="hljs-number">11785</span> DataNode<br><span class="hljs-number">13291</span> Jps<br><span class="hljs-number">11164</span> NameNode<br><span class="hljs-number">13230</span> QuorumPeerMain<br><span class="hljs-number">8959</span> JournalNode<br>=========== admin@hd003 ============<br><span class="hljs-number">12817</span> QuorumPeerMain<br><span class="hljs-number">8388</span> JournalNode<br><span class="hljs-number">10892</span> NameNode<br><span class="hljs-number">12879</span> Jps<br><span class="hljs-comment">#在其中一台启动zkCli.sh连接服务</span><br>ls /<br><br></code></pre></td></tr></table></figure></li><li><h5 id="hdfs-site-xml增加配置"><a href="#hdfs-site-xml增加配置" class="headerlink" title="hdfs-site.xml增加配置"></a>hdfs-site.xml增加配置</h5>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h5 id="core-site增加配置"><a href="#core-site增加配置" class="headerlink" title="core-site增加配置"></a>core-site增加配置</h5><p>  在 core-site.xml 增加</p>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- zookeeper通信客户端地址  --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>ha.zookeeper.quorum<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:2181,hd002:2181,hd003:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>  故障自动转移完成</p></li><li><h5 id="故障自动转移测试"><a href="#故障自动转移测试" class="headerlink" title="故障自动转移测试"></a>故障自动转移测试</h5><pre><code class="hljs">  - 先停掉节点&lt;br&gt;  sbin/stop-dfs.sh   - 初始化HA在Zookeeper中状态：&lt;br&gt;  bin/hdfs zkfc -formatZK  - 启动journalnode&lt;br&gt;  sbin/hadoop-daemon.sh start journalnode  - 启动dfs&lt;br&gt;  sbin/start-dfs.sh &lt;br&gt;  查看hd002:50070和hd003:50070,其中一台处于active    - kill active namenode &lt;br&gt;  sbin/hadoop-daemon.sh stop namenode &lt;br&gt;  查看hd002:50070和hd003:50070,刚刚处于standby的namoenode自动切换为active了.</code></pre></li></ul><h4 id="配置yarn-resourcemanager高可用"><a href="#配置yarn-resourcemanager高可用" class="headerlink" title="配置yarn-resourcemanager高可用"></a>配置yarn-resourcemanager高可用</h4><ul><li>编辑yarn-site.xml<blockquote><p>可参考 <a href="http://hadoop.apache.org/docs/r2.7.5/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html">Resourcemanager-HA官方文档</a>{:target&#x3D;”_blank”}</p></blockquote>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- reducer获取数据的方式 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!--启用resourcemanager ha--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!--声明两台resourcemanager的地址--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>cluster-yarn1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>rm1,rm2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!--指定zookeeper集群的地址--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd001:2181,hd001:2181,hd001:2181<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!--启用自动恢复--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-comment">&lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 日志聚集功能使能 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 日志保留时间设置7天 --&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log.server.url<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>http://hd001:19888/jobhistory/logs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li></ul><p>配置完成,分发文件</p><ul><li><p>rm1启动yarn集群<br>  sbin&#x2F;start-yarn.sh</p></li><li><p>rm2启动resourcemanager<br>  sbin&#x2F;yarn-daemon.sh start resourcemanager <br><br>  <font color='red'>注意:<br><br>      1.rm2的resourcemanager不会同yarn集群一起启动,需要单独启动;<br><br>      2.yarn的resourcemanager的HA,不会经过ZKFC控制,是通过yarn集群自己进行自动切换的</font>  </p></li><li><p>查看集群进程</p>  <figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs elixir">sh ~/jpsutil.sh<br>[admin<span class="hljs-variable">@hd001</span> hadoop<span class="hljs-number">-2.7</span>.<span class="hljs-number">2</span>]<span class="hljs-variable">$ </span>sh ~/jpsutil.sh<br>=========== admin<span class="hljs-variable">@hd001</span> ============<br><span class="hljs-number">27937</span> <span class="hljs-title class_">ResourceManager</span><br><span class="hljs-number">24390</span> <span class="hljs-title class_">QuorumPeerMain</span><br><span class="hljs-number">27160</span> <span class="hljs-title class_">JournalNode</span><br><span class="hljs-number">27513</span> <span class="hljs-title class_">NodeManager</span><br><span class="hljs-number">28026</span> <span class="hljs-title class_">Jps</span><br><span class="hljs-number">26894</span> <span class="hljs-title class_">DataNode</span><br>=========== admin<span class="hljs-variable">@hd002</span> ============<br><span class="hljs-number">27505</span> <span class="hljs-title class_">ResourceManager</span><br><span class="hljs-number">27271</span> <span class="hljs-title class_">DFSZKFailoverController</span><br><span class="hljs-number">28232</span> <span class="hljs-title class_">Jps</span><br><span class="hljs-number">27659</span> <span class="hljs-title class_">NodeManager</span><br><span class="hljs-number">22556</span> <span class="hljs-title class_">QuorumPeerMain</span><br><span class="hljs-number">27116</span> <span class="hljs-title class_">JournalNode</span><br><span class="hljs-number">26988</span> <span class="hljs-title class_">DataNode</span><br><span class="hljs-number">26861</span> <span class="hljs-title class_">NameNode</span><br>=========== admin<span class="hljs-variable">@hd003</span> ============<br><span class="hljs-number">25202</span> <span class="hljs-title class_">JournalNode</span><br><span class="hljs-number">25074</span> <span class="hljs-title class_">DataNode</span><br><span class="hljs-number">24968</span> <span class="hljs-title class_">NameNode</span><br><span class="hljs-number">25595</span> <span class="hljs-title class_">NodeManager</span><br><span class="hljs-number">22092</span> <span class="hljs-title class_">QuorumPeerMain</span><br><span class="hljs-number">26044</span> <span class="hljs-title class_">Jps</span><br><span class="hljs-number">25357</span> <span class="hljs-title class_">DFSZKFailoverController</span><br></code></pre></td></tr></table></figure><p>可访问 rm1 和 rm2, hd002:8088  hd003:8088<br><br>本文中 rm2 hd002处于activ中, 当访问hd001:8088时,会自动重定向到 hd002:8088&#x2F;cluster<br><br>当将 rm2 停止 后,rm1处于active中<br></p></li><li><h4 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h4><ul><li><h5 id="图解hadoop-HA"><a href="#图解hadoop-HA" class="headerlink" title="图解hadoop-HA"></a>图解hadoop-HA</h5>  <img src="https://stone-upyun.b0.aicdn.com/blog20180416172754.png!700x999"></li><li><h5 id="jpsutil-sh"><a href="#jpsutil-sh" class="headerlink" title="jpsutil.sh"></a>jpsutil.sh</h5>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> admin@hd001 admin@hd002 admin@hd003<br><span class="hljs-keyword">do</span><br>        <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;=========== <span class="hljs-variable">$i</span> ============&quot;</span><br>        ssh <span class="hljs-variable">$i</span> <span class="hljs-string">&#x27;jps&#x27;</span><br><span class="hljs-keyword">done</span> <br></code></pre></td></tr></table></figure></li></ul></li><li><h4 id="hadoop-HA官方文档地址-target-x3D-”-blank”"><a href="#hadoop-HA官方文档地址-target-x3D-”-blank”" class="headerlink" title="hadoop-HA官方文档地址{:target&#x3D;”_blank”}"></a>hadoop-HA<a href="http://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html">官方文档地址</a>{:target&#x3D;”_blank”}</h4></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>zookeeper集群搭建</title>
      <link href="/hadoop/2018-04-13-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
      <url>/hadoop/2018-04-13-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul><li>jdk环境</li><li>zookeeper安装包(本文使用的是zookeeper-3.4.10 版本) 可到<a href="http://zookeeper.apache.org/releases.html">Zookeeper官网</a>{:target&#x3D;”_blank”}下载</li></ul><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h4 id="1-解压文件"><a href="#1-解压文件" class="headerlink" title="1.解压文件"></a>1.解压文件</h4><p>解压目标路径 &#x2F;home&#x2F;admin&#x2F;module</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxvf zookeeper-3.4.10.tar.gz -C /home/admin/module/<br></code></pre></td></tr></table></figure><h4 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2.修改配置"></a>2.修改配置</h4><p>进入到zookeeper-3.4.10目录修改相关位置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /home/admin/module/zookeeper-3.4.10<br><span class="hljs-built_in">mkdir</span> zkData<br><span class="hljs-built_in">cd</span> conf<br><span class="hljs-built_in">mv</span> zoo_sample.cfg zoo.cfg<br>vim zoo.cfg<br>dataDir=/home/admin/module/zookeeper-3.4.10/zkData<br>保存退出<br><br><span class="hljs-built_in">cd</span> ../zkData<br><span class="hljs-built_in">echo</span> 2 &gt; myid<br><span class="hljs-comment">## 最后一行下面增加</span><br><span class="hljs-comment">## 配置集群服务地址</span><br>server.2=hd001:2888:3888<br>server.3=hd002:2888:3888<br>server.4=hd003:2888:3888<br><br></code></pre></td></tr></table></figure><h5 id="配置参数解读"><a href="#配置参数解读" class="headerlink" title="配置参数解读"></a>配置参数解读</h5><p>Server.A&#x3D;B:C:D。 <br><br>A是一个数字，表示这个是第几号服务器； <br><br>B是这个服务器的ip地址； <br><br>C是这个服务器与集群中的Leader服务器交换信息的端口； <br><br>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的 <br></p><h4 id="3-分发文件"><a href="#3-分发文件" class="headerlink" title="3.分发文件"></a>3.分发文件</h4><p>完成以上配置后,将此目录分发到其他机器节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">rsync -rvl /home/admin/module/zookeeper-3.4.10 hd002:~/module/<br>rsync -rvl /home/admin/module/zookeeper-3.4.10 hd003:~/module/<br></code></pre></td></tr></table></figure><p><font color="red">分发完成后修改对应文件 zookeeper-3.4.10&#x2F;zkData&#x2F;myid 中对应的值 ,<br><br>其中 myid 文件中的值与 server.3&#x3D;hd002:2888:3888,server.3中的3对应<br></font></p><h5 id="注意"><a href="#注意" class="headerlink" title=" 注意"></a><font color="red"> 注意</font></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">[1]scp -r /home/admin/module/zookeeper-3.4.10 hd002:~/module/<br>[2]scp -r /home/admin/module/zookeeper-3.4.10/ hd002:~/module/<br>[1],[2]效果一样<br><br>&lt;1&gt;/rsync -rvl /home/admin/module/zookeeper-3.4.10 hd002:~/module/<br>&lt;2&gt;rsync -rvl /home/admin/module/zookeeper-3.4.10/ hd002:~/module/<br>&lt;1&gt;&lt;2&gt; 是不同的<br>&lt;1&gt;中是将整个目录和目录下所有文件分发给hd002,会在hd002:~/module/下创建一个新的zookeeper-3.4.10目录并将文件同步过去<br>&lt;2&gt;是将整个目录下所有文件分发给hd001,不会将目录本身分发出去<br><br></code></pre></td></tr></table></figure><h4 id="4-启动和查看命令"><a href="#4-启动和查看命令" class="headerlink" title="4.启动和查看命令"></a>4.启动和查看命令</h4><p>需要分别到每台服务进行启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># hd001</span><br><span class="hljs-built_in">cd</span> /home/admin/module/zookeeper-3.4.10<br>bin/zkServer.sh start<br>bin/zkServer.sh status<br><span class="hljs-comment">#状态结果</span><br>[admin@hd001 zookeeper-3.4.10]$ bin/zkServer.sh status<br>ZooKeeper JMX enabled by default<br>Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg<br>Mode: follower<br><br><span class="hljs-comment"># hd002</span><br><span class="hljs-built_in">cd</span> /home/admin/module/zookeeper-3.4.10<br>bin/zkServer.sh start<br>bin/zkServer.sh status<br><span class="hljs-comment">#状态结果(因本地已经重启过很多次 .此台机器第一次按顺序启动将会被选举为 leader的)</span><br>[admin@hd002 ~]$ ./module/zookeeper-3.4.10/bin/zkServer.sh status<br>ZooKeeper JMX enabled by default<br>Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg<br>Mode: follower<br><span class="hljs-comment"># hd003</span><br><span class="hljs-built_in">cd</span> /home/admin/module/zookeeper-3.4.10<br>bin/zkServer.sh start<br>bin/zkServer.sh status<br><span class="hljs-comment">#状态结果</span><br>[admin@hd003 ~]$ ./module/zookeeper-3.4.10/bin/zkServer.sh status<br>ZooKeeper JMX enabled by default<br>Using config: /home/admin/module/zookeeper-3.4.10/bin/../conf/zoo.cfg<br>Mode: leader<br></code></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>macos装虚拟机NAT网络互ping问题</title>
      <link href="/linux/2018-04-12-macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98/"/>
      <url>/linux/2018-04-12-macos%E8%A3%85%E8%99%9A%E6%8B%9F%E6%9C%BANAT%E7%BD%91%E7%BB%9C%E4%BA%92ping%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul><li>macOS系统装虚拟机,虚拟机与宿主机互ping不通</li></ul><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ul><li>修改宿主机的VMware网络设置</li><li>编辑文件目录 <blockquote><p>&#x2F;Library&#x2F;Preferences&#x2F;VMware Fusion&#x2F;networking<br>内容如下</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">VERSION=1,0<br><span class="hljs-comment"># 此处禁用DHCP模式</span><br>answer VNET_1_DHCP no<br>answer VNET_1_DHCP_CFG_HASH A1C3DC05C0F343C380B049B0A45A95DD63494961<br>answer VNET_1_HOSTONLY_NETMASK 255.255.255.0<br>answer VNET_1_HOSTONLY_SUBNET 192.168.181.0<br><span class="hljs-comment"># 宿主机的ip地址</span><br>answer VNET_1_VIRTUAL_ADAPTER <span class="hljs-built_in">yes</span><br>answer VNET_1_VIRTUAL_ADAPTER_ADDR 10.10.1.67<br><span class="hljs-comment"># 禁用DHCP模式</span><br>answer VNET_8_DHCP no<br>answer VNET_8_DHCP_CFG_HASH 5197E3A254D370D2E0B1CCD8B3F59319D3A67453<br><span class="hljs-comment"># 子网掩码</span><br>answer VNET_8_HOSTONLY_NETMASK 255.255.255.0<br><span class="hljs-comment"># 子网网段 192.168.1.0-192.168.255.0</span><br>answer VNET_8_HOSTONLY_SUBNET 192.168.1.0<br>answer VNET_8_NAT <span class="hljs-built_in">yes</span><br>answer VNET_8_VIRTUAL_ADAPTER <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>本地jekyll-server启动证书错误问题</title>
      <link href="/blog/2018-04-09-%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98/"/>
      <url>/blog/2018-04-09-%E6%9C%AC%E5%9C%B0jekyll-server%E5%90%AF%E5%8A%A8%E8%AF%81%E4%B9%A6%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<hr><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述:"></a>问题描述:</h3><blockquote><p>本地启动jekyll server 博客时显示如下错误:</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Liquid Exception: SSL_connect returned=1 errno=0 state=error: certificate verify failed <span class="hljs-keyword">in</span> /_layouts/page.html<br>jekyll 3.6.2 | Error:  SSL_connect returned=1 errno=0 state=error: certificate verify failed    <br></code></pre></td></tr></table></figure><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h3><blockquote><p>1.下载一个证书 名称为: cacert.pem</p></blockquote><blockquote><p>2.将证书路径设置到系统变量中 </p></blockquote><blockquote><p>window下 可使用命令 set SSL_CERT_FILE&#x3D;d:&#x2F;XmacZone&#x2F;down&#x2F;cacert.pem</p></blockquote><blockquote><p>linux 或macos 编制.brash 或.zshrc </p></blockquote><blockquote><p>最后一行添加 export  SSL_CERT_FILE&#x3D;&#x2F;Users&#x2F;XmacZone&#x2F;down&#x2F;cacert.pem   ;执行命令 source ~&#x2F;.zshrc 即可.</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Blog </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>hadoop完全分布式环境搭建</title>
      <link href="/hadoop/2018-04-09-hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80/"/>
      <url>/hadoop/2018-04-09-hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA(%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F)%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作:"></a>准备工作:</h2><ul><li>三台或三台以上机器(本文以三台虚拟机为例)<blockquote><p>centOS 6.8 </p><p>VMware Fusion 10.1(maxos的虚拟机版本),window下推荐VMware 12或14稳定版 </p></blockquote></li><li>每台机器安装jdk,hadoop,并配置相应的环境变量<blockquote><p>jdk 1.8</p><p>hadoop 2.7.2</p></blockquote></li></ul><h2 id="安装规划"><a href="#安装规划" class="headerlink" title="安装规划"></a>安装规划</h2><ul><li><p>系统中新建个非root用户, 并且 将此用户修改用户root权限</p></li><li><p>所需安装文件全部存于&#x2F;opt&#x2F;software目录中</p></li><li><p>所有软件安装到  &#x2F;opt&#x2F;module目录下</p></li><li><p>修改&#x2F;opt目录的拥有者  chgroup hadoop hdaoop </p><p>  | 主机  | hadoop101 |  hadoop102  | hadoop103 |<br>  | 角色       | namenode  | datanode    | datanode |<br>  |           | datanode  | resourcemanager |nodemanager     |<br>  |           | nodemanager  |  nodemanager   | secondaryNameNode |</p></li></ul><h2 id="机器设置"><a href="#机器设置" class="headerlink" title="机器设置"></a>机器设置</h2><ul><li><p>配置三台机器的ip为静态ip,并能够互相ping通,且能ping通外网</p></li><li><p>以下已一台机器为例</p></li><li><h4 id="新建用户"><a href="#新建用户" class="headerlink" title="新建用户"></a>新建用户</h4><blockquote><p>新建nginx用户并增加到nginx工作组,-g后跟组名 组和用户名都为hadoop,也可更改为其他用户名<br>useradd -g hadoop hadoop  (后续文章都以hadoop用户登录系统做操作)</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">1、建用户：<br>adduser 用户名                           //新建用户<br>passwd 用户名                           //给用户设置密码<br>2、建工作组<br>groupadd 组名                         //新建工作组<br>3、新建用户同时增加工作组<br>useradd -g nginx nginx               //新建nginx用户并增加到nginx工作组,-g后跟组名<br>注：：-g 所属组 -d 家目录 -s 所用的SHELL<br>4、给已有的用户增加工作组<br>usermod -G groupname username<br></code></pre></td></tr></table></figure></li><li><h4 id="设置静态ip"><a href="#设置静态ip" class="headerlink" title="设置静态ip"></a>设置静态ip</h4><blockquote><p>vim &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-eth0</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs bash">DEVICE=eth0<br>TYPE=Ethernet<br>UUID=c4fcd4b8-9338-4489-bee5-6797d077a036<br>NM_CONTROLLED=<span class="hljs-built_in">yes</span><br><span class="hljs-comment"># 设置静态ip地址</span><br>IPADDR=192.168.1.102<br><span class="hljs-comment"># 网关</span><br>GATEWAY=192.168.1.2<br>NETMASK=255.255.255.0<br><span class="hljs-comment"># 系统启动时启用</span><br>ONBOOT=<span class="hljs-built_in">yes</span><br><span class="hljs-comment"># 设置为静态ip</span><br>BOOTPROTO=static<br><span class="hljs-comment"># dns</span><br>DNS1=114.114.114.114<br>PREFIX=24<br>DEFROUTE=<span class="hljs-built_in">yes</span><br>IPV4_FAILURE_FATAL=<span class="hljs-built_in">yes</span><br><span class="hljs-comment"># 禁用ipv6</span><br>IPV6INIT=no<br>NAME=<span class="hljs-string">&quot;System eth0&quot;</span><br><span class="hljs-comment"># mac地址 对应 /etc/udev/rules.d/70-persistent-net.rules 中的 ATTR&#123;address&#125;的值</span><br><span class="hljs-comment"># SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, DRIVERS==&quot;?*&quot;, ATTR&#123;address&#125;==&quot;00:0c:29:d8:7f:e3&quot;, ATTR&#123;type&#125;==&quot;1&quot;, KERNEL==&quot;eth*&quot;, NAME=&quot;eth0&quot;</span><br>HWADDR=00:0c:29:d8:7f:e3<br>LAST_CONNECT=1520522957<br></code></pre></td></tr></table></figure></blockquote></li><li><h4 id="修改hostname"><a href="#修改hostname" class="headerlink" title="修改hostname"></a>修改hostname</h4><blockquote><p>vim &#x2F;etc&#x2F;sysconfig&#x2F;network</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">NETWORKING=<span class="hljs-built_in">yes</span><br>HOSTNAME=hadoop102<br></code></pre></td></tr></table></figure></li><li><h4 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h4><blockquote><p>sudo reboot -h now</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo reboot -h now <br></code></pre></td></tr></table></figure></li><li><h4 id="修改其他机器的静态ip和hostname"><a href="#修改其他机器的静态ip和hostname" class="headerlink" title="修改其他机器的静态ip和hostname"></a>修改其他机器的静态ip和hostname</h4><p>此处忽略,可以参考第一台的设置</p></li></ul><h2 id="安装jdk-和-hadoop"><a href="#安装jdk-和-hadoop" class="headerlink" title="安装jdk 和 hadoop"></a>安装jdk 和 hadoop</h2><ul><li><p>下载jdk 和 hadoop压缩包存于 &#x2F;opt&#x2F;software目录中</p></li><li><p>将jdk压缩包,hadoop压缩包解到  &#x2F;opt&#x2F;module </p><blockquote><p>tar -zxvf </p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 解压命令</span><br>tar -zxvf /opt/software/jdk-8u144-linux-x64.tar.gz -C /opt/module<br>tar -zxvf /opt/software/hadoop-2.7.2.tar.gz -C /opt/module<br></code></pre></td></tr></table></figure></li><li><p>配置JAVA_HOME和PATH ,编辑&#x2F;etc&#x2F;profile文件,最后一行添加如下</p><blockquote><p>sudo vim &#x2F;etc&#x2F;profile</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin<br><span class="hljs-built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/bin<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/sbin<br></code></pre></td></tr></table></figure></li><li><p>检验是否安装成功</p><blockquote><p>java -version </p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">java version <span class="hljs-string">&quot;1.8.0_144&quot;</span><br>Java(TM) SE Runtime Environment (build 1.8.0_144-b01)<br>Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)<br></code></pre></td></tr></table></figure><blockquote><p>hadoop version</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">Hadoop 2.7.2<br>Subversion Unknown -r Unknown<br>Compiled by root on 2017-05-22T10:49Z<br>Compiled with protoc 2.5.0<br>From <span class="hljs-built_in">source</span> with checksum d0fda26633fa762bff87ec759ebe689c<br>This <span class="hljs-built_in">command</span> was run using /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar<br></code></pre></td></tr></table></figure></li></ul><h2 id="配置-hadoop"><a href="#配置-hadoop" class="headerlink" title="配置 hadoop"></a>配置 hadoop</h2><ul><li><p>进入到 &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop 目录下</p></li><li><h4 id="编辑hadoop-env-sh"><a href="#编辑hadoop-env-sh" class="headerlink" title="编辑hadoop-env.sh"></a>编辑hadoop-env.sh</h4><blockquote><p>vim hadoop-env.sh 配置JAVA_HOME</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144<br></code></pre></td></tr></table></figure></li><li><h4 id="编辑hdfs-site-xml"><a href="#编辑hdfs-site-xml" class="headerlink" title="编辑hdfs-site.xml"></a>编辑hdfs-site.xml</h4><blockquote><p>vim hdfs-site.xml</p></blockquote>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>        # hdfs文件系统中的文件副本数量 为3(一般情况,完全分布式都是3分以上基数份)<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        # 第二名称辅助节点地址和端口<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop104:50090<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        # 节点检测频率,用户namenode 检测datanode是否存活 120s<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>120<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        # namenode存name相关数据地址<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp/dfs/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>        #多namenode的name目录,其中 name1 和name2的数据不会重复<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///$&#123;hadoop.tmp.dir&#125;/dfs/name1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/name2<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        # 指定 dfs 相关的机器地址,用户上下线新的机器<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.hosts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        # 指定退役的节点<br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.hosts.exclude<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br><br></code></pre></td></tr></table></figure></li><li><h4 id="编辑-core-site-xml"><a href="#编辑-core-site-xml" class="headerlink" title="编辑 core-site.xml"></a>编辑 core-site.xml</h4><blockquote><p>vim core-site.xml</p></blockquote>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    # dfs 的名称节点<br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    # dfs 系统存取数据的目录<br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.trash.interval<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h4 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置yarn-site.xml</h4><blockquote><p>vim yarn-site.xml</p></blockquote>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!-- reducer获取数据的方式 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>        <span class="hljs-comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hd002<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- 日志聚集功能使能 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-comment">&lt;!-- 日志保留时间设置7天 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h4 id="编辑maperd-site-xml"><a href="#编辑maperd-site-xml" class="headerlink" title="编辑maperd-site.xml"></a>编辑maperd-site.xml</h4><blockquote><p>vim maperd-site.xml</p></blockquote>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 指定mr运行在yarn上 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>        <span class="hljs-comment">&lt;!--配置历史服务器 --&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop101:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hadoop101:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure></li><li><h4 id="配置集群地址"><a href="#配置集群地址" class="headerlink" title="配置集群地址"></a>配置集群地址</h4><blockquote><p>vim slaves</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop102<br>hadoop103<br>hadoop104<br></code></pre></td></tr></table></figure></li><li><h4 id="分发文件"><a href="#分发文件" class="headerlink" title="分发文件"></a>分发文件</h4></li><li><p>将&#x2F;opt&#x2F;moudle&#x2F;目录下所有文件分发到其他机器</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 可自定义脚本执行</span><br>rsync -rvl /opt/moudle hadoop@hadoop102:/opt/moudle<br>rsync -rvl /opt/moudle hadoop@hadoop103:/opt/moudle<br>rsync -rvl /opt/moudle hadoop@hadoop104:/opt/moudle<br></code></pre></td></tr></table></figure></li><li><p>将&#x2F;etc&#x2F;profile文件分发到其他机器</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rsync -rvl /etc/profile hadoop@hadoop102:/etc<br></code></pre></td></tr></table></figure></li><li><h4 id="启动查看结果"><a href="#启动查看结果" class="headerlink" title="启动查看结果"></a>启动查看结果</h4><blockquote><p>hadoop101上 启动 dfs </p></blockquote>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sbin/start-dfs.sh<br></code></pre></td></tr></table></figure><blockquote><p>hadoop102上 启动 yarn</p></blockquote>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sbin/start-yarn.sh<br></code></pre></td></tr></table></figure><blockquote><p>查看结果</p></blockquote>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">hadoop101$ jps<br>36577 SecondaryNameNode<br>38209 Jps<br>35314 DataNode<br>35604 NodeManager<br>35160 NameNode<br><br>hadoop102$ jps<br>37283 NodeManager<br>36981 ResourceManager<br>36829 DataNode<br>41519 Jps<br><br>hadoop103$ jps<br>36577 SecondaryNameNode<br>36678 NodeManager<br>36438 DataNode<br>41403 Jps<br><br></code></pre></td></tr></table></figure></li></ul><h2 id="图解说明"><a href="#图解说明" class="headerlink" title="图解说明"></a>图解说明</h2><ul><li><h4 id="图解namenode工作机制"><a href="#图解namenode工作机制" class="headerlink" title="图解namenode工作机制"></a>图解namenode工作机制</h4><img src="https://stone-upyun.b0.aicdn.com/blog20180416172857.png!700x999"></li><li><h4 id="图解datanode工作机制"><a href="#图解datanode工作机制" class="headerlink" title="图解datanode工作机制"></a>图解datanode工作机制</h4><img src="https://stone-upyun.b0.aicdn.com/blog20180416173056.png!700x999"></li><li><h4 id="图解yarn架构"><a href="#图解yarn架构" class="headerlink" title="图解yarn架构"></a>图解yarn架构</h4><img src="https://stone-upyun.b0.aicdn.com/blog20180416173218.png!700x999"></li></ul><h3 id="自定义脚本分发文件"><a href="#自定义脚本分发文件" class="headerlink" title="自定义脚本分发文件"></a>自定义脚本分发文件</h3><blockquote><p>新建自定义脚本文件 touch &#x2F;usr&#x2F;bin&#x2F;xsync</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">chmod</span> +x /usr/bin/xsync<br>vim /usr/bin/xsync<br></code></pre></td></tr></table></figure><pre><code class="hljs"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-comment"># 获取输入参数个数</span><br>pcount=<span class="hljs-variable">$#</span><br><span class="hljs-keyword">if</span>((pcount==0));<span class="hljs-keyword">then</span><br><span class="hljs-built_in">echo</span> no args;<br><span class="hljs-built_in">exit</span>;<br><span class="hljs-keyword">fi</span><br><br><span class="hljs-comment"># 获取文件名</span><br>p1=<span class="hljs-variable">$1</span><br>fname=`<span class="hljs-built_in">basename</span> <span class="hljs-variable">$p1</span>`<br><span class="hljs-built_in">echo</span> fname=<span class="hljs-variable">$fname</span><br><br><span class="hljs-comment"># 获取上机目录到绝对路径</span><br><br>pdir=`<span class="hljs-built_in">cd</span> -P $(<span class="hljs-built_in">dirname</span> <span class="hljs-variable">$p1</span>); <span class="hljs-built_in">pwd</span>`<br><br><span class="hljs-built_in">echo</span> pdir=<span class="hljs-variable">$pdir</span><br><br><span class="hljs-comment"># 获取当前用户名</span><br>user=`<span class="hljs-built_in">whoami</span>`<br><br><span class="hljs-keyword">for</span>((host=103;host&lt;109;host++));<span class="hljs-keyword">do</span><br>        <span class="hljs-built_in">echo</span> --------------------hadoop<span class="hljs-variable">$host</span>-----------------<br>        rsync -rvl <span class="hljs-variable">$pdir</span>/<span class="hljs-variable">$fname</span> <span class="hljs-variable">$user</span>@hadoop<span class="hljs-variable">$host</span>:<span class="hljs-variable">$pdir</span><br><span class="hljs-keyword">done</span><br><br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;success&quot;</span><br></code></pre></td></tr></table></figure></code></pre>]]></content>
      
      
      <categories>
          
          <category> Hadoop </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>linux下恢复删除的文件</title>
      <link href="/linux/2017-07-18-linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6/"/>
      <url>/linux/2017-07-18-linux%E4%B8%AD%E6%81%A2%E5%A4%8D%E5%88%A0%E9%99%A4%E7%9A%84%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux-Ubuntu-修复删除的文件"><a href="#Linux-Ubuntu-修复删除的文件" class="headerlink" title="Linux(Ubuntu)修复删除的文件"></a>Linux(Ubuntu)修复删除的文件</h2><p>本人基于Ubuntu server 16.04 环境下,其他linux系统类似.<br>作为一个初学者,难免有不小心删除文件的误操作,google了下,成功恢复了.</p><h3 id="查看自己的文件系统和分区"><a href="#查看自己的文件系统和分区" class="headerlink" title="查看自己的文件系统和分区"></a>查看自己的文件系统和分区</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sh">hadoop@ubuntu-ser1:~/devapp$ <span class="hljs-built_in">df</span> -T /home<br>Filesystem                        Type 1K-blocks    Used Available Use% Mounted on<br>/dev/mapper/ubuntu--ser1--vg-root ext4  18982780 3766336  14229104  21% /<br><br><span class="hljs-comment">## /dev/mapper/ubuntu--ser1--vg-root 就是当前系统所在分区  ext4是文件系统类型</span><br><br></code></pre></td></tr></table></figure><h3 id="安装恢复文件所需的软件extundelete"><a href="#安装恢复文件所需的软件extundelete" class="headerlink" title="安装恢复文件所需的软件extundelete"></a>安装恢复文件所需的软件extundelete</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo apt install extundelete -y<br><br></code></pre></td></tr></table></figure><h3 id="恢复文件"><a href="#恢复文件" class="headerlink" title="恢复文件"></a>恢复文件</h3><p>跳转到一个目录,最好是不需要的目录,因为一会恢复的文件会恢复到这个目录;例如,我跳到了我刚刚删除文件的那个目录</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh"><span class="hljs-built_in">cd</span> ~/devapp/<br><br></code></pre></td></tr></table></figure><p>然后执行</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sh">sudo extundelete /dev/mapper/ubuntu--ser1--vg-root --restore-all<br><span class="hljs-comment">## /dev/mapper/ubuntu--ser1--vg-root 这个是文件所在的分区,就是刚刚 df -T /home,home目录所在的分区地址,参数--restore-all 是恢复所有最近删除的文件</span><br><br></code></pre></td></tr></table></figure><p>完成后,即可在当前目录下产生一个 RECOVERED_FILES文件夹,里面放着这个分区近期删除的文件,至此恢复完成.</p><p>参考博客<a href="http://nphard.me/2015/09/30/linux-ubuntu-rm-hui-fu/">http://nphard.me/2015/09/30/linux-ubuntu-rm-hui-fu/</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>docker学习笔记(二)Dockerfile</title>
      <link href="/docker/2017-07-13-docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C--Dockerfile/"/>
      <url>/docker/2017-07-13-docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C--Dockerfile/</url>
      
        <content type="html"><![CDATA[<h2 id="docker学习笔记二–Dockerfile"><a href="#docker学习笔记二–Dockerfile" class="headerlink" title="docker学习笔记二–Dockerfile"></a>docker学习笔记二–Dockerfile</h2><hr><p>参考自<a href="https://docs.docker.com/engine/reference/builder/#usage">官方文档-Dockerfile</a>部分</p><h3 id="一-Dockerfile中常用的指令简介"><a href="#一-Dockerfile中常用的指令简介" class="headerlink" title="(一)Dockerfile中常用的指令简介"></a>(一)Dockerfile中常用的指令简介</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs bash">FROM <span class="hljs-comment">#来源于某个基础镜像</span><br>FROM ubuntu 16.04<br><br><br>LABEL<br>ARG SPRING_PROFILE_ACTIVE <span class="hljs-comment">#获取外部参数 SPRING_PROFILE_ACTIVE为外部参数的名称</span><br>RUN  <span class="hljs-comment">#运行镜像中系统级的命令</span><br>RUN apt-get uppdate &amp;&amp; apt-get install -y <br><br>RUN apt-get update &amp;&amp; apt-get install -y \<br>    aufs-tools \<br>    automake \<br>    build-essential \<br>    curl \<br>    dpkg-sig \<br>    libcap-dev \<br>    libsqlite3-dev \<br>    mercurial \<br>    reprepro \<br>    ruby1.9.1 \<br>    ruby1.9.1-dev \<br>    s3cmd=1.1.* \<br> &amp;&amp; <span class="hljs-built_in">rm</span> -rf /var/lib/apt/lists/*<br><br>RUN [<span class="hljs-string">&quot;/bin/bash&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>, <span class="hljs-string">&quot;set -o pipefail &amp;&amp; wget -O - https://some.site | wc -l &gt; /number&quot;</span>]<br><br>CMD  <span class="hljs-comment">#运行非系统级别的命令</span><br>CMD [<span class="hljs-string">&quot;perl&quot;</span>, <span class="hljs-string">&quot;-de0&quot;</span>]<br>ENV  <span class="hljs-comment">#设置系统参数</span><br>ADD or COPY <br><br>COPY /home/userName/xxx.jar  /images/  <span class="hljs-comment">#讲系统中的内容copy到镜像中的指定目录</span><br>ENV profile <span class="hljs-variable">$&#123;SPRING_PROFILE_ACTIVE&#125;</span> <span class="hljs-comment">#设置参数  $&#123;SPRING_PROFILE_ACTIVE&#125;为外部传入参数</span><br>CMD [bash,-c,java -jar /xxx.jar --spring.profiles.active=<span class="hljs-variable">$&#123;profile&#125;</span>]<br><br>(/home/userName/xxx.jar为当前系统目录下的内容) 目标地址为镜像目录 /images/<br> <br>EXPOSE  <span class="hljs-comment"># 不常用,后续补充该字段</span><br>ENTRYPOINT<br>VOLUME<br>USER<br>WORKDIR<br>ONBUILD<br><br></code></pre></td></tr></table></figure><h3 id="二-一些简单的Dockerfile示例"><a href="#二-一些简单的Dockerfile示例" class="headerlink" title="(二)一些简单的Dockerfile示例"></a>(二)一些简单的Dockerfile示例</h3><blockquote><p>以下为一个简介版本的Dockerfile</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">FROM openjdk:8<br>ARG SPRING_PROFILE_ACTIVE<br> <br>ENV SPRING_PROFILE_ACTIVE <span class="hljs-variable">$&#123;SPRING_PROFILE_ACTIVE&#125;</span><br><br>COPY demo-www-1.0-SNAPSHOT.jar  /temp/<br><br>CMD [bash,-c,java -jar   /temp/demo-www-1.0-SNAPSHOT.jar --spring.profiles.active=<span class="hljs-variable">$&#123;SPRING_PROFILE_ACTIVE&#125;</span>] <br></code></pre></td></tr></table></figure><blockquote><p>项目中使用的镜像</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 基于一个简介版本的可运行jdk环境的docker镜像</span><br>FROM reg.longdai.com/base/openjdk:8u131-jdk-alpine<br><br><span class="hljs-comment"># 作者信息</span><br>MAINTAINER mritd &lt;mritd@mritd.me&gt;<br><br><span class="hljs-comment"># 获取参数</span><br>ARG SPRING_PROFILE_ACTIVE<br>ARG PROJECT_BUILD_FINALNAME<br><br><span class="hljs-comment"># 设置时区,项目参数,项目名称</span><br>ENV TZ <span class="hljs-string">&#x27;Asia/Shanghai&#x27;</span><br>ENV SPRING_PROFILE_ACTIVE <span class="hljs-variable">$&#123;SPRING_PROFILE_ACTIVE&#125;</span><br>ENV PROJECT_BUILD_FINALNAME <span class="hljs-variable">$&#123;PROJECT_BUILD_FINALNAME&#125;</span><br><br><span class="hljs-comment"># 运行命令设置和安装 搭建项目所需要环境</span><br>RUN apk upgrade --update \<br>    &amp;&amp; apk add tzdata bash \<br>    &amp;&amp; <span class="hljs-built_in">ln</span> -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \<br>    &amp;&amp; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Asia/Shanghai&quot;</span> &gt; /etc/timezone \<br>    &amp;&amp; <span class="hljs-built_in">rm</span> -rf /var/cache/apk/*<br><br><span class="hljs-comment"># copy 项目中可运行的jar包到镜像中</span><br>COPY target/<span class="hljs-variable">$&#123;PROJECT_BUILD_FINALNAME&#125;</span>.jar /<span class="hljs-variable">$&#123;PROJECT_BUILD_FINALNAME&#125;</span>.jar<br><br><span class="hljs-comment"># 执行启动命令,项目使用spring-boot框架搭建,所以直接使用此命令就好</span><br>CMD [<span class="hljs-string">&quot;bash&quot;</span>,<span class="hljs-string">&quot;-c&quot;</span>,<span class="hljs-string">&quot;java -jar /<span class="hljs-variable">$&#123;PROJECT_BUILD_FINALNAME&#125;</span>.jar --spring.profiles.active=<span class="hljs-variable">$&#123;SPRING_PROFILE_ACTIVE&#125;</span>&quot;</span>]<br><br><span class="hljs-comment"># 更复杂的Dockerfile待更新</span><br></code></pre></td></tr></table></figure><h3 id="三-build-Dcokerfile"><a href="#三-build-Dcokerfile" class="headerlink" title="(三)build Dcokerfile"></a>(三)build Dcokerfile</h3><p>写完Dockerfile后,使用docker build 命令build自己的镜像</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs sh">docker build /path/to/a/Dockerfile  -t testDocker:1.2 .<br><br>docker -H https://githu.com/xxx/xxx.git  build -t image_name:1.12 --build-arg SPRING_PROFILE_ACTIVE=dohko   PROJECT_BUILD_FINALNAME=longdai-p2p-core longdai-core<br><br><span class="hljs-comment"># 为镜像指定tag</span><br>docker -H <span class="hljs-variable">$DOHKO_BUILD_HOST_19</span> tag <span class="hljs-variable">$IMAGE_NAME</span> <span class="hljs-variable">$LATEST_IMAGE_NAME</span><br><br><span class="hljs-comment"># 将镜像push到指定仓库</span><br>docker -H <span class="hljs-variable">$DOHKO_BUILD_HOST_19</span> push <span class="hljs-variable">$IMAGE_NAME</span><br><br><span class="hljs-comment"># 删除本地的docker镜像</span><br>docker -H <span class="hljs-variable">$DOHKO_BUILD_HOST_19</span>  rmi <span class="hljs-variable">$IMAGE_NAME</span><br><br><span class="hljs-comment"># 指定build的文件来源地址</span><br>-H https://githu.com/xxx/xxx.git <br><span class="hljs-comment"># build后的镜像名称为: image_name:1.12 </span><br>build -t image_name:1.12 <br><span class="hljs-comment"># build 时带入的参数</span><br>--build-arg SPRING_PROFILE_ACTIVE=dohko   PROJECT_BUILD_FINALNAME=longdai-p2p-core<br><span class="hljs-comment"># build的文件中的目录</span><br>longdai-core<br><br><br><br></code></pre></td></tr></table></figure><p>更多详细的命令参考<a href="https://docs.docker.com/engine/reference/builder/">官方文档Dockerfile reference</a></p>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>docker学习笔记(一)</title>
      <link href="/docker/2017-07-07-docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/"/>
      <url>/docker/2017-07-07-docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h2 id="docker学习笔记-一"><a href="#docker学习笔记-一" class="headerlink" title="docker学习笔记(一)"></a>docker学习笔记(一)</h2><h3 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h3><p>google一下,dokcer安装到本地即可.</p><blockquote><p>ubuntu,及其 参考地址 <a href="https://docs.docker.com/engine/installation/">官网安装地址</a>,进行安装.</p></blockquote><blockquote><p>macOs 需要下载安装包进行安装,或者使用 brew install docker 进行安装.</p></blockquote><p>安装完成后,允许docker info 查看安装信息,如果是生产环境使用,需要单独配置其他信息(如nfs&lt;文件存储相关信息&gt;),具体信息可访问docker官网进行配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs bash">    <br>➜  ~ docker info<br>Containers: 15<br> Running: 2<br> Paused: 0<br> Stopped: 13<br>Images: 17<br>Server Version: 17.03.1-ce<br>Storage Driver: overlay2<br> Backing Filesystem: extfs<br> Supports d_type: <span class="hljs-literal">true</span><br> Native Overlay Diff: <span class="hljs-literal">true</span><br>Logging Driver: json-file<br>Cgroup Driver: cgroupfs<br>Plugins:<br> Volume: <span class="hljs-built_in">local</span><br> Network: bridge host ipvlan macvlan null overlay<br>Swarm: inactive<br>Runtimes: runc<br>Default Runtime: runc<br>Init Binary: docker-init<br>containerd version: 4ab9917febca54791c5f071a9d1f404867857fcc<br>runc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe<br>init version: 949e6fa<br>Security Options:<br> seccomp<br>  Profile: default<br>Kernel Version: 4.9.27-moby<br>Operating System: Alpine Linux v3.5<br>OSType: linux<br>Architecture: x86_64<br>CPUs: 2<br>Total Memory: 1.952 GiB<br>Name: moby<br>ID: XAOC:ARKJ:IDEE:6Z57:KARG:V7GA:CQ2A:L3R3:4Y6L:VTDU:KACG:AGJ5<br>Docker Root Dir: /var/lib/docker<br>Debug Mode (client): <span class="hljs-literal">false</span><br>Debug Mode (server): <span class="hljs-literal">true</span><br> File Descriptors: 29<br> Goroutines: 36<br> System Time: 2017-07-07T08:41:25.128911087Z<br> EventsListeners: 1<br>No Proxy: *.<span class="hljs-built_in">local</span>, 169.254/16<br><br></code></pre></td></tr></table></figure><pre><code class="hljs">允许 docker version</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash">➜  ~ docker version<br> Client:<br>  Version:      17.03.1-ce<br>  API version:  1.27<br>  Go version:   go1.7.5<br>  Git commit:   c6d412e<br>  Built:        Tue Mar 28 00:40:02 2017<br>  OS/Arch:      darwin/amd64<br> <br> Server:<br>  Version:      17.03.1-ce<br>  API version:  1.27 (minimum version 1.12)<br>  Go version:   go1.7.5<br>  Git commit:   c6d412e<br>  Built:        Fri Mar 24 00:00:50 2017<br>  OS/Arch:      linux/amd64<br>  Experimental: <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><h3 id="运行hello-world"><a href="#运行hello-world" class="headerlink" title="运行hello world"></a>运行hello world</h3><p>docker run hello-world</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br>➜  ~ docker run hello-world<br>Unable to find image <span class="hljs-string">&#x27;hello-world:latest&#x27;</span> locally<br>latest: Pulling from library/hello-world<br>b04784fba78d: Pull complete<br>Digest: sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f<br>Status: Downloaded newer image <span class="hljs-keyword">for</span> hello-world:latest<br><br>Hello from Docker!<br>This message shows that your installation appears to be working correctly.<br><br>To generate this message, Docker took the following steps:<br> 1. The Docker client contacted the Docker daemon.<br> 2. The Docker daemon pulled the hello-world image from the Docker Hub.<br> 3. The Docker daemon created a new container from that image <span class="hljs-built_in">which</span> runs the<br>    executable that produces the output you are currently reading.<br> 4. The Docker daemon streamed that output to the Docker client, <span class="hljs-built_in">which</span> sent it<br>    to your terminal.<br><br>To try something more ambitious, you can run an Ubuntu container with:<br> $ docker run -it ubuntu bash<br><br>Share images, automate workflows, and more with a free Docker ID:<br> https://cloud.docker.com/<br><br>For more examples and ideas, visit:<br> https://docs.docker.com/engine/userguide/<br><br></code></pre></td></tr></table></figure><p>如果是linux生产关键要设置docker存储驱动,一般情况编辑 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service,以下为示例:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs bash">[Unit]<br><span class="hljs-comment"># 描述</span><br>Description=Docker Application Container Engine<br>Documentation=https://docs.docker.com<br><span class="hljs-comment"># 先决条件</span><br>After=network.target<br><br>[Service]<br>Type=notify<br><span class="hljs-comment"># the default is not to use systemd for cgroups because the delegate issues still</span><br><span class="hljs-comment"># exists and systemd currently does not support the cgroup feature set required</span><br><span class="hljs-comment"># for containers run by docker 通过docker 启动那些containers</span><br>ExecStart=/usr/bin/dockerd  -H tcp://172.16.0.22:2375 \<br>                            -H unix:///var/run/docker.sock<br>                            --insecure-registry registry.gozap.com \ <span class="hljs-comment">#仓库</span><br>                            --storage-driver=overlay2 \ <span class="hljs-comment"># 存储驱动</span><br>                            --graph=/data/docker \ <span class="hljs-comment">#docker 相关数据存储地址</span><br>                            --log-driver json-file \ <span class="hljs-comment">#日志驱动 </span><br>                            --log-opt max-size=50m \<br>                            --log-opt max-file=3 \<br>                            --log-opt labels=dohko22<br>ExecReload=/bin/kill -s HUP <span class="hljs-variable">$MAINPID</span><br><span class="hljs-comment"># Having non-zero Limit*s causes performance problems due to accounting overhead</span><br><span class="hljs-comment"># in the kernel. We recommend using cgroups to do container-local accounting.</span><br>LimitNOFILE=infinity<br>LimitNPROC=infinity<br>LimitCORE=infinity<br><span class="hljs-comment"># Uncomment TasksMax if your systemd version supports it.</span><br><span class="hljs-comment"># Only systemd 226 and above support this version.</span><br><span class="hljs-comment">#TasksMax=infinity</span><br>TimeoutStartSec=0<br><span class="hljs-comment"># set delegate yes so that systemd does not reset the cgroups of docker containers</span><br>Delegate=<span class="hljs-built_in">yes</span><br><span class="hljs-comment"># kill only the docker process, not all processes in the cgroup</span><br>KillMode=process<br><br>[Install]<br>WantedBy=multi-user.target<br><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">For Docker CE<br>Linux distribution  Supported storage drivers<br>Docker CE on Ubuntuaufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs<br>Docker CE on Debianaufs, devicemapper, overlay2 (Debian Stretch), overlay<br>Docker CE on CentOSdevicemapper<br>Docker CE on Fedoradevicemapper, overlay2 (Fedora 26 or later, experimental), overlay (experimental)<br><br>Supported backing filesystems<br>Storage driverSupported backing filesystems<br>overlay, overlay2ext4, xfs<br>aufsext4, xfs<br>devicemapperdirect-lvm<br>btrfsbtrfs<br>zfszfs<br><br></code></pre></td></tr></table></figure><h3 id="附录1"><a href="#附录1" class="headerlink" title="附录1"></a>附录1</h3><p>docker 一些常用命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t friendlyname .  <span class="hljs-comment"># Create image using this directory&#x27;s Dockerfile</span><br>docker run -p 4000:80 friendlyname  <span class="hljs-comment"># Run friendlyname mapping port 4000 to 80</span><br>docker run -d -p 4000:80 friendlyname         <span class="hljs-comment"># Same thing, but in detached mode</span><br>docker ps                                 <span class="hljs-comment"># See a list of all running containers</span><br>docker stop &lt;<span class="hljs-built_in">hash</span>&gt;                     <span class="hljs-comment"># Gracefully stop the specified container</span><br>docker ps -a           <span class="hljs-comment"># See a list of all containers, even the ones not running</span><br>docker <span class="hljs-built_in">kill</span> &lt;<span class="hljs-built_in">hash</span>&gt;                   <span class="hljs-comment"># Force shutdown of the specified container</span><br>docker <span class="hljs-built_in">rm</span> &lt;<span class="hljs-built_in">hash</span>&gt;              <span class="hljs-comment"># Remove the specified container from this machine</span><br>docker <span class="hljs-built_in">rm</span> $(docker ps -a -q)           <span class="hljs-comment"># Remove all containers from this machine</span><br>docker images -a                               <span class="hljs-comment"># Show all images on this machine</span><br>docker rmi &lt;imagename&gt;            <span class="hljs-comment"># Remove the specified image from this machine</span><br>docker rmi $(docker images -q)             <span class="hljs-comment"># Remove all images from this machine</span><br>docker login             <span class="hljs-comment"># Log in this CLI session using your Docker credentials</span><br>docker tag &lt;image&gt; username/repository:tag  <span class="hljs-comment"># Tag &lt;image&gt; for upload to registry</span><br>docker push username/repository:tag            <span class="hljs-comment"># Upload tagged image to registry</span><br>docker run username/repository:tag                   <span class="hljs-comment"># Run image from a registry</span><br></code></pre></td></tr></table></figure><ul><li>本文参考<a href="https://docs.docker.com/hackathon/">docker官方文档</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> docker </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>github.io+jekyll搭建博客</title>
      <link href="/blog/2017-06-28-buildBlog-github-jekyll/"/>
      <url>/blog/2017-06-28-buildBlog-github-jekyll/</url>
      
        <content type="html"><![CDATA[<h2 id="gitHub-io-jekyll搭建静态博客"><a href="#gitHub-io-jekyll搭建静态博客" class="headerlink" title="gitHub.io+jekyll搭建静态博客"></a>gitHub.io+jekyll搭建静态博客</h2><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><blockquote><p>macos10.12(Linux类似)</p></blockquote><blockquote><p>rvm</p></blockquote><blockquote><p>ruby 2.3.0</p></blockquote><blockquote><p>jekyll 3.2.1</p></blockquote><p>本文基于macOs的,Linux系统类似</p><hr><h3 id="一-安装rvm"><a href="#一-安装rvm" class="headerlink" title="一.安装rvm"></a>一.安装rvm</h3><p>因为国内网络原因,rvm安装需要翻墙才能访问.至于翻墙,自行想办法了.<br>install rvm 参考地址:<a href="https://rvm.io/rvm/install">https://rvm.io/rvm/install</a>进行安装<br>中间可能需要等待有点长时间,时间视网络情况,你懂的;<br>安装成功输入 rvm -v 查看</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">rvm -v<br>rvm 1.29.2 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io/]<br><br></code></pre></td></tr></table></figure><hr><h3 id="二-安装ruby"><a href="#二-安装ruby" class="headerlink" title="二.安装ruby"></a>二.安装ruby</h3><p>如果你成功安装rvm了.安装ruby就轻松了.参考<br><a href="https://ruby-china.org/wiki/install_ruby_guide">https://ruby-china.org/wiki/install_ruby_guide</a><br>,soeasy</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">rvm install 2.3.0<br><span class="hljs-comment"># 设置默认使用的 ruby 版本</span><br>rvm use 2.3.0 --default<br><span class="hljs-comment"># 安装 bundler</span><br>gem install bundler<br><br></code></pre></td></tr></table></figure><hr><h3 id="三-安装jekyll"><a href="#三-安装jekyll" class="headerlink" title="三.安装jekyll"></a>三.安装jekyll</h3><p>克隆jekyll模板<br>git clone <a href="https://github.com/mzlogin/mzlogin.github.io.git">https://github.com/mzlogin/mzlogin.github.io.git</a> 到本地目录,<br>进入刚刚克隆的目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入主题目录</span><br><span class="hljs-built_in">cd</span> mzlogin.github.io<br><span class="hljs-comment"># 安装 jekyll 等</span><br>bundle install<br><span class="hljs-comment"># 启动</span><br>jekyll -H 0.0.0.0 -P 4444<br><br></code></pre></td></tr></table></figure><p>打开浏览器可看到,删除作者自己写的_posts中的内容,替换成自己的博客markdown文件,根据博客主题作者提示改配置和文件,替换为自己的即可;</p><hr><h3 id="四-推送到自己gitHub上"><a href="#四-推送到自己gitHub上" class="headerlink" title="四.推送到自己gitHub上"></a>四.推送到自己gitHub上</h3><p>首先在 Github 上创建一个自己用户名的github.io，如: 用户名.github.io，之后讲刚刚修改的主题目录下的 .git 删除 ,git init 初始化,设置 git remote set-url 指向自己的github.io,最后推送到github上完成；Github 本身也是使用 jekyll 进行生成，所以会自动识别并生成博客；最后访问 http:&#x2F;&#x2F;用户名.github.io 即可.</p><hr><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p>本搭建教程参考<br><a href="https://mritd.me/2016/10/09/jekyll-create-a-static-blog/">https://mritd.me/2016/10/09/jekyll-create-a-static-blog/</a></p>]]></content>
      
      
      <categories>
          
          <category> Blog </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
